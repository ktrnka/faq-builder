{
  "submission": {
    "id": "1161hdg",
    "title": "Question about probabilities in a simple neural network classifier",
    "author": "FarmPharm",
    "selftext": "From my understanding, if we train a neural network to classify emails as either \"spam\" or not \"spam\", and we apply a softmax layer to the output, we can get a value for P(y | x). We could have two outputs, P(y=\"spam\" | x) and P(y=\"not spam\" | x) and then whichever value is higher is the likelier label.\n\nI know that Bayes rule says that P(y | x) = P(x | y) P(y) / P(x). So my question is, is the neural network learning the prior distribution of labels P(y) during training? I am kind of confused how this Bayes rule fits together with the output probablity P(y | x).\n\nAnd another question, if the network does learn the prior distribution of labels, does this mean that training the model with a training set consisting of 80% spam and 20% not spam vs. the opposite with 80% not spam and 20% spam will produce a very different model?\n\nThanks for the help!",
    "selftext_html": "<!-- SC_OFF --><div class=\"md\"><p>From my understanding, if we train a neural network to classify emails as either &quot;spam&quot; or not &quot;spam&quot;, and we apply a softmax layer to the output, we can get a value for P(y | x). We could have two outputs, P(y=&quot;spam&quot; | x) and P(y=&quot;not spam&quot; | x) and then whichever value is higher is the likelier label.</p>\n\n<p>I know that Bayes rule says that P(y | x) = P(x | y) P(y) / P(x). So my question is, is the neural network learning the prior distribution of labels P(y) during training? I am kind of confused how this Bayes rule fits together with the output probablity P(y | x).</p>\n\n<p>And another question, if the network does learn the prior distribution of labels, does this mean that training the model with a training set consisting of 80% spam and 20% not spam vs. the opposite with 80% not spam and 20% spam will produce a very different model?</p>\n\n<p>Thanks for the help!</p>\n</div><!-- SC_ON -->",
    "url": "https://www.reddit.com/r/MLQuestions/comments/1161hdg/question_about_probabilities_in_a_simple_neural/",
    "permalink": "/r/MLQuestions/comments/1161hdg/question_about_probabilities_in_a_simple_neural/",
    "subreddit": "MLQuestions",
    "created_utc": 1676780858.0,
    "score": 7,
    "ups": 7,
    "downs": 0,
    "upvote_ratio": 1.0,
    "num_comments": 3,
    "is_self": true,
    "over_18": false,
    "spoiler": false,
    "stickied": false,
    "locked": false,
    "archived": false,
    "distinguished": null,
    "link_flair_text": null,
    "timestamp": "2023-02-18T20:27:38"
  },
  "comments": [
    {
      "id": "j94klsb",
      "author": "activatedgeek",
      "body": "The first important thing to understand here is that we are not being Bayesian about x. It is something that we condition on (simply another input to the probability density function).\n\nThe Bayes rule here is instead applied over the classifier parameters. If we call the weights w, that means what we are learning for is:\n\np(w | x, y) = p(y | x, w) p(w) / p(x, y)\n\nThe output probability is p(y | x, w). The prior is p(w).\n\nThe neural network is not learning a prior over p(y) but an approximate posterior predictive distribution: p(y | x). Note that the predictive distribution is independent of w. I’ll skip explaining here but see definition of “posterior predictive distribution”.\n\nYou last question still stands and is a very important one! The answer in general is yes, both training sets will produce different answers. And it should!",
      "body_html": "<div class=\"md\"><p>The first important thing to understand here is that we are not being Bayesian about x. It is something that we condition on (simply another input to the probability density function).</p>\n\n<p>The Bayes rule here is instead applied over the classifier parameters. If we call the weights w, that means what we are learning for is:</p>\n\n<p>p(w | x, y) = p(y | x, w) p(w) / p(x, y)</p>\n\n<p>The output probability is p(y | x, w). The prior is p(w).</p>\n\n<p>The neural network is not learning a prior over p(y) but an approximate posterior predictive distribution: p(y | x). Note that the predictive distribution is independent of w. I’ll skip explaining here but see definition of “posterior predictive distribution”.</p>\n\n<p>You last question still stands and is a very important one! The answer in general is yes, both training sets will produce different answers. And it should!</p>\n</div>",
      "created_utc": 1676781895.0,
      "score": 6,
      "ups": 6,
      "downs": 0,
      "permalink": "/r/MLQuestions/comments/1161hdg/question_about_probabilities_in_a_simple_neural/j94klsb/",
      "parent_id": "t3_1161hdg",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-18T20:44:55"
    },
    {
      "id": "j9559dm",
      "author": "trnka",
      "body": "Great question! I can share my experiences from industry but I don't know the theory of it. \n\nAt the very least, most models seem to have a \"default guess\" when the input doesn't lead them one way or another. In that case they generally learn to predict the more common class. So in your 80/20 example a model would at least learn that differently. That's true in general, not just of neural networks.\n\nIf you take a set of examples that could go either way, in general it's my experience that models will predict the most common output rather than matching the distribution of outputs.\n\nOtherwise, it's my experience that models are much more affected by the inputs than prior probabilities of each class. I've seen hints that simpler models may be more affected by priors and less by the input, for instance in comparing confusion matrixes for a neural network text classifier to a logistic regression text classifier there was more \"banding\" in the confusion matrix for the logistic regression model. In other words it tended to predict a smaller set of common outputs.",
      "body_html": "<div class=\"md\"><p>Great question! I can share my experiences from industry but I don&#39;t know the theory of it. </p>\n\n<p>At the very least, most models seem to have a &quot;default guess&quot; when the input doesn&#39;t lead them one way or another. In that case they generally learn to predict the more common class. So in your 80/20 example a model would at least learn that differently. That&#39;s true in general, not just of neural networks.</p>\n\n<p>If you take a set of examples that could go either way, in general it&#39;s my experience that models will predict the most common output rather than matching the distribution of outputs.</p>\n\n<p>Otherwise, it&#39;s my experience that models are much more affected by the inputs than prior probabilities of each class. I&#39;ve seen hints that simpler models may be more affected by priors and less by the input, for instance in comparing confusion matrixes for a neural network text classifier to a logistic regression text classifier there was more &quot;banding&quot; in the confusion matrix for the logistic regression model. In other words it tended to predict a smaller set of common outputs.</p>\n</div>",
      "created_utc": 1676796608.0,
      "score": 2,
      "ups": 2,
      "downs": 0,
      "permalink": "/r/MLQuestions/comments/1161hdg/question_about_probabilities_in_a_simple_neural/j9559dm/",
      "parent_id": "t3_1161hdg",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-19T00:50:08"
    },
    {
      "id": "j94lzqh",
      "author": "FarmPharm",
      "body": "Thank you so much for the answer! That makes a lot more sense now.",
      "body_html": "<div class=\"md\"><p>Thank you so much for the answer! That makes a lot more sense now.</p>\n</div>",
      "created_utc": 1676782696.0,
      "score": 3,
      "ups": 3,
      "downs": 0,
      "permalink": "/r/MLQuestions/comments/1161hdg/question_about_probabilities_in_a_simple_neural/j94lzqh/",
      "parent_id": "t1_j94klsb",
      "depth": 1,
      "is_submitter": true,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-18T20:58:16"
    }
  ],
  "total_comments": 3,
  "fetched_at": "2025-09-13T20:47:25.923622"
}