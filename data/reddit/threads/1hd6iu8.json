{
  "submission": {
    "id": "1hd6iu8",
    "title": "For those running model experiments, ",
    "author": "Maleficent_Ad5541",
    "selftext": "How much of your workday or project timeline do you feel gets consumed by hyperparameter tuning? Do you find hyperparameter tuning to be a significant bottleneck in your workflow? \n\nI've asked around a bit and figured it differ between those in industry vs academia and even more so depending on specific sectors of applications but am curious what everyone's experiences has been. ",
    "selftext_html": "<!-- SC_OFF --><div class=\"md\"><p>How much of your workday or project timeline do you feel gets consumed by hyperparameter tuning? Do you find hyperparameter tuning to be a significant bottleneck in your workflow? </p>\n\n<p>I&#39;ve asked around a bit and figured it differ between those in industry vs academia and even more so depending on specific sectors of applications but am curious what everyone&#39;s experiences has been. </p>\n</div><!-- SC_ON -->",
    "url": "https://www.reddit.com/r/MLQuestions/comments/1hd6iu8/for_those_running_model_experiments/",
    "permalink": "/r/MLQuestions/comments/1hd6iu8/for_those_running_model_experiments/",
    "subreddit": "MLQuestions",
    "created_utc": 1734072289.0,
    "score": 5,
    "ups": 5,
    "downs": 0,
    "upvote_ratio": 1.0,
    "num_comments": 3,
    "is_self": true,
    "over_18": false,
    "spoiler": false,
    "stickied": false,
    "locked": false,
    "archived": false,
    "distinguished": null,
    "link_flair_text": "Beginner question ðŸ‘¶",
    "timestamp": "2024-12-12T22:44:49"
  },
  "comments": [
    {
      "id": "m1v8xls",
      "author": "trnka",
      "body": "From industry: Periodically I spend a day to a week on hyperparameter tuning but not much more. It's usually fun because because I get to learn more about the dataset I'm working with and/or try out ideas I've read in papers. So I don't think of it as a bottleneck.",
      "body_html": "<div class=\"md\"><p>From industry: Periodically I spend a day to a week on hyperparameter tuning but not much more. It&#39;s usually fun because because I get to learn more about the dataset I&#39;m working with and/or try out ideas I&#39;ve read in papers. So I don&#39;t think of it as a bottleneck.</p>\n</div>",
      "created_utc": 1734102427.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MLQuestions/comments/1hd6iu8/for_those_running_model_experiments/m1v8xls/",
      "parent_id": "t3_1hd6iu8",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2024-12-13T07:07:07"
    },
    {
      "id": "m2ao991",
      "author": "Maleficent_Ad5541",
      "body": "I appreciate the insight! I'm curious what insights you get into your dataset through the tuning process.",
      "body_html": "<div class=\"md\"><p>I appreciate the insight! I&#39;m curious what insights you get into your dataset through the tuning process.</p>\n</div>",
      "created_utc": 1734332563.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MLQuestions/comments/1hd6iu8/for_those_running_model_experiments/m2ao991/",
      "parent_id": "t1_m1v8xls",
      "depth": 1,
      "is_submitter": true,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2024-12-15T23:02:43"
    },
    {
      "id": "m2c3m2r",
      "author": "trnka",
      "body": "A good example would be depth vs width in neural networks and how the optimal hyperparameters vary based on the dataset size, dataset type (text vs image), etc.\n\nAnother was the filter width for convolutional neural networks for text classification and how that depends on the domain as well as dataset size.\n\nAnother one that's somewhat dependent on data size and type is the batch size. I'm aware of the relationship between batch size and learning rate, and Karpathy's recommendation to max out your batch size. In practice I found it hard to get reliable results for medium-sized datasets with maxxed batch sizes. It was also interesting for me to see that the recommended approach differed between image processing and text processing and to explore some.\n\nNot all of these are completely dependent on the dataset, but they tend to be affected a little bit and I find that fascinating.",
      "body_html": "<div class=\"md\"><p>A good example would be depth vs width in neural networks and how the optimal hyperparameters vary based on the dataset size, dataset type (text vs image), etc.</p>\n\n<p>Another was the filter width for convolutional neural networks for text classification and how that depends on the domain as well as dataset size.</p>\n\n<p>Another one that&#39;s somewhat dependent on data size and type is the batch size. I&#39;m aware of the relationship between batch size and learning rate, and Karpathy&#39;s recommendation to max out your batch size. In practice I found it hard to get reliable results for medium-sized datasets with maxxed batch sizes. It was also interesting for me to see that the recommended approach differed between image processing and text processing and to explore some.</p>\n\n<p>Not all of these are completely dependent on the dataset, but they tend to be affected a little bit and I find that fascinating.</p>\n</div>",
      "created_utc": 1734360847.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MLQuestions/comments/1hd6iu8/for_those_running_model_experiments/m2c3m2r/",
      "parent_id": "t1_m2ao991",
      "depth": 2,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2024-12-16T06:54:07"
    }
  ],
  "total_comments": 3,
  "fetched_at": "2025-09-13T20:47:08.995705"
}