{
  "submission": {
    "id": "11ckopj",
    "title": "[D] Simple Questions Thread",
    "author": "AutoModerator",
    "selftext": "Please post your questions here instead of creating a new thread. Encourage others who create new posts for questions to post here instead!\n\nThread will stay alive until next one so keep posting after the date in the title.\n\nThanks to everyone for answering questions in the previous thread!",
    "selftext_html": "<!-- SC_OFF --><div class=\"md\"><p>Please post your questions here instead of creating a new thread. Encourage others who create new posts for questions to post here instead!</p>\n\n<p>Thread will stay alive until next one so keep posting after the date in the title.</p>\n\n<p>Thanks to everyone for answering questions in the previous thread!</p>\n</div><!-- SC_ON -->",
    "url": "https://www.reddit.com/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/",
    "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/",
    "subreddit": "MachineLearning",
    "created_utc": 1677427223.0,
    "score": 19,
    "ups": 19,
    "downs": 0,
    "upvote_ratio": 0.92,
    "num_comments": 148,
    "is_self": true,
    "over_18": false,
    "spoiler": false,
    "stickied": false,
    "locked": false,
    "archived": false,
    "distinguished": null,
    "link_flair_text": "Discussion",
    "timestamp": "2023-02-26T08:00:23"
  },
  "comments": [
    {
      "id": "jac6zke",
      "author": "spruce5637",
      "body": "Is \"context window\" (as in GPT models) the same as maximum input sequence length (like in e.g., BERT, Longformer)? \n\nI see it used a lot recently in ChatGPT-related conversations, but when I look up \"context window\" on Google, most results are about word2vec. Since the transformer doesn't have a word2vec style context window during training, I'm guessing that people use it to refer to maximum input token length (based on the context, e.g. [this thread](https://www.reddit.com/r/MachineLearning/comments/zjbsie/comment/izv48yc/?utm_source=share&utm_medium=web2x&context=3) and [this thread](https://news.ycombinator.com/item?id=22197774)), but I'd like to be sure.",
      "body_html": "<div class=\"md\"><p>Is &quot;context window&quot; (as in GPT models) the same as maximum input sequence length (like in e.g., BERT, Longformer)? </p>\n\n<p>I see it used a lot recently in ChatGPT-related conversations, but when I look up &quot;context window&quot; on Google, most results are about word2vec. Since the transformer doesn&#39;t have a word2vec style context window during training, I&#39;m guessing that people use it to refer to maximum input token length (based on the context, e.g. <a href=\"https://www.reddit.com/r/MachineLearning/comments/zjbsie/comment/izv48yc/?utm_source=share&amp;utm_medium=web2x&amp;context=3\">this thread</a> and <a href=\"https://news.ycombinator.com/item?id=22197774\">this thread</a>), but I&#39;d like to be sure.</p>\n</div>",
      "created_utc": 1677583796.0,
      "score": 3,
      "ups": 3,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/jac6zke/",
      "parent_id": "t3_11ckopj",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-28T03:29:56"
    },
    {
      "id": "jb6bmrr",
      "author": "MaybeADragon",
      "body": "I'm incredibly new to machine learning, so apologies if my terminology is off.    \n\nMy boss wants to investigate image classification software for one of our clients. I found AutoKeras and I'm testing it on my home PC (Ryzen 9 5950x, Nvidia RTX 3090, 32gb DDR4 @ 3200mHz). I'm currently testing on the Cats and Dogs dataset   \n\nI've left it running for a good part of my day and as I've sat down to play some video games and chill for the evening I've found some strange behaviour. When leaving it running during a game of league of legends it runs slower as expected since it's using my GPU, however the instant I locked my FPS to 30 instead of 240 it ran faster than not having it running in the first place.    \n\nAverage time per epoch normally: ~600s    \nWith league @240 FPS lock: ~900s     \nWith league @30 FPS lock: ~400s    \n\nThis makes 0 sense. My gpu is under more load so why is it running the same number of steps of the same trial faster.     \n\nEDIT: If I had to guess, the gpu is clocking up under load thus increasing the performance on my ML task but by limiting FPS to 30 its not eating into the resources needed for it?",
      "body_html": "<div class=\"md\"><p>I&#39;m incredibly new to machine learning, so apologies if my terminology is off.    </p>\n\n<p>My boss wants to investigate image classification software for one of our clients. I found AutoKeras and I&#39;m testing it on my home PC (Ryzen 9 5950x, Nvidia RTX 3090, 32gb DDR4 @ 3200mHz). I&#39;m currently testing on the Cats and Dogs dataset   </p>\n\n<p>I&#39;ve left it running for a good part of my day and as I&#39;ve sat down to play some video games and chill for the evening I&#39;ve found some strange behaviour. When leaving it running during a game of league of legends it runs slower as expected since it&#39;s using my GPU, however the instant I locked my FPS to 30 instead of 240 it ran faster than not having it running in the first place.    </p>\n\n<p>Average time per epoch normally: ~600s<br/>\nWith league @240 FPS lock: ~900s<br/>\nWith league @30 FPS lock: ~400s    </p>\n\n<p>This makes 0 sense. My gpu is under more load so why is it running the same number of steps of the same trial faster.     </p>\n\n<p>EDIT: If I had to guess, the gpu is clocking up under load thus increasing the performance on my ML task but by limiting FPS to 30 its not eating into the resources needed for it?</p>\n</div>",
      "created_utc": 1678131518.0,
      "score": 3,
      "ups": 3,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/jb6bmrr/",
      "parent_id": "t3_11ckopj",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": true,
      "distinguished": null,
      "timestamp": "2023-03-06T11:38:38"
    },
    {
      "id": "jab8xnx",
      "author": "TuckAndRolle",
      "body": "Anyone have a sense of how ML-related  internships at a national laboratory are viewed by industry? I imagine it's not as good as an internship at FAANG but how would it compare to say smaller companies or groups within non-tech firms (say, Walmart, as a random example)\n\nEdit: By good I mean purely in terms of finding a fulltime job\n\nEdit2: This is a PhD summer internship fwiw",
      "body_html": "<div class=\"md\"><p>Anyone have a sense of how ML-related  internships at a national laboratory are viewed by industry? I imagine it&#39;s not as good as an internship at FAANG but how would it compare to say smaller companies or groups within non-tech firms (say, Walmart, as a random example)</p>\n\n<p>Edit: By good I mean purely in terms of finding a fulltime job</p>\n\n<p>Edit2: This is a PhD summer internship fwiw</p>\n</div>",
      "created_utc": 1677558252.0,
      "score": 2,
      "ups": 2,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/jab8xnx/",
      "parent_id": "t3_11ckopj",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": true,
      "distinguished": null,
      "timestamp": "2023-02-27T20:24:12"
    },
    {
      "id": "jaei77l",
      "author": "No_Bee_9081",
      "body": "A question from a noob.\n\nI have a dataset related to DDoS attacks, with has 80 features . In this dataset I have information about a network flow, ips, macs, packet information, tcp flags etc.\n\nNow I am starting to analyse, so I did:\n\n1-Clean the data(Dimensionality), where I looked for data missed,features with null values,converting categorical variables to numerical variables, and normalizing the data etc.\n\n2- I added a collumn with 1 or 0 in the end to represent an attack or no attack in my dataset.\n\n3-  What I should do now? I read that I should verify  be the correlation between features,is that correct? If is correct, how I can do it ? because I tried to create a heatmap but I still have 70 features, so it is impossible to verify it. is there any other way ? Because I still dont know what are the most important features, to create a correlation only between them.\n\nThank you for any help",
      "body_html": "<div class=\"md\"><p>A question from a noob.</p>\n\n<p>I have a dataset related to DDoS attacks, with has 80 features . In this dataset I have information about a network flow, ips, macs, packet information, tcp flags etc.</p>\n\n<p>Now I am starting to analyse, so I did:</p>\n\n<p>1-Clean the data(Dimensionality), where I looked for data missed,features with null values,converting categorical variables to numerical variables, and normalizing the data etc.</p>\n\n<p>2- I added a collumn with 1 or 0 in the end to represent an attack or no attack in my dataset.</p>\n\n<p>3-  What I should do now? I read that I should verify  be the correlation between features,is that correct? If is correct, how I can do it ? because I tried to create a heatmap but I still have 70 features, so it is impossible to verify it. is there any other way ? Because I still dont know what are the most important features, to create a correlation only between them.</p>\n\n<p>Thank you for any help</p>\n</div>",
      "created_utc": 1677619340.0,
      "score": 2,
      "ups": 2,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/jaei77l/",
      "parent_id": "t3_11ckopj",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-28T13:22:20"
    },
    {
      "id": "jagdtsm",
      "author": "monouns",
      "body": "I already shared this question at r/deeplearning, but once more share it here!  \n\nAny discussion or comments are welcome!\n\n1. I want to study adversarial attacks, and wondering if it's possible to know the foundation paper to recent paper lists. (well-written blog posts are also good!)\r  \n\r\n2. Risen by ChatGPT, the huge model with RL feedback learning is a popular trend in AI. Also, the Multi-Modal model with big parameters is a similarly popular trend with ChatGPT. I'm wondering if the research with small or toy models on this subject is still valuable or not. For individual researchers, it is hard to experiment with a big model which needs huge computation costs.\r  \n\r\n3. Finally, past to recent deep learning research focuses on two big categories: Vision and NLP. What do you think about the TimeSeries data domain?",
      "body_html": "<div class=\"md\"><p>I already shared this question at <a href=\"/r/deeplearning\">r/deeplearning</a>, but once more share it here!  </p>\n\n<p>Any discussion or comments are welcome!</p>\n\n<ol>\n<li><p>I want to study adversarial attacks, and wondering if it&#39;s possible to know the foundation paper to recent paper lists. (well-written blog posts are also good!)</p></li>\n<li><p>Risen by ChatGPT, the huge model with RL feedback learning is a popular trend in AI. Also, the Multi-Modal model with big parameters is a similarly popular trend with ChatGPT. I&#39;m wondering if the research with small or toy models on this subject is still valuable or not. For individual researchers, it is hard to experiment with a big model which needs huge computation costs.</p></li>\n<li><p>Finally, past to recent deep learning research focuses on two big categories: Vision and NLP. What do you think about the TimeSeries data domain?</p></li>\n</ol>\n</div>",
      "created_utc": 1677650818.0,
      "score": 2,
      "ups": 2,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/jagdtsm/",
      "parent_id": "t3_11ckopj",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-28T22:06:58"
    },
    {
      "id": "jahg1en",
      "author": "Broke_traveller",
      "body": "Do you think that model compression can help against overfitting?  \n\n\nWe know that big models with huge datasets can lead to very good results in terms of generalization ability. I am researching methods that tackle deep learning under data scarcity, and wondering if model compression/pruning could be one of the ways to research.  \nThe logic I am following is that since dropout is one of the ways we fight overfitting in NNs, and tree pruning is also a method to stop a decision tree from overfitting, then it follows that the extension of these (i.e. model compression techniques) can be useful.  \n\n\nDespite believing in my logic I could not find much papers to confirm this. Do you know of any papers that address this? Any help is appreciated.",
      "body_html": "<div class=\"md\"><p>Do you think that model compression can help against overfitting?  </p>\n\n<p>We know that big models with huge datasets can lead to very good results in terms of generalization ability. I am researching methods that tackle deep learning under data scarcity, and wondering if model compression/pruning could be one of the ways to research.<br/>\nThe logic I am following is that since dropout is one of the ways we fight overfitting in NNs, and tree pruning is also a method to stop a decision tree from overfitting, then it follows that the extension of these (i.e. model compression techniques) can be useful.  </p>\n\n<p>Despite believing in my logic I could not find much papers to confirm this. Do you know of any papers that address this? Any help is appreciated.</p>\n</div>",
      "created_utc": 1677678399.0,
      "score": 2,
      "ups": 2,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/jahg1en/",
      "parent_id": "t3_11ckopj",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-01T05:46:39"
    },
    {
      "id": "jaifg1d",
      "author": "shoegraze",
      "body": "Is there any research done around decreasing the likelihood of hallucinations in LLMs, particularly with regard to whether these are likely to decrease with scale? Personally I've found ChatGPT to be a really frustrating tool with respect to help on programming, logical, scientific, medical questions because the rate of hallucination is very high. With programming in particular, more often than not unless you're using a trivial problem it will invent functions or function arguments that don't exist, but \"seem right,\" or misuse functions or arguments to real functions. Then if you point out that it's wrong, it often suggests alternatives that are also hallucinated. \n\nI know alignment researchers are working on approaches to improve the truthfulness of language models, but has there been much compelling research published that LLMs will scale to be more accurate? I feel like most of the arguments I've heard from people have had to do with \"Well if we change the objective function to be so and so, it will be more likely to mesa-optimize some sort of honest-to-god genuine logic within its billions of weights.\"\n\nInterested if anyone's seen something they would be willing to share about improvements in this category",
      "body_html": "<div class=\"md\"><p>Is there any research done around decreasing the likelihood of hallucinations in LLMs, particularly with regard to whether these are likely to decrease with scale? Personally I&#39;ve found ChatGPT to be a really frustrating tool with respect to help on programming, logical, scientific, medical questions because the rate of hallucination is very high. With programming in particular, more often than not unless you&#39;re using a trivial problem it will invent functions or function arguments that don&#39;t exist, but &quot;seem right,&quot; or misuse functions or arguments to real functions. Then if you point out that it&#39;s wrong, it often suggests alternatives that are also hallucinated. </p>\n\n<p>I know alignment researchers are working on approaches to improve the truthfulness of language models, but has there been much compelling research published that LLMs will scale to be more accurate? I feel like most of the arguments I&#39;ve heard from people have had to do with &quot;Well if we change the objective function to be so and so, it will be more likely to mesa-optimize some sort of honest-to-god genuine logic within its billions of weights.&quot;</p>\n\n<p>Interested if anyone&#39;s seen something they would be willing to share about improvements in this category</p>\n</div>",
      "created_utc": 1677692705.0,
      "score": 2,
      "ups": 2,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/jaifg1d/",
      "parent_id": "t3_11ckopj",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-01T09:45:05"
    },
    {
      "id": "jaliayp",
      "author": "TinkerAndThinker",
      "body": "Just tried running Random Forest (1mil obs with 2100 features because of one-hot encoding) on my Macbook Pro, and it ran out of memory. \n\n1. What development/production build do y'all use for training Random Forest? \n2. Do you need to maintain that or you can just saved the trained model and just \"predict\" as and when necessary?\n3. What do you save the trained model as? Pickle?",
      "body_html": "<div class=\"md\"><p>Just tried running Random Forest (1mil obs with 2100 features because of one-hot encoding) on my Macbook Pro, and it ran out of memory. </p>\n\n<ol>\n<li>What development/production build do y&#39;all use for training Random Forest? </li>\n<li>Do you need to maintain that or you can just saved the trained model and just &quot;predict&quot; as and when necessary?</li>\n<li>What do you save the trained model as? Pickle?</li>\n</ol>\n</div>",
      "created_utc": 1677742681.0,
      "score": 2,
      "ups": 2,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/jaliayp/",
      "parent_id": "t3_11ckopj",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-01T23:38:01"
    },
    {
      "id": "jaroeuf",
      "author": "No_Canary_5299",
      "body": "Hi all I am doing a school project and am trying to find interesting real-life problems that can be solved with regression and classification. Hoping to find life sciences problem, so that it is more meaningful. Any suggestions for datasets?",
      "body_html": "<div class=\"md\"><p>Hi all I am doing a school project and am trying to find interesting real-life problems that can be solved with regression and classification. Hoping to find life sciences problem, so that it is more meaningful. Any suggestions for datasets?</p>\n</div>",
      "created_utc": 1677859225.0,
      "score": 2,
      "ups": 2,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/jaroeuf/",
      "parent_id": "t3_11ckopj",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-03T08:00:25"
    },
    {
      "id": "jas1gbj",
      "author": "FatalPaperCut",
      "body": "Anyone know if there's a language model which is built to produce a wiki (summary pages with concept links) based off a corpus of text?",
      "body_html": "<div class=\"md\"><p>Anyone know if there&#39;s a language model which is built to produce a wiki (summary pages with concept links) based off a corpus of text?</p>\n</div>",
      "created_utc": 1677864320.0,
      "score": 2,
      "ups": 2,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/jas1gbj/",
      "parent_id": "t3_11ckopj",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-03T09:25:20"
    },
    {
      "id": "jbfvi1g",
      "author": "Various_Ad7388",
      "body": "What does TensorFlow do really well as opposed to others like Pytorch?",
      "body_html": "<div class=\"md\"><p>What does TensorFlow do really well as opposed to others like Pytorch?</p>\n</div>",
      "created_utc": 1678303409.0,
      "score": 2,
      "ups": 2,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/jbfvi1g/",
      "parent_id": "t3_11ckopj",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-08T11:23:29"
    },
    {
      "id": "jbicird",
      "author": "SleekGeek8",
      "body": "Has anyone heard of or got to use ClearML? Hearing a lot of noise on it lately but never had a chance to play with it. Curious to hear people perspective - how is it different than FlowML or Comet?",
      "body_html": "<div class=\"md\"><p>Has anyone heard of or got to use ClearML? Hearing a lot of noise on it lately but never had a chance to play with it. Curious to hear people perspective - how is it different than FlowML or Comet?</p>\n</div>",
      "created_utc": 1678343649.0,
      "score": 2,
      "ups": 2,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/jbicird/",
      "parent_id": "t3_11ckopj",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-08T22:34:09"
    },
    {
      "id": "jbtm8ar",
      "author": "ExpressionCareful223",
      "body": "I'm a total noob to machine learning but the LLaMA leak makes me want to try to run it and learn more about machine learning. \n\nOne question I have so far is how the heck does 4bit quanitzation allow a model to run on a far less powerful machine with no reduction in output quality? \n\nMy initial impression is this sounds too good to be true, as if I can run an entire LLM on my phone if quantizized enough ðŸ˜‚ can someone help me understand what's actually happening here, and what the limits are?",
      "body_html": "<div class=\"md\"><p>I&#39;m a total noob to machine learning but the LLaMA leak makes me want to try to run it and learn more about machine learning. </p>\n\n<p>One question I have so far is how the heck does 4bit quanitzation allow a model to run on a far less powerful machine with no reduction in output quality? </p>\n\n<p>My initial impression is this sounds too good to be true, as if I can run an entire LLM on my phone if quantizized enough ðŸ˜‚ can someone help me understand what&#39;s actually happening here, and what the limits are?</p>\n</div>",
      "created_utc": 1678553396.0,
      "score": 2,
      "ups": 2,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/jbtm8ar/",
      "parent_id": "t3_11ckopj",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-11T08:49:56"
    },
    {
      "id": "ja3mycj",
      "author": "Impressive-Cancel892",
      "body": "Best machine learning course? (Free) or YouTube channel/ book/ etc",
      "body_html": "<div class=\"md\"><p>Best machine learning course? (Free) or YouTube channel/ book/ etc</p>\n</div>",
      "created_utc": 1677429271.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/ja3mycj/",
      "parent_id": "t3_11ckopj",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-26T08:34:31"
    },
    {
      "id": "ja42bzg",
      "author": "SHOVIC23",
      "body": "I am trying to build a neural network to model a function. There are 5 input parameters and one output parameter.\r  \n\r  \nSince I know the function, I randomly sample it to create a dataset. This way I have created a dataset of 10,000 entries. The neural network that I built has 3 hidden layers with 8,16,8 neurons. I have used gelu as activation the function in the hidden layers and linear as the activation function for the output layer. I used keras to build the neural network and used rmsprop as the optimizer.\r  \n\r  \nAfter 250 epochs, the validation mae is in the range of 0.33.\r  \n\r  \nIs there any way I can improve the mae? As far as I know that it is possible to model any function with a neural network having two or more layers.\r  \n\r  \nIn this case, I know the function, but can't seem to model it perfectly. Would it be possible to do that? If so, how?\r  \n\r  \nI would really appreciate any help.",
      "body_html": "<div class=\"md\"><p>I am trying to build a neural network to model a function. There are 5 input parameters and one output parameter.</p>\n\n<p>Since I know the function, I randomly sample it to create a dataset. This way I have created a dataset of 10,000 entries. The neural network that I built has 3 hidden layers with 8,16,8 neurons. I have used gelu as activation the function in the hidden layers and linear as the activation function for the output layer. I used keras to build the neural network and used rmsprop as the optimizer.</p>\n\n<p>After 250 epochs, the validation mae is in the range of 0.33.</p>\n\n<p>Is there any way I can improve the mae? As far as I know that it is possible to model any function with a neural network having two or more layers.</p>\n\n<p>In this case, I know the function, but can&#39;t seem to model it perfectly. Would it be possible to do that? If so, how?</p>\n\n<p>I would really appreciate any help.</p>\n</div>",
      "created_utc": 1677435284.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/ja42bzg/",
      "parent_id": "t3_11ckopj",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-26T10:14:44"
    },
    {
      "id": "ja48bfr",
      "author": "ALEXJAZZ008008",
      "body": "I find that a lot of things are not implemented for 3D volumetric data, which I'm exclusively working on. Which can be a slow down, especially if you want to try more novel ideas. However, usually I can at least bodge together something that works.\n\nI've tried to write my own version of tf.depth_to_space and tf.space_to_depth, as I would like to try using them over a standard strided convolution and nearest neighbours upsampling. My versions mainly use reshape and manually manipulating indexes etc. I don't trust that my versions work. Thus, I wondered if anyone had a semi-elegant implementation of this in Tensorflow, please?",
      "body_html": "<div class=\"md\"><p>I find that a lot of things are not implemented for 3D volumetric data, which I&#39;m exclusively working on. Which can be a slow down, especially if you want to try more novel ideas. However, usually I can at least bodge together something that works.</p>\n\n<p>I&#39;ve tried to write my own version of tf.depth_to_space and tf.space_to_depth, as I would like to try using them over a standard strided convolution and nearest neighbours upsampling. My versions mainly use reshape and manually manipulating indexes etc. I don&#39;t trust that my versions work. Thus, I wondered if anyone had a semi-elegant implementation of this in Tensorflow, please?</p>\n</div>",
      "created_utc": 1677437598.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/ja48bfr/",
      "parent_id": "t3_11ckopj",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-26T10:53:18"
    },
    {
      "id": "ja4jedq",
      "author": "Zorpork00",
      "body": "Im very new to machine learning, I have a few questions regarding it:\n1.  Best language to do machine learning(I know there might be multiple as per the goal in mind), to start with at least\n2. The best course for it(free and paid)\n3. Any tips would be nice :)",
      "body_html": "<div class=\"md\"><p>Im very new to machine learning, I have a few questions regarding it:\n1.  Best language to do machine learning(I know there might be multiple as per the goal in mind), to start with at least\n2. The best course for it(free and paid)\n3. Any tips would be nice :)</p>\n</div>",
      "created_utc": 1677442016.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/ja4jedq/",
      "parent_id": "t3_11ckopj",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-26T12:06:56"
    },
    {
      "id": "ja73zan",
      "author": "cagan1999",
      "body": "Hi guys, This semester I will start to write a bachelor thesis using machine learning methods. I am trying to research about other thesis to decide which topic I should use these methods on.I mostly want to work in a banking sector so if anybody here is also on the same position as me, let's help each other  \nhere is my discord: xenon1#1983",
      "body_html": "<div class=\"md\"><p>Hi guys, This semester I will start to write a bachelor thesis using machine learning methods. I am trying to research about other thesis to decide which topic I should use these methods on.I mostly want to work in a banking sector so if anybody here is also on the same position as me, let&#39;s help each other<br/>\nhere is my discord: xenon1#1983</p>\n</div>",
      "created_utc": 1677490633.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/ja73zan/",
      "parent_id": "t3_11ckopj",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-27T01:37:13"
    },
    {
      "id": "ja881a3",
      "author": "0660990",
      "body": "Is there any model that works for voice \"transition\"? For example feminizing a male voice. Thanks.",
      "body_html": "<div class=\"md\"><p>Is there any model that works for voice &quot;transition&quot;? For example feminizing a male voice. Thanks.</p>\n</div>",
      "created_utc": 1677513649.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/ja881a3/",
      "parent_id": "t3_11ckopj",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-27T08:00:49"
    },
    {
      "id": "ja88lqt",
      "author": "Dr_Gaius__Baltar",
      "body": "I'm seeing all these companies making new LLMs that are way smaller than GPT-3 for example, but have about the same performance. Why would they make the model smaller and not just use the same amount of parameters with better efficiency? Is it that they don't scale well?\nI'm thinking of Meta's LLaMA-13B that can reportedly run on a single GPU.",
      "body_html": "<div class=\"md\"><p>I&#39;m seeing all these companies making new LLMs that are way smaller than GPT-3 for example, but have about the same performance. Why would they make the model smaller and not just use the same amount of parameters with better efficiency? Is it that they don&#39;t scale well?\nI&#39;m thinking of Meta&#39;s LLaMA-13B that can reportedly run on a single GPU.</p>\n</div>",
      "created_utc": 1677513879.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/ja88lqt/",
      "parent_id": "t3_11ckopj",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-27T08:04:39"
    },
    {
      "id": "ja8qrgz",
      "author": "pidgezero_one",
      "body": "Would anyone have a recommendation for an AI tool that can recolour an image based on the palette of a very similar image?\n\nAn example would be recolouring the hi-res image of Mario in this link according to the colour palette of the lower-res version below it: https://imgur.com/a/RWewv7p\n\nSearching for something like this is kind of hard since Google assumes I'm looking to colourize black and white images.",
      "body_html": "<div class=\"md\"><p>Would anyone have a recommendation for an AI tool that can recolour an image based on the palette of a very similar image?</p>\n\n<p>An example would be recolouring the hi-res image of Mario in this link according to the colour palette of the lower-res version below it: <a href=\"https://imgur.com/a/RWewv7p\">https://imgur.com/a/RWewv7p</a></p>\n\n<p>Searching for something like this is kind of hard since Google assumes I&#39;m looking to colourize black and white images.</p>\n</div>",
      "created_utc": 1677520907.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/ja8qrgz/",
      "parent_id": "t3_11ckopj",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-27T10:01:47"
    },
    {
      "id": "ja9ujc4",
      "author": "AcresOfGreen",
      "body": "How popular is machine learning or artificial intelligence, how many people deeply understand versus apply known techniques. And is it a profitable field or has it become so competitive it isn't much above other jobs in pay?.",
      "body_html": "<div class=\"md\"><p>How popular is machine learning or artificial intelligence, how many people deeply understand versus apply known techniques. And is it a profitable field or has it become so competitive it isn&#39;t much above other jobs in pay?.</p>\n</div>",
      "created_utc": 1677535949.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/ja9ujc4/",
      "parent_id": "t3_11ckopj",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-27T14:12:29"
    },
    {
      "id": "jac4m8h",
      "author": "Human-Mess6152",
      "body": " I'm trying to find a dataset of people on different chat applications talking about meeting up, planning a party or similar things, i.e. talking about some kind of event. We're making a bot in Discord that will be able to recognize events using Machine learning but are having a hard time finding data. Either the data is just casual conversations not mentioning any type of event planning or the data is too structured as in a booking system. Anyone know any",
      "body_html": "<div class=\"md\"><p>I&#39;m trying to find a dataset of people on different chat applications talking about meeting up, planning a party or similar things, i.e. talking about some kind of event. We&#39;re making a bot in Discord that will be able to recognize events using Machine learning but are having a hard time finding data. Either the data is just casual conversations not mentioning any type of event planning or the data is too structured as in a booking system. Anyone know any</p>\n</div>",
      "created_utc": 1677581930.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/jac4m8h/",
      "parent_id": "t3_11ckopj",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-28T02:58:50"
    },
    {
      "id": "jadaj70",
      "author": "Browsinginoffice",
      "body": "im new to machine learning and my school project currently is researching about federated learning and data compression techniques such as pruning. \n\ncan anyone recommend me a good library to start with? i see most people recommending pytorch over tensorflow. is that a good idea?",
      "body_html": "<div class=\"md\"><p>im new to machine learning and my school project currently is researching about federated learning and data compression techniques such as pruning. </p>\n\n<p>can anyone recommend me a good library to start with? i see most people recommending pytorch over tensorflow. is that a good idea?</p>\n</div>",
      "created_utc": 1677602744.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/jadaj70/",
      "parent_id": "t3_11ckopj",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-28T08:45:44"
    },
    {
      "id": "jadlyde",
      "author": "Illustrious_Brush588",
      "body": "How can i add input data to a predictive model that uses LSTM",
      "body_html": "<div class=\"md\"><p>How can i add input data to a predictive model that uses LSTM</p>\n</div>",
      "created_utc": 1677607064.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/jadlyde/",
      "parent_id": "t3_11ckopj",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-28T09:57:44"
    },
    {
      "id": "jaeghdf",
      "author": "larenspear",
      "body": "I'm trying to do a binary classification of text with distilbert using HuggingFace transformers. I have my data split into train, validation, and test sets. I use my train and validation sets to get my model. I want to see how well it performs on my test set. What do I have to do to get the accuracy on my test set? Do I have to run an inference pipeline and calculate accuracy myself or is there something I'm missing?",
      "body_html": "<div class=\"md\"><p>I&#39;m trying to do a binary classification of text with distilbert using HuggingFace transformers. I have my data split into train, validation, and test sets. I use my train and validation sets to get my model. I want to see how well it performs on my test set. What do I have to do to get the accuracy on my test set? Do I have to run an inference pipeline and calculate accuracy myself or is there something I&#39;m missing?</p>\n</div>",
      "created_utc": 1677618684.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/jaeghdf/",
      "parent_id": "t3_11ckopj",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-28T13:11:24"
    },
    {
      "id": "jafzycj",
      "author": "wanderingflakjak",
      "body": "How to practice/apply computer vision concepts after learning them?",
      "body_html": "<div class=\"md\"><p>How to practice/apply computer vision concepts after learning them?</p>\n</div>",
      "created_utc": 1677642931.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/jafzycj/",
      "parent_id": "t3_11ckopj",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-28T19:55:31"
    },
    {
      "id": "jagtjhk",
      "author": null,
      "body": "I have a data set of press releases from publicly traded companies and the press release's net impact on the stock's return. For instance, press release X made the stock of that company increase Y %. Y is a floating number. The data set is properly cleaned and prepared (stop words etc) and consists of 20 000 good samples. However, Iâ€™m confused on how to approach the model training in tensor flow. \n\n1.\tIs it appropriate to convert Y into multiple labels (e.g 5 grade scale) and predict the label, or should I aim to predict the net impact return (floating number)?\n2.\tCan someone give me a hint or clue on what type of models to proceed with?\n\nI want to add that I have long experience in programming but am fairly new to machine learning. I have purchased several online courses and I understand the basics, but I need some guidance here. The courses donâ€™t cover this exact topic and I canâ€™t find good tutorials.",
      "body_html": "<div class=\"md\"><p>I have a data set of press releases from publicly traded companies and the press release&#39;s net impact on the stock&#39;s return. For instance, press release X made the stock of that company increase Y %. Y is a floating number. The data set is properly cleaned and prepared (stop words etc) and consists of 20 000 good samples. However, Iâ€™m confused on how to approach the model training in tensor flow. </p>\n\n<ol>\n<li> Is it appropriate to convert Y into multiple labels (e.g 5 grade scale) and predict the label, or should I aim to predict the net impact return (floating number)?</li>\n<li> Can someone give me a hint or clue on what type of models to proceed with?</li>\n</ol>\n\n<p>I want to add that I have long experience in programming but am fairly new to machine learning. I have purchased several online courses and I understand the basics, but I need some guidance here. The courses donâ€™t cover this exact topic and I canâ€™t find good tutorials.</p>\n</div>",
      "created_utc": 1677663161.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/jagtjhk/",
      "parent_id": "t3_11ckopj",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-01T01:32:41"
    },
    {
      "id": "jajo25n",
      "author": "throwaway2676",
      "body": "Is anyone familiar with any research on optimizing DNN parameters by using quantum annealing to minimize the loss function?  QA has achieved some remarkable results in a few niche optimization problems, but I just saw an offhand remark that it might be used to train neural networks.",
      "body_html": "<div class=\"md\"><p>Is anyone familiar with any research on optimizing DNN parameters by using quantum annealing to minimize the loss function?  QA has achieved some remarkable results in a few niche optimization problems, but I just saw an offhand remark that it might be used to train neural networks.</p>\n</div>",
      "created_utc": 1677709405.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/jajo25n/",
      "parent_id": "t3_11ckopj",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-01T14:23:25"
    },
    {
      "id": "jajwypq",
      "author": null,
      "body": "Hi guys, I have a question on how to design an experiment and what kind of modeling I should look at for a specific use case. \n\nI have a set of customers that I've identified as high value. I then want to determine when I should contact them with a specific offer and how often I should send them these offers. \n\nWhat's your guys opinion on a good model to assess this data? Could be supervised or unsupervised but mainly looking for some direction on how to even attack this problem. Also, what's a good way to design an experiment for this? Not looking for someone to give a definitive answer but maybe just something to go off of, any help appreciated!",
      "body_html": "<div class=\"md\"><p>Hi guys, I have a question on how to design an experiment and what kind of modeling I should look at for a specific use case. </p>\n\n<p>I have a set of customers that I&#39;ve identified as high value. I then want to determine when I should contact them with a specific offer and how often I should send them these offers. </p>\n\n<p>What&#39;s your guys opinion on a good model to assess this data? Could be supervised or unsupervised but mainly looking for some direction on how to even attack this problem. Also, what&#39;s a good way to design an experiment for this? Not looking for someone to give a definitive answer but maybe just something to go off of, any help appreciated!</p>\n</div>",
      "created_utc": 1677713068.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/jajwypq/",
      "parent_id": "t3_11ckopj",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-01T15:24:28"
    },
    {
      "id": "jamcipn",
      "author": "rm-rf_",
      "body": "Currently learning Jax. I've always learned frameworks and languages best through working on exercises and building projects.  Most tutorials I have seen are \"Here is how you do X\", rather than setting up a problem and letting you figure it out on your own.\n\nDoes anyone recommend any resources with exercises to work through for the purpose of learning Jax?",
      "body_html": "<div class=\"md\"><p>Currently learning Jax. I&#39;ve always learned frameworks and languages best through working on exercises and building projects.  Most tutorials I have seen are &quot;Here is how you do X&quot;, rather than setting up a problem and letting you figure it out on your own.</p>\n\n<p>Does anyone recommend any resources with exercises to work through for the purpose of learning Jax?</p>\n</div>",
      "created_utc": 1677764476.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/jamcipn/",
      "parent_id": "t3_11ckopj",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-02T05:41:16"
    },
    {
      "id": "jamlxj7",
      "author": "Frequent-Honeydew-64",
      "body": "How can I automate imputing a bunch of data into excel from the internet?\n\nIâ€™m not a ML engineer or data scientist. Iâ€™m actually a sales person doing the job of a marketer and SDR. \n\nI get long attendee lists from industry events that my company attends for marketing purposes. The director of marketing gives me a huge list which range from 600-1000 rows of contacts that I have to find the headquarter locations of the companies they work at. It is a lot of manual work. Where Iâ€™m going back and forth between google and excel typing and looking up info for each row. And Iâ€™m trying to figure out ways to automate this.\n\nI was wondering if anyone here had any ideas or thoughts around this. It will be greatly appreciated!",
      "body_html": "<div class=\"md\"><p>How can I automate imputing a bunch of data into excel from the internet?</p>\n\n<p>Iâ€™m not a ML engineer or data scientist. Iâ€™m actually a sales person doing the job of a marketer and SDR. </p>\n\n<p>I get long attendee lists from industry events that my company attends for marketing purposes. The director of marketing gives me a huge list which range from 600-1000 rows of contacts that I have to find the headquarter locations of the companies they work at. It is a lot of manual work. Where Iâ€™m going back and forth between google and excel typing and looking up info for each row. And Iâ€™m trying to figure out ways to automate this.</p>\n\n<p>I was wondering if anyone here had any ideas or thoughts around this. It will be greatly appreciated!</p>\n</div>",
      "created_utc": 1677768705.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/jamlxj7/",
      "parent_id": "t3_11ckopj",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-02T06:51:45"
    },
    {
      "id": "jan6tp3",
      "author": "albertoimpl",
      "body": "Hello, folks!  \nI am a Software Engineer and have been taking a few courses in ML recently, I am very used to trying things locally but every time I want to run something new I find that I need an NVIDIA card compatible with cuda and a decent amount of hardware.  \nWhat is the typical development workflow for people working on this every day?  \nIs it worth getting a PC with a GPU to play around or do people use Google Colab notebooks and persist the best results as they go?  \nThanks a lot!",
      "body_html": "<div class=\"md\"><p>Hello, folks!<br/>\nI am a Software Engineer and have been taking a few courses in ML recently, I am very used to trying things locally but every time I want to run something new I find that I need an NVIDIA card compatible with cuda and a decent amount of hardware.<br/>\nWhat is the typical development workflow for people working on this every day?<br/>\nIs it worth getting a PC with a GPU to play around or do people use Google Colab notebooks and persist the best results as they go?<br/>\nThanks a lot!</p>\n</div>",
      "created_utc": 1677776994.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/jan6tp3/",
      "parent_id": "t3_11ckopj",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-02T09:09:54"
    },
    {
      "id": "jao7kkz",
      "author": "Ashken",
      "body": "Hello everyone, and thanks in advanced for your help. \n\nNot sure if my question is simple, so I apologize if I'm asking too much. Here's a quick preface: I am a software engineer, been programming since college in 2013. I haven't ever worked with ML or AI, but I am currently in the position with one of the industries that I work in where I see a use case for AI and I'm interested in developing it. \n\nI don't want to say exactly what I want the AI to do because I wish to develop this into a product, but I can describe it in an analogy: Let's say I have numerous articles about food and cooking, and I need to categorize specific words in these articles. For example, when the AI reads \"salmon\", it puts it into the Meat category. When it reads \"Swiss\" it puts it into the Dairy category. When it reads \"whisk\" it puts it in to the Cooking Utensils category as well as the Cooking Method category. And when it is done with the article, it returns all of the words and all of the categories that they fall into. \n\n&#x200B;\n\nQuestions: \n\n1. Is there a model that exists already that can do this?  And if so, would it work no matter the format of document? (for example, instead of an article, it could do lyrics) \n2. If there isn't one, how could I go about training a model to do this? I have the ability to create some data for this, but not much. About 30 or so of these \"articles\".",
      "body_html": "<div class=\"md\"><p>Hello everyone, and thanks in advanced for your help. </p>\n\n<p>Not sure if my question is simple, so I apologize if I&#39;m asking too much. Here&#39;s a quick preface: I am a software engineer, been programming since college in 2013. I haven&#39;t ever worked with ML or AI, but I am currently in the position with one of the industries that I work in where I see a use case for AI and I&#39;m interested in developing it. </p>\n\n<p>I don&#39;t want to say exactly what I want the AI to do because I wish to develop this into a product, but I can describe it in an analogy: Let&#39;s say I have numerous articles about food and cooking, and I need to categorize specific words in these articles. For example, when the AI reads &quot;salmon&quot;, it puts it into the Meat category. When it reads &quot;Swiss&quot; it puts it into the Dairy category. When it reads &quot;whisk&quot; it puts it in to the Cooking Utensils category as well as the Cooking Method category. And when it is done with the article, it returns all of the words and all of the categories that they fall into. </p>\n\n<p>&#x200B;</p>\n\n<p>Questions: </p>\n\n<ol>\n<li>Is there a model that exists already that can do this?  And if so, would it work no matter the format of document? (for example, instead of an article, it could do lyrics) </li>\n<li>If there isn&#39;t one, how could I go about training a model to do this? I have the ability to create some data for this, but not much. About 30 or so of these &quot;articles&quot;.</li>\n</ol>\n</div>",
      "created_utc": 1677791700.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/jao7kkz/",
      "parent_id": "t3_11ckopj",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-02T13:15:00"
    },
    {
      "id": "jaqjqv0",
      "author": "RetardedFanny",
      "body": "Hi everyone,\nA rookie here, I am working on a project where I'm using python to build some models, but I've been told that the scoring of the data using the model has to be done in SQL? \nI'm not quite sure how i can do this, is there a way for me to convert the output of a python model into SQL query form? \nI know that there is a module called XGB2SQL which does what I'm describing but only for XGB models, is there anything for other models, I haven't been able to find anything meaningful so far.\n\nThanks for any advice.",
      "body_html": "<div class=\"md\"><p>Hi everyone,\nA rookie here, I am working on a project where I&#39;m using python to build some models, but I&#39;ve been told that the scoring of the data using the model has to be done in SQL? \nI&#39;m not quite sure how i can do this, is there a way for me to convert the output of a python model into SQL query form? \nI know that there is a module called XGB2SQL which does what I&#39;m describing but only for XGB models, is there anything for other models, I haven&#39;t been able to find anything meaningful so far.</p>\n\n<p>Thanks for any advice.</p>\n</div>",
      "created_utc": 1677836043.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/jaqjqv0/",
      "parent_id": "t3_11ckopj",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-03T01:34:03"
    },
    {
      "id": "jaqnmr7",
      "author": "Konki29",
      "body": "Hi, I'm a student doing the train of a model of a CNN, CIFAR10 dataset, looking at the graph, what would be your advice when training the model? or upgrade my model, idk if my model is enough to learn the patterns of the images.\n\n&#x200B;\n\nmy guess looking at the graph is that the validation is doing nothing good. looking at the training, it has left to learn if I put more epochs.\n\nany help?\n\n[https://imgur.com/a/eNk8X3Q](https://imgur.com/a/eNk8X3Q) \\- error\n\n[https://imgur.com/a/bkM5Q2D](https://imgur.com/a/bkM5Q2D) \\- accuracy",
      "body_html": "<div class=\"md\"><p>Hi, I&#39;m a student doing the train of a model of a CNN, CIFAR10 dataset, looking at the graph, what would be your advice when training the model? or upgrade my model, idk if my model is enough to learn the patterns of the images.</p>\n\n<p>&#x200B;</p>\n\n<p>my guess looking at the graph is that the validation is doing nothing good. looking at the training, it has left to learn if I put more epochs.</p>\n\n<p>any help?</p>\n\n<p><a href=\"https://imgur.com/a/eNk8X3Q\">https://imgur.com/a/eNk8X3Q</a> - error</p>\n\n<p><a href=\"https://imgur.com/a/bkM5Q2D\">https://imgur.com/a/bkM5Q2D</a> - accuracy</p>\n</div>",
      "created_utc": 1677839388.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/jaqnmr7/",
      "parent_id": "t3_11ckopj",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-03T02:29:48"
    },
    {
      "id": "jatc3fc",
      "author": "Eaklony",
      "body": "How much ML research will I be able to do at home with a single 4090? Iâ€™m graduating this summer with pure math Masters degree. And I plan to self study ML before either doing a phd or ml related industry job. Is this a good idea?",
      "body_html": "<div class=\"md\"><p>How much ML research will I be able to do at home with a single 4090? Iâ€™m graduating this summer with pure math Masters degree. And I plan to self study ML before either doing a phd or ml related industry job. Is this a good idea?</p>\n</div>",
      "created_utc": 1677882827.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/jatc3fc/",
      "parent_id": "t3_11ckopj",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-03T14:33:47"
    },
    {
      "id": "jats63r",
      "author": "TheArtorias1",
      "body": "Does anyone have an example code of building an Android app around a TensorFlow/TFLite file converted from trained transformer model used for translation purposes for eg.. english to portuguese?",
      "body_html": "<div class=\"md\"><p>Does anyone have an example code of building an Android app around a TensorFlow/TFLite file converted from trained transformer model used for translation purposes for eg.. english to portuguese?</p>\n</div>",
      "created_utc": 1677889999.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/jats63r/",
      "parent_id": "t3_11ckopj",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-03T16:33:19"
    },
    {
      "id": "jatw37x",
      "author": "Ricenaros",
      "body": "Assuming money is not an issue, what is the best possible single GPU for deep learning? What if I am using multiple GPUs?",
      "body_html": "<div class=\"md\"><p>Assuming money is not an issue, what is the best possible single GPU for deep learning? What if I am using multiple GPUs?</p>\n</div>",
      "created_utc": 1677891875.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/jatw37x/",
      "parent_id": "t3_11ckopj",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-03T17:04:35"
    },
    {
      "id": "jau5o2r",
      "author": "No_Canary_5299",
      "body": "What is ONE dataset that I can perform both regression and classification?",
      "body_html": "<div class=\"md\"><p>What is ONE dataset that I can perform both regression and classification?</p>\n</div>",
      "created_utc": 1677896513.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/jau5o2r/",
      "parent_id": "t3_11ckopj",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-03T18:21:53"
    },
    {
      "id": "javdxdu",
      "author": "MCjnr",
      "body": "Hi, I'm currently in my second degree studies and I want to explore machine learning.\r The problem is that my knowledge level on this topic is very low and I have to make\r an important decision regarding my studies soon. I'd really appreciate if someone could \r reach out to me, preferably in private massage and help me ot a little.",
      "body_html": "<div class=\"md\"><p>Hi, I&#39;m currently in my second degree studies and I want to explore machine learning.\n The problem is that my knowledge level on this topic is very low and I have to make\n an important decision regarding my studies soon. I&#39;d really appreciate if someone could \n reach out to me, preferably in private massage and help me ot a little.</p>\n</div>",
      "created_utc": 1677926300.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/javdxdu/",
      "parent_id": "t3_11ckopj",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-04T02:38:20"
    },
    {
      "id": "jawe6j4",
      "author": "TheGeniusSkipper",
      "body": "I am a computer science student and I have been looking into reinforcement learning for fun. I've been trying to learn deep q learning, but it seems like it wouldn't work for a lot of games. Take tic-tac-toe for example (I know there are much simpler and easier ways to make an AI for tic-tac-toe but I'm just using it as an example). At different points in a tic-tac-toe game, there are a different amount of actions you can take. At the start there are 9 possible actions, but the amount reduces as the game goes on. So how could deep q learning possibly work with this if the neural networks for it have a rigid structure and therefore would not be able to accommodate this? If I were to create the neural network with 9 outputs, towards the end of the game it would start spitting out illegal moves if it gave the highest Q-value to a move that isn't possible and so it wouldn't work. Am I misunderstanding something here? Or is another algorithm required for this kind of problem? Thanks in advance for any help you can give.",
      "body_html": "<div class=\"md\"><p>I am a computer science student and I have been looking into reinforcement learning for fun. I&#39;ve been trying to learn deep q learning, but it seems like it wouldn&#39;t work for a lot of games. Take tic-tac-toe for example (I know there are much simpler and easier ways to make an AI for tic-tac-toe but I&#39;m just using it as an example). At different points in a tic-tac-toe game, there are a different amount of actions you can take. At the start there are 9 possible actions, but the amount reduces as the game goes on. So how could deep q learning possibly work with this if the neural networks for it have a rigid structure and therefore would not be able to accommodate this? If I were to create the neural network with 9 outputs, towards the end of the game it would start spitting out illegal moves if it gave the highest Q-value to a move that isn&#39;t possible and so it wouldn&#39;t work. Am I misunderstanding something here? Or is another algorithm required for this kind of problem? Thanks in advance for any help you can give.</p>\n</div>",
      "created_utc": 1677946823.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/jawe6j4/",
      "parent_id": "t3_11ckopj",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-04T08:20:23"
    },
    {
      "id": "jawer28",
      "author": "SkeeringReal",
      "body": "Can someone please list for me the domains in which AI is better than humans, and we do not understand why?\n\nFor example, AlphaGo did a lot of interesting moves, it's better than humans at Go, but we don't understand its learned knowledge.\n\nAnother example is [here](https://www.nature.com/articles/s41598-021-89743-x), where an AI can predict gender from retinal fungus images, but we have no idea how it's doing it. Wouldn't it be cool to be able to ask the AI how it did it?\n\nAny other domains people can think of? Thank you in advance!",
      "body_html": "<div class=\"md\"><p>Can someone please list for me the domains in which AI is better than humans, and we do not understand why?</p>\n\n<p>For example, AlphaGo did a lot of interesting moves, it&#39;s better than humans at Go, but we don&#39;t understand its learned knowledge.</p>\n\n<p>Another example is <a href=\"https://www.nature.com/articles/s41598-021-89743-x\">here</a>, where an AI can predict gender from retinal fungus images, but we have no idea how it&#39;s doing it. Wouldn&#39;t it be cool to be able to ask the AI how it did it?</p>\n\n<p>Any other domains people can think of? Thank you in advance!</p>\n</div>",
      "created_utc": 1677947058.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/jawer28/",
      "parent_id": "t3_11ckopj",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-04T08:24:18"
    },
    {
      "id": "jax0p74",
      "author": null,
      "body": "Is there a demand for textbook for training LLM's/Foundational Models  OR distributed model training ?",
      "body_html": "<div class=\"md\"><p>Is there a demand for textbook for training LLM&#39;s/Foundational Models  OR distributed model training ?</p>\n</div>",
      "created_utc": 1677955937.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/jax0p74/",
      "parent_id": "t3_11ckopj",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-04T10:52:17"
    },
    {
      "id": "jaxwkxe",
      "author": "GaseousOrchid",
      "body": "How do you guys typically serialize data for training large datasets (\\~1-10 TB)? Right now I'm using multiple shards of tfrecords, and it plays well with [tf.data](https://tf.data), but if I'm using something like PyTorch I'm not sure what to use. Do you guys use msgpack or something like hdf5?",
      "body_html": "<div class=\"md\"><p>How do you guys typically serialize data for training large datasets (~1-10 TB)? Right now I&#39;m using multiple shards of tfrecords, and it plays well with <a href=\"https://tf.data\">tf.data</a>, but if I&#39;m using something like PyTorch I&#39;m not sure what to use. Do you guys use msgpack or something like hdf5?</p>\n</div>",
      "created_utc": 1677969387.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/jaxwkxe/",
      "parent_id": "t3_11ckopj",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-04T14:36:27"
    },
    {
      "id": "jazkymz",
      "author": "Reasonable-Fox-2459",
      "body": "Is anyone doing AI Research for companies/start-ups/research labs fully remote? \n\nIf so, how is your experience so far? Are such openings common? How did you find yours? Are you still able to publish in top venues? Can you still advance in your career?\n\nThanks!",
      "body_html": "<div class=\"md\"><p>Is anyone doing AI Research for companies/start-ups/research labs fully remote? </p>\n\n<p>If so, how is your experience so far? Are such openings common? How did you find yours? Are you still able to publish in top venues? Can you still advance in your career?</p>\n\n<p>Thanks!</p>\n</div>",
      "created_utc": 1678002017.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/jazkymz/",
      "parent_id": "t3_11ckopj",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-04T23:40:17"
    },
    {
      "id": "jb0ks51",
      "author": "Romcom1398",
      "body": "Say I want to do binary classification with a very imbalanced dataset with labels 'yes' and 'no'. I use Gridsearch to compare different hyperparameters of an ML algorithm. Would it be bad to first split the data into 'yes' and 'no', then from both take 70%, 20% and 10% accordingly for training validation and testing,, and then mush them back together so the training set for instance has 70% of the yes data and 70% of the 'no' data, to make sure that the model has enough instances with both labels to train on?",
      "body_html": "<div class=\"md\"><p>Say I want to do binary classification with a very imbalanced dataset with labels &#39;yes&#39; and &#39;no&#39;. I use Gridsearch to compare different hyperparameters of an ML algorithm. Would it be bad to first split the data into &#39;yes&#39; and &#39;no&#39;, then from both take 70%, 20% and 10% accordingly for training validation and testing,, and then mush them back together so the training set for instance has 70% of the yes data and 70% of the &#39;no&#39; data, to make sure that the model has enough instances with both labels to train on?</p>\n</div>",
      "created_utc": 1678027831.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/jb0ks51/",
      "parent_id": "t3_11ckopj",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-05T06:50:31"
    },
    {
      "id": "jb27a3e",
      "author": null,
      "body": "I coded and trained a naive bayes classifer in python.\n\nHow do I deploy a trained algorithm to the web, so I can send it data and have it return my classification tags?\n\nSome background: I'm a marketer with a math background. I've been using pandas for the last couple years to do basic exploratory data analysis. This is my first ML algorithm. Any links to tutorials or other resources would be greatly appreciated.",
      "body_html": "<div class=\"md\"><p>I coded and trained a naive bayes classifer in python.</p>\n\n<p>How do I deploy a trained algorithm to the web, so I can send it data and have it return my classification tags?</p>\n\n<p>Some background: I&#39;m a marketer with a math background. I&#39;ve been using pandas for the last couple years to do basic exploratory data analysis. This is my first ML algorithm. Any links to tutorials or other resources would be greatly appreciated.</p>\n</div>",
      "created_utc": 1678052222.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/jb27a3e/",
      "parent_id": "t3_11ckopj",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-05T13:37:02"
    },
    {
      "id": "jb4cep8",
      "author": "Party-Worldliness-72",
      "body": "Hi! someone knows any library that implement filter feature selection methods that can detect feature interaction. Until now I've used Relief, it works great but it do not detect  feature redundance. It seem that there is others: FOCUS, INTERACT... but any of them have python implementations or I've not able to find it.",
      "body_html": "<div class=\"md\"><p>Hi! someone knows any library that implement filter feature selection methods that can detect feature interaction. Until now I&#39;ve used Relief, it works great but it do not detect  feature redundance. It seem that there is others: FOCUS, INTERACT... but any of them have python implementations or I&#39;ve not able to find it.</p>\n</div>",
      "created_utc": 1678095552.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/jb4cep8/",
      "parent_id": "t3_11ckopj",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-06T01:39:12"
    },
    {
      "id": "jb915b8",
      "author": "YesteryearNostalgia",
      "body": "Hello,\nI wanted to learn if there are any LLMs pretrained on CVs for job application analysis? commercial or not, doesnt matter",
      "body_html": "<div class=\"md\"><p>Hello,\nI wanted to learn if there are any LLMs pretrained on CVs for job application analysis? commercial or not, doesnt matter</p>\n</div>",
      "created_utc": 1678182526.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/jb915b8/",
      "parent_id": "t3_11ckopj",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-07T01:48:46"
    },
    {
      "id": "jb962ns",
      "author": "reptior",
      "body": "Hello, which models are used to generate the voice of the presidents playing minecraft? I have seen that they are generated by the page voice.ai",
      "body_html": "<div class=\"md\"><p>Hello, which models are used to generate the voice of the presidents playing minecraft? I have seen that they are generated by the page voice.ai</p>\n</div>",
      "created_utc": 1678186770.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/jb962ns/",
      "parent_id": "t3_11ckopj",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-07T02:59:30"
    },
    {
      "id": "jbciv16",
      "author": "goofnug",
      "body": "is there a way to find the words or phrases in a large language model that have the least number of connections?e.g. what words are the most unlikely to occur, and which have very few possible words that could come after?",
      "body_html": "<div class=\"md\"><p>is there a way to find the words or phrases in a large language model that have the least number of connections?e.g. what words are the most unlikely to occur, and which have very few possible words that could come after?</p>\n</div>",
      "created_utc": 1678239104.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/jbciv16/",
      "parent_id": "t3_11ckopj",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-07T17:31:44"
    },
    {
      "id": "jbcjhtb",
      "author": null,
      "body": "[deleted]",
      "body_html": "<div class=\"md\"><p>[deleted]</p>\n</div>",
      "created_utc": 1678239395.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/jbcjhtb/",
      "parent_id": "t3_11ckopj",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-07T17:36:35"
    },
    {
      "id": "jbeiur5",
      "author": "IRadiateNothing",
      "body": "Can someone explain Temperature scaling in an ELI5 fashion please?",
      "body_html": "<div class=\"md\"><p>Can someone explain Temperature scaling in an ELI5 fashion please?</p>\n</div>",
      "created_utc": 1678284315.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/jbeiur5/",
      "parent_id": "t3_11ckopj",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-08T06:05:15"
    },
    {
      "id": "jbezimn",
      "author": "oge_retla",
      "body": "Hello, I am wondering if a language model the likes of chatGPT would need an internet connection in order to function, supposedly if you could \"download\" the model. And if so, what would be the size of the model. This is because I was thinking that if having it on system without internet, would pretty much still make it sort of like you have internet, which would be amazing for a lot of applications - like Learning in countries / regions with slow or no internet connection.",
      "body_html": "<div class=\"md\"><p>Hello, I am wondering if a language model the likes of chatGPT would need an internet connection in order to function, supposedly if you could &quot;download&quot; the model. And if so, what would be the size of the model. This is because I was thinking that if having it on system without internet, would pretty much still make it sort of like you have internet, which would be amazing for a lot of applications - like Learning in countries / regions with slow or no internet connection.</p>\n</div>",
      "created_utc": 1678291220.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/jbezimn/",
      "parent_id": "t3_11ckopj",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-08T08:00:20"
    },
    {
      "id": "jbfrxjy",
      "author": null,
      "body": "[deleted]",
      "body_html": "<div class=\"md\"><p>[deleted]</p>\n</div>",
      "created_utc": 1678302046.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/jbfrxjy/",
      "parent_id": "t3_11ckopj",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-08T11:00:46"
    },
    {
      "id": "jbk1293",
      "author": "beewally",
      "body": "I might be starting  a job at a FAANG company that would entail supporting ML engineers. \n\nI know almost nothing about ML right now other than they need lots of dataâ€” which I believe is a problem for me to do my job very well. What resources would you recommend?",
      "body_html": "<div class=\"md\"><p>I might be starting  a job at a FAANG company that would entail supporting ML engineers. </p>\n\n<p>I know almost nothing about ML right now other than they need lots of dataâ€” which I believe is a problem for me to do my job very well. What resources would you recommend?</p>\n</div>",
      "created_utc": 1678379690.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/jbk1293/",
      "parent_id": "t3_11ckopj",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-09T08:34:50"
    },
    {
      "id": "jbl1oqi",
      "author": "loly0ss",
      "body": "Hello!\n\nI'm using resnet50 for a task and I wanted to remove the fully connected layer. I was curious about something. Is removing resnet's fully connected layer entirely using nn.Identity() then add my own fc layer different than if I directly overwrite resnet's original fc layer? I put a small code example for clarification.\r  \n\r  \nThank you!\r  \n\r  \nself.resnet50.fc = nn.Sequential(\r  \nnn.Linear(2048, 256),\r  \nnn.ReLU(inplace=True),\r  \nnn.Linear(256, 10)).to(device)\r  \ndef forward(self,x):\r  \n\r  \nx = self.resnet50(x)\r  \n  \nreturn x\r  \n \r  \n\r  \nvs\r  \n\r  \nself.resnet50.fc = nn.Identity()\r  \n\r  \nself.fc = nn.Sequential(\r  \nnn.Linear(2048, 256),\r  \nnn.ReLU(inplace=True),\r  \nnn.Linear(256, 10)).to(device)\r  \n\r  \ndef forward(self,x):\r  \n\r  \nx = self.resnet50(x)\r  \nx= self.fc(x)\r  \n\r  \nreturn x",
      "body_html": "<div class=\"md\"><p>Hello!</p>\n\n<p>I&#39;m using resnet50 for a task and I wanted to remove the fully connected layer. I was curious about something. Is removing resnet&#39;s fully connected layer entirely using nn.Identity() then add my own fc layer different than if I directly overwrite resnet&#39;s original fc layer? I put a small code example for clarification.</p>\n\n<p>Thank you!</p>\n\n<p>self.resnet50.fc = nn.Sequential(</p>\n\n<p>nn.Linear(2048, 256),</p>\n\n<p>nn.ReLU(inplace=True),</p>\n\n<p>nn.Linear(256, 10)).to(device)</p>\n\n<p>def forward(self,x):</p>\n\n<p>x = self.resnet50(x)</p>\n\n<p>return x</p>\n\n<p>vs</p>\n\n<p>self.resnet50.fc = nn.Identity()</p>\n\n<p>self.fc = nn.Sequential(</p>\n\n<p>nn.Linear(2048, 256),</p>\n\n<p>nn.ReLU(inplace=True),</p>\n\n<p>nn.Linear(256, 10)).to(device)</p>\n\n<p>def forward(self,x):</p>\n\n<p>x = self.resnet50(x)</p>\n\n<p>x= self.fc(x)</p>\n\n<p>return x</p>\n</div>",
      "created_utc": 1678393357.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/jbl1oqi/",
      "parent_id": "t3_11ckopj",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-09T12:22:37"
    },
    {
      "id": "jbnlivh",
      "author": "rmofati",
      "body": "Guys, please help me build an artificial intelligence system for a store. Common recommender systems recommend products to users based on their interactions with the site, but in this tool I would like to develop, I would like to do just the opposite, make the site build a list of the most popular users indicated to buy a certain product. Do you know of any similar turorial or way I could do this? I have user interaction data with the page, in addition to product and user data. Thanks!",
      "body_html": "<div class=\"md\"><p>Guys, please help me build an artificial intelligence system for a store. Common recommender systems recommend products to users based on their interactions with the site, but in this tool I would like to develop, I would like to do just the opposite, make the site build a list of the most popular users indicated to buy a certain product. Do you know of any similar turorial or way I could do this? I have user interaction data with the page, in addition to product and user data. Thanks!</p>\n</div>",
      "created_utc": 1678440603.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/jbnlivh/",
      "parent_id": "t3_11ckopj",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": true,
      "distinguished": null,
      "timestamp": "2023-03-10T01:30:03"
    },
    {
      "id": "jbnq37s",
      "author": "Riboflavius",
      "body": "Autocorrelograms and digital signal processing - why did (mel) spectrograms persist?  \n\nI'm trying to look deeper into audio generation with transformers and diffusion models, and I can't seem to find any that aren't using spectrograms and are basically doing computer vision on audio data. Is there a technical reason for that?",
      "body_html": "<div class=\"md\"><p>Autocorrelograms and digital signal processing - why did (mel) spectrograms persist?  </p>\n\n<p>I&#39;m trying to look deeper into audio generation with transformers and diffusion models, and I can&#39;t seem to find any that aren&#39;t using spectrograms and are basically doing computer vision on audio data. Is there a technical reason for that?</p>\n</div>",
      "created_utc": 1678444507.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/jbnq37s/",
      "parent_id": "t3_11ckopj",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-10T02:35:07"
    },
    {
      "id": "jbnqxul",
      "author": "PassNazitaire",
      "body": "I have a small project that includes feeding to chatgpt description of images from profiles. I am struggling to find a free app that lets me automatically caption images. Do you know any? Ideally, I could just infer with a pretrained model locally.",
      "body_html": "<div class=\"md\"><p>I have a small project that includes feeding to chatgpt description of images from profiles. I am struggling to find a free app that lets me automatically caption images. Do you know any? Ideally, I could just infer with a pretrained model locally.</p>\n</div>",
      "created_utc": 1678445209.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/jbnqxul/",
      "parent_id": "t3_11ckopj",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-10T02:46:49"
    },
    {
      "id": "jbnsenx",
      "author": "Accomplished_Hunt332",
      "body": "Hello guys, \n\nAnyone knows how Microsoft CMT works for double-blind review process?\n\nI made a STUPID mistake of revealing my name on the \"file name\"  of the PDF manuscript. Breaking the anonymity will definitely be a straight desk-reject, and I have NO idea what I could do after this point as submission deadline has passed. \n\nI hope the CMT system automatically strips the original file name to something else before it gets forwarded to reviewers or area chairs, but\n\nI did email the track chairs but they are taking forever to respond. \n\nThanks a lot in advance!",
      "body_html": "<div class=\"md\"><p>Hello guys, </p>\n\n<p>Anyone knows how Microsoft CMT works for double-blind review process?</p>\n\n<p>I made a STUPID mistake of revealing my name on the &quot;file name&quot;  of the PDF manuscript. Breaking the anonymity will definitely be a straight desk-reject, and I have NO idea what I could do after this point as submission deadline has passed. </p>\n\n<p>I hope the CMT system automatically strips the original file name to something else before it gets forwarded to reviewers or area chairs, but</p>\n\n<p>I did email the track chairs but they are taking forever to respond. </p>\n\n<p>Thanks a lot in advance!</p>\n</div>",
      "created_utc": 1678446373.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/jbnsenx/",
      "parent_id": "t3_11ckopj",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-10T03:06:13"
    },
    {
      "id": "jbr5vsu",
      "author": "OkConsideration5245",
      "body": "Hello guys, we're planning a reverse vending machine for our project and we want to use ML in the opening and cloaing of its door by classifying if its plastic bottle or paper. \n\nMy question is, can Teachable Machine by google do the job? We don't have great background in ml. Most literature uses cnn and yolo. We plan to deploy it into a raspberry pi module. Or do you have any module in mind that costs lower and cn run this? Thank you in advance. \n\n\n\nSorry if i make mistakes with my statements above, as i said, we dunno much about ML. I hope you can share a thing or two of your knowledge with us. Thank you againðŸ’š",
      "body_html": "<div class=\"md\"><p>Hello guys, we&#39;re planning a reverse vending machine for our project and we want to use ML in the opening and cloaing of its door by classifying if its plastic bottle or paper. </p>\n\n<p>My question is, can Teachable Machine by google do the job? We don&#39;t have great background in ml. Most literature uses cnn and yolo. We plan to deploy it into a raspberry pi module. Or do you have any module in mind that costs lower and cn run this? Thank you in advance. </p>\n\n<p>Sorry if i make mistakes with my statements above, as i said, we dunno much about ML. I hope you can share a thing or two of your knowledge with us. Thank you againðŸ’š</p>\n</div>",
      "created_utc": 1678499467.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/jbr5vsu/",
      "parent_id": "t3_11ckopj",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-10T17:51:07"
    },
    {
      "id": "jbrdp5s",
      "author": "Ok-Kitchen4623",
      "body": "Hi guys! I am currently trying out models for purchase prediction. It's about simple models like logistic regression and random forest. \n\nFor this I am supposed to use the data from Comscore Web Behavior Database. Has anyone worked with this before and could possibly help me? \n\nBasically, I want to draw the sample of households (7.000) from the demographics and then add the visits (ss241-252) to the households and the purchases (ptrans).",
      "body_html": "<div class=\"md\"><p>Hi guys! I am currently trying out models for purchase prediction. It&#39;s about simple models like logistic regression and random forest. </p>\n\n<p>For this I am supposed to use the data from Comscore Web Behavior Database. Has anyone worked with this before and could possibly help me? </p>\n\n<p>Basically, I want to draw the sample of households (7.000) from the demographics and then add the visits (ss241-252) to the households and the purchases (ptrans).</p>\n</div>",
      "created_utc": 1678503310.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/jbrdp5s/",
      "parent_id": "t3_11ckopj",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-10T18:55:10"
    },
    {
      "id": "jbrpei8",
      "author": "monouns",
      "body": "How does the learned reward model from PPO fine-tune the GPT3?\r  \n\r  \nAs for the GPT fine-tuning algorithm, it seems like using PPO optimization (I'm not quite sure how this process works?). But isn't it harm the already trained knowledge pre-trained from self-supervised learning of GPT?\r  \n\r  \nPapers such as instrumental GTP and Deep RL Human Preference argue for a human-aligned model. It contemplates how to keep the AI model human-friendly and at the same time not deviate from ethics. Won't RL take the lead in the development of AI ethics technology beyond simple AI algorithms?",
      "body_html": "<div class=\"md\"><p>How does the learned reward model from PPO fine-tune the GPT3?</p>\n\n<p>As for the GPT fine-tuning algorithm, it seems like using PPO optimization (I&#39;m not quite sure how this process works?). But isn&#39;t it harm the already trained knowledge pre-trained from self-supervised learning of GPT?</p>\n\n<p>Papers such as instrumental GTP and Deep RL Human Preference argue for a human-aligned model. It contemplates how to keep the AI model human-friendly and at the same time not deviate from ethics. Won&#39;t RL take the lead in the development of AI ethics technology beyond simple AI algorithms?</p>\n</div>",
      "created_utc": 1678509629.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/jbrpei8/",
      "parent_id": "t3_11ckopj",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-10T20:40:29"
    },
    {
      "id": "jbrr1e6",
      "author": "monouns",
      "body": "past to recent deep learning research focuses on two big categories: Vision and NLP. What do you think about the TimeSeries data domain?",
      "body_html": "<div class=\"md\"><p>past to recent deep learning research focuses on two big categories: Vision and NLP. What do you think about the TimeSeries data domain?</p>\n</div>",
      "created_utc": 1678510602.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/jbrr1e6/",
      "parent_id": "t3_11ckopj",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-10T20:56:42"
    },
    {
      "id": "jbsihi3",
      "author": "-xylon",
      "body": "So, it's the first time I'm managing my own remote GPU machine, and I have a question: in order to train a model there, I can of course install my \"dev package\" (i.e. the code and scripts I used locally to train) there and just run it, then download the model... what I was wondering is, is there some better way to do this so I don't need to clone the code, just \"send the model over the network\" or something like that to that machine, train there, and get the model back.   \nIn other words, how to set up a \"training server\" by myself? Any help is greatly appreciated.  \n\n\nI use TensorFlow btw.",
      "body_html": "<div class=\"md\"><p>So, it&#39;s the first time I&#39;m managing my own remote GPU machine, and I have a question: in order to train a model there, I can of course install my &quot;dev package&quot; (i.e. the code and scripts I used locally to train) there and just run it, then download the model... what I was wondering is, is there some better way to do this so I don&#39;t need to clone the code, just &quot;send the model over the network&quot; or something like that to that machine, train there, and get the model back.<br/>\nIn other words, how to set up a &quot;training server&quot; by myself? Any help is greatly appreciated.  </p>\n\n<p>I use TensorFlow btw.</p>\n</div>",
      "created_utc": 1678531877.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/jbsihi3/",
      "parent_id": "t3_11ckopj",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-11T02:51:17"
    },
    {
      "id": "jbt1etb",
      "author": "EMilyxoxo12",
      "body": "What role does AI play in cyber security, is it possible to create apps with 0 technical bugs as the program? or scan websites thoroughly for vulnerabilities? im sure these do exist but i could not find any valuable info.",
      "body_html": "<div class=\"md\"><p>What role does AI play in cyber security, is it possible to create apps with 0 technical bugs as the program? or scan websites thoroughly for vulnerabilities? im sure these do exist but i could not find any valuable info.</p>\n</div>",
      "created_utc": 1678544244.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/jbt1etb/",
      "parent_id": "t3_11ckopj",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-11T06:17:24"
    },
    {
      "id": "jbtcpoq",
      "author": "Raiden7732",
      "body": "What is the best method of fine tune training GPT-3x on variations of code? Iâ€™m not exactly sure how to parse and annotate the deltas of the code to teach the model about the natural language prompt.",
      "body_html": "<div class=\"md\"><p>What is the best method of fine tune training GPT-3x on variations of code? Iâ€™m not exactly sure how to parse and annotate the deltas of the code to teach the model about the natural language prompt.</p>\n</div>",
      "created_utc": 1678549374.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/jbtcpoq/",
      "parent_id": "t3_11ckopj",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-11T07:42:54"
    },
    {
      "id": "jbtkxs5",
      "author": "ahrzb",
      "body": "With ChatGPT (and generally LLMs) we can empirically observe that them being verbose and explaining something step by step helps them perform better.\n\nIs there any research that allows them to have some sort of inner chatter before giving the output?\n\nSpecially this can lead them to be turing complete (assuming context length is long enough), they will be able to so arbitrary long computation given some input.\n\nFor example allow a specific pair if tags that marks a section of output to be hidden from the user.",
      "body_html": "<div class=\"md\"><p>With ChatGPT (and generally LLMs) we can empirically observe that them being verbose and explaining something step by step helps them perform better.</p>\n\n<p>Is there any research that allows them to have some sort of inner chatter before giving the output?</p>\n\n<p>Specially this can lead them to be turing complete (assuming context length is long enough), they will be able to so arbitrary long computation given some input.</p>\n\n<p>For example allow a specific pair if tags that marks a section of output to be hidden from the user.</p>\n</div>",
      "created_utc": 1678552858.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/jbtkxs5/",
      "parent_id": "t3_11ckopj",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-11T08:40:58"
    },
    {
      "id": "jub0245",
      "author": "nsundar",
      "body": "NooB question: is the context size a hardcoded parameter for each LLM? Is there any way to reduce the context size after training, as a way to consume less RAM or improve inference time (possibly at the expense of accuracy)? \n\nP.S.: I know that increasing the context size after training is not a thing.",
      "body_html": "<div class=\"md\"><p>NooB question: is the context size a hardcoded parameter for each LLM? Is there any way to reduce the context size after training, as a way to consume less RAM or improve inference time (possibly at the expense of accuracy)? </p>\n\n<p>P.S.: I know that increasing the context size after training is not a thing.</p>\n</div>",
      "created_utc": 1690866639.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/jub0245/",
      "parent_id": "t3_11ckopj",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-07-31T22:10:39"
    },
    {
      "id": "jaf8b7x",
      "author": "sfhsrtjn",
      "body": "I would say yes:\n\n>A key parameter of a Large Language Model (LLM) is its context window, the number of text tokens that it can process in a forward pass. Current LLM architectures limit context window size â€” typically up to 2048 tokens â€” because the global nature of the attention mechanism imposes computational costs quadratic in context length. This presents an obstacle to use cases where the LLM needs to process a lot of text, e.g., tackling tasks that require long inputs, considering large sets of retrieved documents for open-book question answering, or performing in-context learning when the desired inputâ€“output relationship cannot adequately be characterized within the con-\ntext window.\n\n(source: [\nParallel Context Windows Improve In-Context Learning of Large Language Models](https://arxiv.org/abs/2212.10947) - arXiv  Dec 2022)",
      "body_html": "<div class=\"md\"><p>I would say yes:</p>\n\n<blockquote>\n<p>A key parameter of a Large Language Model (LLM) is its context window, the number of text tokens that it can process in a forward pass. Current LLM architectures limit context window size â€” typically up to 2048 tokens â€” because the global nature of the attention mechanism imposes computational costs quadratic in context length. This presents an obstacle to use cases where the LLM needs to process a lot of text, e.g., tackling tasks that require long inputs, considering large sets of retrieved documents for open-book question answering, or performing in-context learning when the desired inputâ€“output relationship cannot adequately be characterized within the con-\ntext window.</p>\n</blockquote>\n\n<p>(source: <a href=\"https://arxiv.org/abs/2212.10947\">\nParallel Context Windows Improve In-Context Learning of Large Language Models</a> - arXiv  Dec 2022)</p>\n</div>",
      "created_utc": 1677630247.0,
      "score": 2,
      "ups": 2,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/jaf8b7x/",
      "parent_id": "t1_jac6zke",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-28T16:24:07"
    },
    {
      "id": "jb9ol2x",
      "author": "trnka",
      "body": "That's a really interesting finding! And worth sharing more broadly if you get some more stats on it, such as a dedicated post or blog post.\n\nModern Windows has \"game mode\" which detects running games and changes the system performance somehow. Nvidia drivers also do something to adjust configuration by game I think. Maybe that's helping? It's also plausible that something else you're doing during normal training is slowing things down. Or it's possible that a random seed somewhere is affecting AutoKeras in a major way. Either way I'd suggest doing more controlled testing as you experiment.",
      "body_html": "<div class=\"md\"><p>That&#39;s a really interesting finding! And worth sharing more broadly if you get some more stats on it, such as a dedicated post or blog post.</p>\n\n<p>Modern Windows has &quot;game mode&quot; which detects running games and changes the system performance somehow. Nvidia drivers also do something to adjust configuration by game I think. Maybe that&#39;s helping? It&#39;s also plausible that something else you&#39;re doing during normal training is slowing things down. Or it&#39;s possible that a random seed somewhere is affecting AutoKeras in a major way. Either way I&#39;d suggest doing more controlled testing as you experiment.</p>\n</div>",
      "created_utc": 1678197864.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/jb9ol2x/",
      "parent_id": "t1_jb6bmrr",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-07T06:04:24"
    },
    {
      "id": "jabc9bt",
      "author": "Donno_Nemore",
      "body": "For an internship you should be asking details about what exactly you will be doing. FAANG or no FAANG, if you can't speak to an accomplishment at the end of your internship what are you going to say when an interviewer asks for details?\n\nIs the proposed project a supervised or unsupervised learning task? If supervised, do they have data? Have they tried something and you will be continuing? You don't want to spend 3-months writing web scrapers and data labelers and never see a line of ML code.",
      "body_html": "<div class=\"md\"><p>For an internship you should be asking details about what exactly you will be doing. FAANG or no FAANG, if you can&#39;t speak to an accomplishment at the end of your internship what are you going to say when an interviewer asks for details?</p>\n\n<p>Is the proposed project a supervised or unsupervised learning task? If supervised, do they have data? Have they tried something and you will be continuing? You don&#39;t want to spend 3-months writing web scrapers and data labelers and never see a line of ML code.</p>\n</div>",
      "created_utc": 1677560111.0,
      "score": 2,
      "ups": 2,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/jabc9bt/",
      "parent_id": "t1_jab8xnx",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-27T20:55:11"
    },
    {
      "id": "jacjiop",
      "author": "trnka",
      "body": "Former hiring manager here. It really depends on what you do in the internship and how you communicate it in your resume and interviews. There are situations in which a national lab internship would be more valuable experience than FAANG, and vice versa. It's more likely that a FAANG internship would be relevant in industry, I just can't say how much more likely because I don't have a large enough sample size to say.\n\nAny coding internship is definitely a plus when reviewing a junior candidate's resume though.",
      "body_html": "<div class=\"md\"><p>Former hiring manager here. It really depends on what you do in the internship and how you communicate it in your resume and interviews. There are situations in which a national lab internship would be more valuable experience than FAANG, and vice versa. It&#39;s more likely that a FAANG internship would be relevant in industry, I just can&#39;t say how much more likely because I don&#39;t have a large enough sample size to say.</p>\n\n<p>Any coding internship is definitely a plus when reviewing a junior candidate&#39;s resume though.</p>\n</div>",
      "created_utc": 1677591413.0,
      "score": 2,
      "ups": 2,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/jacjiop/",
      "parent_id": "t1_jab8xnx",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-28T05:36:53"
    },
    {
      "id": "jbbpx90",
      "author": "G_fucking_G",
      "body": "For the first point: \n\nhttps://nicholas.carlini.com/writing/2018/adversarial-machine-learning-reading-list.html\n\n\nNicolas Carlini has a great website and is one of the most known researchers in Adv. Examples.",
      "body_html": "<div class=\"md\"><p>For the first point: </p>\n\n<p><a href=\"https://nicholas.carlini.com/writing/2018/adversarial-machine-learning-reading-list.html\">https://nicholas.carlini.com/writing/2018/adversarial-machine-learning-reading-list.html</a></p>\n\n<p>Nicolas Carlini has a great website and is one of the most known researchers in Adv. Examples.</p>\n</div>",
      "created_utc": 1678226582.0,
      "score": 2,
      "ups": 2,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/jbbpx90/",
      "parent_id": "t1_jagdtsm",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-07T14:03:02"
    },
    {
      "id": "jamcmmf",
      "author": "rm-rf_",
      "body": "Great question, I just posted about this myself: https://www.reddit.com/r/MachineLearning/comments/11g306o/d_have_there_been_any_significant_breakthroughs/",
      "body_html": "<div class=\"md\"><p>Great question, I just posted about this myself: <a href=\"https://www.reddit.com/r/MachineLearning/comments/11g306o/d_have_there_been_any_significant_breakthroughs/\">https://www.reddit.com/r/MachineLearning/comments/11g306o/d_have_there_been_any_significant_breakthroughs/</a></p>\n</div>",
      "created_utc": 1677764530.0,
      "score": 3,
      "ups": 3,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/jamcmmf/",
      "parent_id": "t1_jaifg1d",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-02T05:42:10"
    },
    {
      "id": "janmwt5",
      "author": "trnka",
      "body": "You might try putting feature selection in your pipeline and/or using some basic pruning on the RF like minimum samples split.\n\nIf that's not an option, I'd spin up a beefy notebook in Sagemaker and run it there, then export the model as a pickle file to be used on another machine.\n\nHope this helps!",
      "body_html": "<div class=\"md\"><p>You might try putting feature selection in your pipeline and/or using some basic pruning on the RF like minimum samples split.</p>\n\n<p>If that&#39;s not an option, I&#39;d spin up a beefy notebook in Sagemaker and run it there, then export the model as a pickle file to be used on another machine.</p>\n\n<p>Hope this helps!</p>\n</div>",
      "created_utc": 1677783554.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/janmwt5/",
      "parent_id": "t1_jaliayp",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-02T10:59:14"
    },
    {
      "id": "jaspqos",
      "author": "cd_1999",
      "body": "If you're pre-calculating the one-hot encoding (actually creating a dataframe with 1 and 0), then don't. Any reasonable RF implementation will have a better way to handle categorical variables and will consume less memory. 1 million isn't a lagre n so I doubt you'll have issues. You can look into training RF with batches if you like too.\n\n1. I recommend that, once you mature your workflow, you have a script for training and one for predict / inference\n\n2 and 3. You can certainly save the model. Look for the Dill package, it can pickle more stuff. There are other ways to save models that have different trade-offs",
      "body_html": "<div class=\"md\"><p>If you&#39;re pre-calculating the one-hot encoding (actually creating a dataframe with 1 and 0), then don&#39;t. Any reasonable RF implementation will have a better way to handle categorical variables and will consume less memory. 1 million isn&#39;t a lagre n so I doubt you&#39;ll have issues. You can look into training RF with batches if you like too.</p>\n\n<ol>\n<li>I recommend that, once you mature your workflow, you have a script for training and one for predict / inference</li>\n</ol>\n\n<p>2 and 3. You can certainly save the model. Look for the Dill package, it can pickle more stuff. There are other ways to save models that have different trade-offs</p>\n</div>",
      "created_utc": 1677873855.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/jaspqos/",
      "parent_id": "t1_jaliayp",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-03T12:04:15"
    },
    {
      "id": "jbk425w",
      "author": "Clicketrie",
      "body": "Disclaimer, I work for Comet. But for my personal usage, ClearML doesn't have the data management capabilities, and I rely on creating a data artifact and tracking the data lineage so that I know which data is the latest/correct. They're all great tools, but also mlflow doesn't have the graphing capabilities that CometML has..  it's just easier to get graphs of precision, recall, map, and loss by epoch right out of the box to make comparisons.",
      "body_html": "<div class=\"md\"><p>Disclaimer, I work for Comet. But for my personal usage, ClearML doesn&#39;t have the data management capabilities, and I rely on creating a data artifact and tracking the data lineage so that I know which data is the latest/correct. They&#39;re all great tools, but also mlflow doesn&#39;t have the graphing capabilities that CometML has..  it&#39;s just easier to get graphs of precision, recall, map, and loss by epoch right out of the box to make comparisons.</p>\n</div>",
      "created_utc": 1678380796.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/jbk425w/",
      "parent_id": "t1_jbicird",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-09T08:53:16"
    },
    {
      "id": "ja4a16l",
      "author": "Gawkies",
      "body": "for theory i would highly recommend pattern recognition and machine learning by Christopher M. bishop [found here](https://www.microsoft.com/en-us/research/uploads/prod/2006/01/Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf)\n\nit is purely theory though as i said but it does teach a lot, was my main source when i dove deep into machine learning class during my first semester in uni and it got me through on the first attempt\n\nbest of luck!",
      "body_html": "<div class=\"md\"><p>for theory i would highly recommend pattern recognition and machine learning by Christopher M. bishop <a href=\"https://www.microsoft.com/en-us/research/uploads/prod/2006/01/Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf\">found here</a></p>\n\n<p>it is purely theory though as i said but it does teach a lot, was my main source when i dove deep into machine learning class during my first semester in uni and it got me through on the first attempt</p>\n\n<p>best of luck!</p>\n</div>",
      "created_utc": 1677438273.0,
      "score": 2,
      "ups": 2,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/ja4a16l/",
      "parent_id": "t1_ja3mycj",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-26T11:04:33"
    },
    {
      "id": "ja4oooo",
      "author": "lexsiga",
      "body": "www.serverless-ml.org\nBest thing about putting ml in an actual operational form. Not a modeling course tho; more mlops-ish",
      "body_html": "<div class=\"md\"><p><a href=\"http://www.serverless-ml.org\">www.serverless-ml.org</a>\nBest thing about putting ml in an actual operational form. Not a modeling course tho; more mlops-ish</p>\n</div>",
      "created_utc": 1677444124.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/ja4oooo/",
      "parent_id": "t1_ja3mycj",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-26T12:42:04"
    },
    {
      "id": "ja4r56t",
      "author": "Disastrous-War-9675",
      "body": "What's the training MAE? You can check if your model is expressive enough by intentionally overfitting the data (turn off regularizers for a more accurate picture). If it cannot overfit, you need more neurons.\n\nOptimizers and hparams are really important, as stated in other responses. Adam usually works best but plain old SGD is fine in most of the cases, it may just be a bit slow.\n\nDon't overcomplicate things. Start with the simplest approach and add things to it until it works. For instance, even though GeLU should be just fine, I'd start with the simplest rectifier, ReLU.\n\nLastly, you're randomly sampling to generate the dataset but that's probably not ideal. What you want is sobol/quasi random sampling (sampling in a way that the samples cover the domain of interest quickly and evenly, so that each sample has something to teach to the network). Now, if your function is very weird, for instance discrete/discontinuous, this might not matter. This would benefit you the most if your function has some nice properties like being lipschitz continuous, have low total variation, etc, since sampling points uniformly at random would lead to some samples being quite close to one another and they wouldn't carry much extra information.\n\nEdit: It's possible to model any reasonably behaving function with an arbitrary width/depth (can be one at a time) neural network with specific activation functions (i.e., ReLU works, along with an infinite class of functions with specific properties). This is not of much use from a practical standpoint, keyword being the \"arbitrary\" part. For the bounded with+depth case you need customly built activation functions which are not used in practice. All in all, the universal approximation theorem you're referring to does not apply to your case since your network does not have the necessary properties. This does not mean you cannot model your function, you probably can. There's just not any theoritical guarantee, but don't worry, every single non-theoritical ML paper you've seen uses networks violating these constraints and they're modeling hard functions just fine.",
      "body_html": "<div class=\"md\"><p>What&#39;s the training MAE? You can check if your model is expressive enough by intentionally overfitting the data (turn off regularizers for a more accurate picture). If it cannot overfit, you need more neurons.</p>\n\n<p>Optimizers and hparams are really important, as stated in other responses. Adam usually works best but plain old SGD is fine in most of the cases, it may just be a bit slow.</p>\n\n<p>Don&#39;t overcomplicate things. Start with the simplest approach and add things to it until it works. For instance, even though GeLU should be just fine, I&#39;d start with the simplest rectifier, ReLU.</p>\n\n<p>Lastly, you&#39;re randomly sampling to generate the dataset but that&#39;s probably not ideal. What you want is sobol/quasi random sampling (sampling in a way that the samples cover the domain of interest quickly and evenly, so that each sample has something to teach to the network). Now, if your function is very weird, for instance discrete/discontinuous, this might not matter. This would benefit you the most if your function has some nice properties like being lipschitz continuous, have low total variation, etc, since sampling points uniformly at random would lead to some samples being quite close to one another and they wouldn&#39;t carry much extra information.</p>\n\n<p>Edit: It&#39;s possible to model any reasonably behaving function with an arbitrary width/depth (can be one at a time) neural network with specific activation functions (i.e., ReLU works, along with an infinite class of functions with specific properties). This is not of much use from a practical standpoint, keyword being the &quot;arbitrary&quot; part. For the bounded with+depth case you need customly built activation functions which are not used in practice. All in all, the universal approximation theorem you&#39;re referring to does not apply to your case since your network does not have the necessary properties. This does not mean you cannot model your function, you probably can. There&#39;s just not any theoritical guarantee, but don&#39;t worry, every single non-theoritical ML paper you&#39;ve seen uses networks violating these constraints and they&#39;re modeling hard functions just fine.</p>\n</div>",
      "created_utc": 1677445111.0,
      "score": 3,
      "ups": 3,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/ja4r56t/",
      "parent_id": "t1_ja42bzg",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": true,
      "distinguished": null,
      "timestamp": "2023-02-26T12:58:31"
    },
    {
      "id": "ja48vci",
      "author": "Gawkies",
      "body": "you mighy be stuck in a local minimum. \n\n tune your learning rate, batch size, weight decay, momentum etc... \ntry changing the activation function\n\ngenerally speaking, its very difficult to figure out why a network behaves a certain way so you have a lot of fine tuning to do until you get a better result",
      "body_html": "<div class=\"md\"><p>you mighy be stuck in a local minimum. </p>\n\n<p>tune your learning rate, batch size, weight decay, momentum etc... \ntry changing the activation function</p>\n\n<p>generally speaking, its very difficult to figure out why a network behaves a certain way so you have a lot of fine tuning to do until you get a better result</p>\n</div>",
      "created_utc": 1677437814.0,
      "score": 2,
      "ups": 2,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/ja48vci/",
      "parent_id": "t1_ja42bzg",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-26T10:56:54"
    },
    {
      "id": "ja4rlhf",
      "author": "literum",
      "body": "I would increase the number of neurons. (ex 80 160 80). You can model any function, but you need enough expressive power. Your model is most likely underfitting.",
      "body_html": "<div class=\"md\"><p>I would increase the number of neurons. (ex 80 160 80). You can model any function, but you need enough expressive power. Your model is most likely underfitting.</p>\n</div>",
      "created_utc": 1677445297.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/ja4rlhf/",
      "parent_id": "t1_ja42bzg",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-26T13:01:37"
    },
    {
      "id": "ja6ev56",
      "author": "xxgetrektxx2",
      "body": "1. Python, can't beat the library support.\n2. Not really a course, but Andrej Karpathy, previously the director of AI at Tesla, has a great introduction to neural networks on [YouTube](https://youtu.be/VMj-3S1tku0).",
      "body_html": "<div class=\"md\"><ol>\n<li>Python, can&#39;t beat the library support.</li>\n<li>Not really a course, but Andrej Karpathy, previously the director of AI at Tesla, has a great introduction to neural networks on <a href=\"https://youtu.be/VMj-3S1tku0\">YouTube</a>.</li>\n</ol>\n</div>",
      "created_utc": 1677472259.0,
      "score": 3,
      "ups": 3,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/ja6ev56/",
      "parent_id": "t1_ja4jedq",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-26T20:30:59"
    },
    {
      "id": "ja7bl2u",
      "author": null,
      "body": "I started learning on Codecademy (pricey but worth it) and Datacamp (affordable and worth it) and they both encourage Python because of the different libraries.",
      "body_html": "<div class=\"md\"><p>I started learning on Codecademy (pricey but worth it) and Datacamp (affordable and worth it) and they both encourage Python because of the different libraries.</p>\n</div>",
      "created_utc": 1677497030.0,
      "score": 2,
      "ups": 2,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/ja7bl2u/",
      "parent_id": "t1_ja4jedq",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-27T03:23:50"
    },
    {
      "id": "ja87j3h",
      "author": "prtt",
      "body": "Python and [FastAI](https://course.fast.ai/).\n\nGood luck on your journey!",
      "body_html": "<div class=\"md\"><p>Python and <a href=\"https://course.fast.ai/\">FastAI</a>.</p>\n\n<p>Good luck on your journey!</p>\n</div>",
      "created_utc": 1677513447.0,
      "score": 2,
      "ups": 2,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/ja87j3h/",
      "parent_id": "t1_ja4jedq",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-27T07:57:27"
    },
    {
      "id": "jablki7",
      "author": "Particular_Message46",
      "body": "There are pitch shifting tools for music production that do this quite well. They don't need any deep learning.",
      "body_html": "<div class=\"md\"><p>There are pitch shifting tools for music production that do this quite well. They don&#39;t need any deep learning.</p>\n</div>",
      "created_utc": 1677566156.0,
      "score": 2,
      "ups": 2,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/jablki7/",
      "parent_id": "t1_ja881a3",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-27T22:35:56"
    },
    {
      "id": "jac7xjl",
      "author": "spruce5637",
      "body": "You might also want to look into the keyword \"voice conversion\". For papers you can start at [Papers with Code](https://paperswithcode.com/task/voice-conversion) . You may also try [ESPNet](https://github.com/espnet/espnet)or [Coqui](https://coqui.ai/blog/tts/yourtts-zero-shot-text-synthesis-low-resource-languages) for a larger library of code around speech-related tasks (incl. voice conversion).\n\nMany companies are also selling their voice conversion technology as a product, a quick google search gave me [Respeecher](https://www.respeecher.com/) and [Resemble.ai](https://www.resemble.ai/speech-to-speech/)",
      "body_html": "<div class=\"md\"><p>You might also want to look into the keyword &quot;voice conversion&quot;. For papers you can start at <a href=\"https://paperswithcode.com/task/voice-conversion\">Papers with Code</a> . You may also try <a href=\"https://github.com/espnet/espnet\">ESPNet</a>or <a href=\"https://coqui.ai/blog/tts/yourtts-zero-shot-text-synthesis-low-resource-languages\">Coqui</a> for a larger library of code around speech-related tasks (incl. voice conversion).</p>\n\n<p>Many companies are also selling their voice conversion technology as a product, a quick google search gave me <a href=\"https://www.respeecher.com/\">Respeecher</a> and <a href=\"https://www.resemble.ai/speech-to-speech/\">Resemble.ai</a></p>\n</div>",
      "created_utc": 1677584496.0,
      "score": 2,
      "ups": 2,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/jac7xjl/",
      "parent_id": "t1_ja881a3",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-28T03:41:36"
    },
    {
      "id": "ja9j1oy",
      "author": "ai_ai_captain",
      "body": "Smaller models are faster and cheaper to run",
      "body_html": "<div class=\"md\"><p>Smaller models are faster and cheaper to run</p>\n</div>",
      "created_utc": 1677531568.0,
      "score": 3,
      "ups": 3,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/ja9j1oy/",
      "parent_id": "t1_ja88lqt",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-27T12:59:28"
    },
    {
      "id": "jaig5hz",
      "author": "shoegraze",
      "body": "You have to have some decent level of understanding to use ML in the real world, but the deepest knowledge comes in research positions. It is \"profitable\" in that it's a tech field and can be used to generate revenues, yeah. Being a data scientist or a machine learning engineer generally pays the same as being a software engineer in industry",
      "body_html": "<div class=\"md\"><p>You have to have some decent level of understanding to use ML in the real world, but the deepest knowledge comes in research positions. It is &quot;profitable&quot; in that it&#39;s a tech field and can be used to generate revenues, yeah. Being a data scientist or a machine learning engineer generally pays the same as being a software engineer in industry</p>\n</div>",
      "created_utc": 1677692975.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/jaig5hz/",
      "parent_id": "t1_ja9ujc4",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-01T09:49:35"
    },
    {
      "id": "japjtnh",
      "author": "Melodic_Stomach_2704",
      "body": "Yes, feed that test set into your trained model, count the total no. of correct prediction. acc=no. of correct prediction/test set size",
      "body_html": "<div class=\"md\"><p>Yes, feed that test set into your trained model, count the total no. of correct prediction. acc=no. of correct prediction/test set size</p>\n</div>",
      "created_utc": 1677812627.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/japjtnh/",
      "parent_id": "t1_jaeghdf",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-02T19:03:47"
    },
    {
      "id": "japj3mi",
      "author": "Melodic_Stomach_2704",
      "body": "Think about a problem that you can solve with CV and build project around it.",
      "body_html": "<div class=\"md\"><p>Think about a problem that you can solve with CV and build project around it.</p>\n</div>",
      "created_utc": 1677812278.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/japj3mi/",
      "parent_id": "t1_jafzycj",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-02T18:57:58"
    },
    {
      "id": "jbgvigd",
      "author": "bgighjigftuik",
      "body": "Jax is not intended to be learnt unless you work at Google, or at one of the teams who is developing the library.\n\nThat's why after almost 5 years, Jax is still highly irrelevant",
      "body_html": "<div class=\"md\"><p>Jax is not intended to be learnt unless you work at Google, or at one of the teams who is developing the library.</p>\n\n<p>That&#39;s why after almost 5 years, Jax is still highly irrelevant</p>\n</div>",
      "created_utc": 1678317268.0,
      "score": 0,
      "ups": 0,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/jbgvigd/",
      "parent_id": "t1_jamcipn",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-08T15:14:28"
    },
    {
      "id": "janmbfe",
      "author": "trnka",
      "body": "Personally I like Colab. I've heard the paid version is worth it but I haven't tried it yet.\n\nIf you have a PC that you already use then a dedicated GPU might be worthwhile, but you might face some challenges now and then with getting the right drivers and cuda versions.",
      "body_html": "<div class=\"md\"><p>Personally I like Colab. I&#39;ve heard the paid version is worth it but I haven&#39;t tried it yet.</p>\n\n<p>If you have a PC that you already use then a dedicated GPU might be worthwhile, but you might face some challenges now and then with getting the right drivers and cuda versions.</p>\n</div>",
      "created_utc": 1677783293.0,
      "score": 2,
      "ups": 2,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/janmbfe/",
      "parent_id": "t1_jan6tp3",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-02T10:54:53"
    },
    {
      "id": "japh1xk",
      "author": "Melodic_Stomach_2704",
      "body": "We mostly SSH into our GPU server and do the training there.",
      "body_html": "<div class=\"md\"><p>We mostly SSH into our GPU server and do the training there.</p>\n</div>",
      "created_utc": 1677811311.0,
      "score": 2,
      "ups": 2,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/japh1xk/",
      "parent_id": "t1_jan6tp3",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-02T18:41:51"
    },
    {
      "id": "japgo5s",
      "author": "Melodic_Stomach_2704",
      "body": "Have you considered using NER? It's a NLP technique which can classify such named entity. If required you can train your own model for NER using libraries like spacy.",
      "body_html": "<div class=\"md\"><p>Have you considered using NER? It&#39;s a NLP technique which can classify such named entity. If required you can train your own model for NER using libraries like spacy.</p>\n</div>",
      "created_utc": 1677811137.0,
      "score": 2,
      "ups": 2,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/japgo5s/",
      "parent_id": "t1_jao7kkz",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-02T18:38:57"
    },
    {
      "id": "jar7owh",
      "author": "trnka",
      "body": "Well the model's learned *something* because validation loss and accuracy do improve at first. The graphs look like overfitting to me -- training metrics are still improving but not validation. Increasing regularization is likely to help, whether that's adding dropout, increasing dropout, or adding a little L2 regularization. Data augmentation like rotation, zoom, skew, etc may also help.\n\nYou might also try decreasing the number of parameters in the network, especially if it's slow to train. That usually improves generalization too.",
      "body_html": "<div class=\"md\"><p>Well the model&#39;s learned <em>something</em> because validation loss and accuracy do improve at first. The graphs look like overfitting to me -- training metrics are still improving but not validation. Increasing regularization is likely to help, whether that&#39;s adding dropout, increasing dropout, or adding a little L2 regularization. Data augmentation like rotation, zoom, skew, etc may also help.</p>\n\n<p>You might also try decreasing the number of parameters in the network, especially if it&#39;s slow to train. That usually improves generalization too.</p>\n</div>",
      "created_utc": 1677851954.0,
      "score": 2,
      "ups": 2,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/jar7owh/",
      "parent_id": "t1_jaqnmr7",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-03T05:59:14"
    },
    {
      "id": "jb26bc6",
      "author": "Particular_Message46",
      "body": "Datasets that record human activity over time, e.g. speech or body motion:  \n\\- regression: predict the speech or body pose at a near future position  \n\\- classification:  classify if the speech seems happy/sad, or the body motion is young/old person  \n\n\nFor an image dataset, classify cat/dog, and regress to do inpainting e.g. predict the bottom half of imag from the top half,  e.g. do texture synthesis seeded from part of the image  \n\n\nIn the regression cases ideally you should be thinking in terms of predicting a distribution over possibilities",
      "body_html": "<div class=\"md\"><p>Datasets that record human activity over time, e.g. speech or body motion:<br/>\n- regression: predict the speech or body pose at a near future position<br/>\n- classification:  classify if the speech seems happy/sad, or the body motion is young/old person  </p>\n\n<p>For an image dataset, classify cat/dog, and regress to do inpainting e.g. predict the bottom half of imag from the top half,  e.g. do texture synthesis seeded from part of the image  </p>\n\n<p>In the regression cases ideally you should be thinking in terms of predicting a distribution over possibilities</p>\n</div>",
      "created_utc": 1678051820.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/jb26bc6/",
      "parent_id": "t1_jau5o2r",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-05T13:30:20"
    },
    {
      "id": "jb48qdn",
      "author": "Donno_Nemore",
      "body": "One consideration is that an illegal action is still an action. Such an action would have a very low score.\n\nAnother consideration is that a separate algorithm to verify move legality can be used to ensure only legal action are explored in play.",
      "body_html": "<div class=\"md\"><p>One consideration is that an illegal action is still an action. Such an action would have a very low score.</p>\n\n<p>Another consideration is that a separate algorithm to verify move legality can be used to ensure only legal action are explored in play.</p>\n</div>",
      "created_utc": 1678092288.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/jb48qdn/",
      "parent_id": "t1_jawe6j4",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-06T00:44:48"
    },
    {
      "id": "jb1ogoe",
      "author": "trnka",
      "body": "That's very common! It's often called a stratified split.",
      "body_html": "<div class=\"md\"><p>That&#39;s very common! It&#39;s often called a stratified split.</p>\n</div>",
      "created_utc": 1678044395.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/jb1ogoe/",
      "parent_id": "t1_jb0ks51",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-05T11:26:35"
    },
    {
      "id": "jbj3jle",
      "author": "ggf31416",
      "body": "It probably broke rule 2 \"Make your post clear and comprehensive\". Also, it may be better suited for r/MLQuestions.",
      "body_html": "<div class=\"md\"><p>It probably broke rule 2 &quot;Make your post clear and comprehensive&quot;. Also, it may be better suited for <a href=\"/r/MLQuestions\">r/MLQuestions</a>.</p>\n</div>",
      "created_utc": 1678364835.0,
      "score": 2,
      "ups": 2,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/jbj3jle/",
      "parent_id": "t1_jbcjhtb",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-09T04:27:15"
    },
    {
      "id": "jbi4lsz",
      "author": "should_go_work",
      "body": "What follows is going to be more like an ELIUndergrad - suppose you train a powerful enough model on classification data for a long enough time. We observe in practice that the probabilities that this model predicts usually end up being too \"spiky\", i.e. there is some class for which it is predicting a probability very close to 1.\n\nThis usually means the model is \"overconfident\", which can be an especially bad thing when it gets predictions wrong (imagine a sensitive use case like predicting cancer diagnoses). Temperature scaling is one attempt to fix this *after* training, by introducing a single extra parameter T which you use to rescale the model outputs (the logits, not the softmax outputs).\n\nNamely, you set aside a subset of your data to be calibration data, and then you optimize the temperature T such that when you divide all of your model logit predictions (the inputs to the softmax to produce the class probabilities) by T you get as good cross-entropy loss as possible on the calibration data. Intuitively, you can just think of T as a dampening factor on your model outputs; as T -> \\infty, your model just starts predicting randomly (it is completely unsure what the correct class should be), and as T -> 0 your model is becoming ultra confident in a single class. Optimizing T usually corresponds to obtaining a T that is slightly larger than 1, so you decrease your model confidence.",
      "body_html": "<div class=\"md\"><p>What follows is going to be more like an ELIUndergrad - suppose you train a powerful enough model on classification data for a long enough time. We observe in practice that the probabilities that this model predicts usually end up being too &quot;spiky&quot;, i.e. there is some class for which it is predicting a probability very close to 1.</p>\n\n<p>This usually means the model is &quot;overconfident&quot;, which can be an especially bad thing when it gets predictions wrong (imagine a sensitive use case like predicting cancer diagnoses). Temperature scaling is one attempt to fix this <em>after</em> training, by introducing a single extra parameter T which you use to rescale the model outputs (the logits, not the softmax outputs).</p>\n\n<p>Namely, you set aside a subset of your data to be calibration data, and then you optimize the temperature T such that when you divide all of your model logit predictions (the inputs to the softmax to produce the class probabilities) by T you get as good cross-entropy loss as possible on the calibration data. Intuitively, you can just think of T as a dampening factor on your model outputs; as T -&gt; \\infty, your model just starts predicting randomly (it is completely unsure what the correct class should be), and as T -&gt; 0 your model is becoming ultra confident in a single class. Optimizing T usually corresponds to obtaining a T that is slightly larger than 1, so you decrease your model confidence.</p>\n</div>",
      "created_utc": 1678338402.0,
      "score": 2,
      "ups": 2,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/jbi4lsz/",
      "parent_id": "t1_jbeiur5",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-08T21:06:42"
    },
    {
      "id": "jbguvuc",
      "author": "bgighjigftuik",
      "body": "We can't actually wrap our human head around ir, bur trust me: all that's happening is just interpolation. It may not look like it, bug that's all that is happening. Actual reasoning will not come from a backpropagation nor an attention mechanism",
      "body_html": "<div class=\"md\"><p>We can&#39;t actually wrap our human head around ir, bur trust me: all that&#39;s happening is just interpolation. It may not look like it, bug that&#39;s all that is happening. Actual reasoning will not come from a backpropagation nor an attention mechanism</p>\n</div>",
      "created_utc": 1678317001.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/jbguvuc/",
      "parent_id": "t1_jbfrxjy",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-08T15:10:01"
    },
    {
      "id": "jbk1l8c",
      "author": "beewally",
      "body": "https://youtu.be/jGwO_UgTS7I\nTempted to watch this Stanford class - over 20 hours. Unless someone has something better or thinks that would be too deep since Iâ€™m only supporting ML engineersâ€¦",
      "body_html": "<div class=\"md\"><p><a href=\"https://youtu.be/jGwO_UgTS7I\">https://youtu.be/jGwO_UgTS7I</a>\nTempted to watch this Stanford class - over 20 hours. Unless someone has something better or thinks that would be too deep since Iâ€™m only supporting ML engineersâ€¦</p>\n</div>",
      "created_utc": 1678379889.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/jbk1l8c/",
      "parent_id": "t1_jbk1293",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-09T08:38:09"
    },
    {
      "id": "jub1pqr",
      "author": "nsundar",
      "body": "This combines several very broad questions in one, so I'll just pick the first one.\n\nCybersecurity involves analyzing massive amounts of data  (network traffic, executable files, container images, host/cluster config, etc.) for solving problems or making decisions (e.g., does this file contain malware, does this email include phishing attempts) in a way that is autonomous (we cannot afford manual decisions per-packet or per-file) and adaptive (learns from exposure to more data). That is the very definition of AI. So, cybersecurity needs AI. \n\nThe [NIST](https://www.nist.gov/) [Cybersecurity Framework](https://www.nist.gov/cyberframework) identifies 5 principal functions: Identify, Protect, Detect, Respond and Recover. Each of these can be augmented considerably with AI. \n\nFor more concrete use cases for AI, look at the web sites and white papers of leading cybersecurity companies: Checkpoint, Palo Alto Networks, Versa, Zscaler, ... (in no specific order0.  Just one example: [AI in Cybersecurity](https://www.checkpoint.com/cyber-hub/cyber-security/what-is-ai-cyber-security/).",
      "body_html": "<div class=\"md\"><p>This combines several very broad questions in one, so I&#39;ll just pick the first one.</p>\n\n<p>Cybersecurity involves analyzing massive amounts of data  (network traffic, executable files, container images, host/cluster config, etc.) for solving problems or making decisions (e.g., does this file contain malware, does this email include phishing attempts) in a way that is autonomous (we cannot afford manual decisions per-packet or per-file) and adaptive (learns from exposure to more data). That is the very definition of AI. So, cybersecurity needs AI. </p>\n\n<p>The <a href=\"https://www.nist.gov/\">NIST</a> <a href=\"https://www.nist.gov/cyberframework\">Cybersecurity Framework</a> identifies 5 principal functions: Identify, Protect, Detect, Respond and Recover. Each of these can be augmented considerably with AI. </p>\n\n<p>For more concrete use cases for AI, look at the web sites and white papers of leading cybersecurity companies: Checkpoint, Palo Alto Networks, Versa, Zscaler, ... (in no specific order0.  Just one example: <a href=\"https://www.checkpoint.com/cyber-hub/cyber-security/what-is-ai-cyber-security/\">AI in Cybersecurity</a>.</p>\n</div>",
      "created_utc": 1690867737.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/jub1pqr/",
      "parent_id": "t1_jbt1etb",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-07-31T22:28:57"
    },
    {
      "id": "jag8hl2",
      "author": "spruce5637",
      "body": "Thanks, good to see a proper definition! \n\n<ramble> \n\nBoth GPT-2 and GPT-3 papers also used \"context size\" or \"context window\" without really defining the terms. Makes me wonder if earlier literature that used the term to refer to maximum input length exist...\n\n<\\\\ramble>",
      "body_html": "<div class=\"md\"><p>Thanks, good to see a proper definition! </p>\n\n<p>&lt;ramble&gt; </p>\n\n<p>Both GPT-2 and GPT-3 papers also used &quot;context size&quot; or &quot;context window&quot; without really defining the terms. Makes me wonder if earlier literature that used the term to refer to maximum input length exist...</p>\n\n<p>&lt;\\ramble&gt;</p>\n</div>",
      "created_utc": 1677647477.0,
      "score": 3,
      "ups": 3,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/jag8hl2/",
      "parent_id": "t1_jaf8b7x",
      "depth": 2,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-28T21:11:17"
    },
    {
      "id": "jbaiz62",
      "author": "MaybeADragon",
      "body": "It was just a test run, following https://autokeras.com/tutorial/image_classification/ this tutorial from AutoKeras except with the cats and dogs dataset as mentioned.   \n\nI'm not a dedicated machine learning guy for my company so I won't really have the time to spend researching and documenting this in a controlled environment. We're just trying to find whatever we could learn, train, deploy and maintain with as few man hours as possible so researching this performance quirk any further is outside of my purview sadly especially as it looks as if we've found another solution more fitting to our needs.",
      "body_html": "<div class=\"md\"><p>It was just a test run, following <a href=\"https://autokeras.com/tutorial/image_classification/\">https://autokeras.com/tutorial/image_classification/</a> this tutorial from AutoKeras except with the cats and dogs dataset as mentioned.   </p>\n\n<p>I&#39;m not a dedicated machine learning guy for my company so I won&#39;t really have the time to spend researching and documenting this in a controlled environment. We&#39;re just trying to find whatever we could learn, train, deploy and maintain with as few man hours as possible so researching this performance quirk any further is outside of my purview sadly especially as it looks as if we&#39;ve found another solution more fitting to our needs.</p>\n</div>",
      "created_utc": 1678210278.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/jbaiz62/",
      "parent_id": "t1_jb9ol2x",
      "depth": 2,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-07T09:31:18"
    },
    {
      "id": "jaw8irt",
      "author": "TinkerAndThinker",
      "body": "Thanks! Will try out Sagemaker!",
      "body_html": "<div class=\"md\"><p>Thanks! Will try out Sagemaker!</p>\n</div>",
      "created_utc": 1677944480.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/jaw8irt/",
      "parent_id": "t1_janmwt5",
      "depth": 2,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-04T07:41:20"
    },
    {
      "id": "jauyr1f",
      "author": "TinkerAndThinker",
      "body": "Thanks!\n\nI'm indeed pre-processing the data by using one hot encoding. I am using sklearn for random forest, and it seems that I need to pre-process before fitting?",
      "body_html": "<div class=\"md\"><p>Thanks!</p>\n\n<p>I&#39;m indeed pre-processing the data by using one hot encoding. I am using sklearn for random forest, and it seems that I need to pre-process before fitting?</p>\n</div>",
      "created_utc": 1677913567.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/jauyr1f/",
      "parent_id": "t1_jaspqos",
      "depth": 2,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-03T23:06:07"
    },
    {
      "id": "jbx2tka",
      "author": "SleekGeek8",
      "body": "Thanks! Super helpful. What do you think are they key capabilities to look for when choosing one of these tools? I like the OSS approach but given the variety of capabilities it's hard to prioritize.",
      "body_html": "<div class=\"md\"><p>Thanks! Super helpful. What do you think are they key capabilities to look for when choosing one of these tools? I like the OSS approach but given the variety of capabilities it&#39;s hard to prioritize.</p>\n</div>",
      "created_utc": 1678620864.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/jbx2tka/",
      "parent_id": "t1_jbk425w",
      "depth": 2,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-12T04:34:24"
    },
    {
      "id": "ja4h5qa",
      "author": "Impressive-Cancel892",
      "body": "Thank you!!!",
      "body_html": "<div class=\"md\"><p>Thank you!!!</p>\n</div>",
      "created_utc": 1677441119.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/ja4h5qa/",
      "parent_id": "t1_ja4a16l",
      "depth": 2,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-26T11:51:59"
    },
    {
      "id": "ja585nn",
      "author": "eigenfudge",
      "body": "To add, once youâ€™re done with Bishopâ€™s book (which is great and a self-contained textbook), Murphyâ€™s recent book is a great reference manual to sample a wide array of modern ML subjects. Itâ€™s not in the same problem-solving style, but itâ€™s very valuable if you want to dig into a particular sub area. Each sub area is covered by an expert in it, which makes sense as ML has gotten more expansive/ specialized with time.",
      "body_html": "<div class=\"md\"><p>To add, once youâ€™re done with Bishopâ€™s book (which is great and a self-contained textbook), Murphyâ€™s recent book is a great reference manual to sample a wide array of modern ML subjects. Itâ€™s not in the same problem-solving style, but itâ€™s very valuable if you want to dig into a particular sub area. Each sub area is covered by an expert in it, which makes sense as ML has gotten more expansive/ specialized with time.</p>\n</div>",
      "created_utc": 1677452131.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/ja585nn/",
      "parent_id": "t1_ja4a16l",
      "depth": 2,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-26T14:55:31"
    },
    {
      "id": "ja4u04m",
      "author": "SHOVIC23",
      "body": "Thank you so much!!! Right now the training mae is 0.276 and the validaiton mae is 0.28. I think that the model is not overfitting so I just increased the number of neurons to (80 160 80) and started running it again following your suggestion. I will try running it with relu and sgd.\n\nThe function is very weird but not discrete/discontinuous. Probably a bit like the ratrigin function but with 5 input parameters. In that case I think I should follow your advice and sample in a quasi random way. Could you suggest me any sampling function/sceheme?",
      "body_html": "<div class=\"md\"><p>Thank you so much!!! Right now the training mae is 0.276 and the validaiton mae is 0.28. I think that the model is not overfitting so I just increased the number of neurons to (80 160 80) and started running it again following your suggestion. I will try running it with relu and sgd.</p>\n\n<p>The function is very weird but not discrete/discontinuous. Probably a bit like the ratrigin function but with 5 input parameters. In that case I think I should follow your advice and sample in a quasi random way. Could you suggest me any sampling function/sceheme?</p>\n</div>",
      "created_utc": 1677446261.0,
      "score": 2,
      "ups": 2,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/ja4u04m/",
      "parent_id": "t1_ja4r56t",
      "depth": 2,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-26T13:17:41"
    },
    {
      "id": "ja4i4xk",
      "author": "SHOVIC23",
      "body": "Thank you so much! I just tried adam optimizer and the mae improved a bit. I am new to machine learning. So I was stuck at what to do next. Your suggestion helps me a lot.",
      "body_html": "<div class=\"md\"><p>Thank you so much! I just tried adam optimizer and the mae improved a bit. I am new to machine learning. So I was stuck at what to do next. Your suggestion helps me a lot.</p>\n</div>",
      "created_utc": 1677441505.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/ja4i4xk/",
      "parent_id": "t1_ja48vci",
      "depth": 2,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-26T11:58:25"
    },
    {
      "id": "ja4ipkg",
      "author": "SHOVIC23",
      "body": "I already tried tuning the batch size. It seems that 32 is giving better results. I am using keras compile so I think the keras is tuning the learning rate by itself. Will try tuning the weight decay and momentum.",
      "body_html": "<div class=\"md\"><p>I already tried tuning the batch size. It seems that 32 is giving better results. I am using keras compile so I think the keras is tuning the learning rate by itself. Will try tuning the weight decay and momentum.</p>\n</div>",
      "created_utc": 1677441736.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/ja4ipkg/",
      "parent_id": "t1_ja48vci",
      "depth": 2,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-26T12:02:16"
    },
    {
      "id": "ja4u6yv",
      "author": "SHOVIC23",
      "body": "Thank you so much!! I just increased the number of neurons to (80 160 80) and  started the run again. The current training mae is 0.276 and validation mae is 0.28. I guess my model is underfitting.",
      "body_html": "<div class=\"md\"><p>Thank you so much!! I just increased the number of neurons to (80 160 80) and  started the run again. The current training mae is 0.276 and validation mae is 0.28. I guess my model is underfitting.</p>\n</div>",
      "created_utc": 1677446336.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/ja4u6yv/",
      "parent_id": "t1_ja4rlhf",
      "depth": 2,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-26T13:18:56"
    },
    {
      "id": "ja88ciz",
      "author": "Zorpork00",
      "body": "Thank you ðŸ˜Š",
      "body_html": "<div class=\"md\"><p>Thank you ðŸ˜Š</p>\n</div>",
      "created_utc": 1677513774.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/ja88ciz/",
      "parent_id": "t1_ja6ev56",
      "depth": 2,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-27T08:02:54"
    },
    {
      "id": "ja88dq4",
      "author": "Zorpork00",
      "body": "Thanks a lot ðŸ™",
      "body_html": "<div class=\"md\"><p>Thanks a lot ðŸ™</p>\n</div>",
      "created_utc": 1677513787.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/ja88dq4/",
      "parent_id": "t1_ja7bl2u",
      "depth": 2,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-27T08:03:07"
    },
    {
      "id": "ja88eef",
      "author": "Zorpork00",
      "body": "Thank you ðŸ˜Š",
      "body_html": "<div class=\"md\"><p>Thank you ðŸ˜Š</p>\n</div>",
      "created_utc": 1677513795.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/ja88eef/",
      "parent_id": "t1_ja87j3h",
      "depth": 2,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-27T08:03:15"
    },
    {
      "id": "jb5pfbr",
      "author": "0660990",
      "body": "Thank you for your answer. Although I work professionally with audio, I could not achieve this convincingly yet. I think gender characteristics tend to be noticeable regardless of pitch, and might have to do with vocal tract length (same pitch, different timber)",
      "body_html": "<div class=\"md\"><p>Thank you for your answer. Although I work professionally with audio, I could not achieve this convincingly yet. I think gender characteristics tend to be noticeable regardless of pitch, and might have to do with vocal tract length (same pitch, different timber)</p>\n</div>",
      "created_utc": 1678122346.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/jb5pfbr/",
      "parent_id": "t1_jablki7",
      "depth": 2,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-06T09:05:46"
    },
    {
      "id": "jb66rd2",
      "author": "0660990",
      "body": "Thank you so much Spruce5637.",
      "body_html": "<div class=\"md\"><p>Thank you so much Spruce5637.</p>\n</div>",
      "created_utc": 1678129397.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/jb66rd2/",
      "parent_id": "t1_jac7xjl",
      "depth": 2,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-06T11:03:17"
    },
    {
      "id": "japi3fe",
      "author": "Ashken",
      "body": "I havenâ€™t, Iâ€™m not familiar with anything. How much data would I need to train?",
      "body_html": "<div class=\"md\"><p>I havenâ€™t, Iâ€™m not familiar with anything. How much data would I need to train?</p>\n</div>",
      "created_utc": 1677811803.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/japi3fe/",
      "parent_id": "t1_japgo5s",
      "depth": 2,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-02T18:50:03"
    },
    {
      "id": "jar8ed1",
      "author": "Konki29",
      "body": "Ok, I'll try all of that, thanks",
      "body_html": "<div class=\"md\"><p>Ok, I&#39;ll try all of that, thanks</p>\n</div>",
      "created_utc": 1677852314.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/jar8ed1/",
      "parent_id": "t1_jar7owh",
      "depth": 2,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-03T06:05:14"
    },
    {
      "id": "jb34rgq",
      "author": "No_Canary_5299",
      "body": "Do you know where I can find such datasets? I found one data test but only consists of 30 records which is too small.",
      "body_html": "<div class=\"md\"><p>Do you know where I can find such datasets? I found one data test but only consists of 30 records which is too small.</p>\n</div>",
      "created_utc": 1678067585.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/jb34rgq/",
      "parent_id": "t1_jb26bc6",
      "depth": 2,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-05T17:53:05"
    },
    {
      "id": "jbjwb1h",
      "author": "nerdponx",
      "body": "I'd also mention that in general, temperature scaling is intended to improve the **calibration** of a model. Calibration is how closely the model's output \"scores\" resemble probabilities. This page provides a nice short summary of the problem and of how temperature scaling addresses it: https://docs.aws.amazon.com/prescriptive-guidance/latest/ml-quantifying-uncertainty/temp-scaling.html.\n\nIn general, if you are interested in predicting *probabilities* `Pr(Y=y|X=x)`, then you should be using **proper scoring rule** to evaluate your model, and not a classification/confusion-matrix-based score such as accuracy, F1, precision, etc. See e.g.: https://stats.stackexchange.com/questions/tagged/scoring-rules\n\nNote that cross-entropy loss for classification is specifically based in the probabilistic interpretation of a model as an estimator for `E(Y|X=x)`, where `Y` follows a Categorical distribution with probabilities `p1, ... pK` for classes 1-K. Probability modeling is inescapable even if you think you don't need or care about it, and it should be part of everyone's intuition!\n\n_I think this should be understandable by any undergrad who is paying attention in their stats and probability classes. Happy to clarify anything if needed._",
      "body_html": "<div class=\"md\"><p>I&#39;d also mention that in general, temperature scaling is intended to improve the <strong>calibration</strong> of a model. Calibration is how closely the model&#39;s output &quot;scores&quot; resemble probabilities. This page provides a nice short summary of the problem and of how temperature scaling addresses it: <a href=\"https://docs.aws.amazon.com/prescriptive-guidance/latest/ml-quantifying-uncertainty/temp-scaling.html\">https://docs.aws.amazon.com/prescriptive-guidance/latest/ml-quantifying-uncertainty/temp-scaling.html</a>.</p>\n\n<p>In general, if you are interested in predicting <em>probabilities</em> <code>Pr(Y=y|X=x)</code>, then you should be using <strong>proper scoring rule</strong> to evaluate your model, and not a classification/confusion-matrix-based score such as accuracy, F1, precision, etc. See e.g.: <a href=\"https://stats.stackexchange.com/questions/tagged/scoring-rules\">https://stats.stackexchange.com/questions/tagged/scoring-rules</a></p>\n\n<p>Note that cross-entropy loss for classification is specifically based in the probabilistic interpretation of a model as an estimator for <code>E(Y|X=x)</code>, where <code>Y</code> follows a Categorical distribution with probabilities <code>p1, ... pK</code> for classes 1-K. Probability modeling is inescapable even if you think you don&#39;t need or care about it, and it should be part of everyone&#39;s intuition!</p>\n\n<p><em>I think this should be understandable by any undergrad who is paying attention in their stats and probability classes. Happy to clarify anything if needed.</em></p>\n</div>",
      "created_utc": 1678377860.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/jbjwb1h/",
      "parent_id": "t1_jbi4lsz",
      "depth": 2,
      "is_submitter": false,
      "stickied": false,
      "edited": true,
      "distinguished": null,
      "timestamp": "2023-03-09T08:04:20"
    },
    {
      "id": "jbjuqzd",
      "author": "nerdponx",
      "body": "I think the big philosophical and neuro/biological question is: are *we* just extremely powerful interpolation machines?\n\nThere are a lot of indications that, at least in part, our minds consist in no small part of interpolation and pattern-matching. There remains the question of qualia, and I don't think we are ever going to produce a neural network that is \"conscious\" in the way that we are conscious. But what we are seeing with the latest generation of models is, that, with enough parameters and enough data to train them, you can perform such powerful interpolation and pattern-matching that it begins to become indistinguishable from whatever human minds actually do, in a wider and wider range of tasks.\n\nOur best biological theories of life are essentially that life is the emergent result of a hierarchy increasingly-complicated units, design patterns, and abstractions, each unit taking millions of years to evolve out of simpler units. Again, there are hard philosophical questions here. But if it's all emergent self-organizing behavior anyway, why *shouldn't* we start to see behavior resembling human thought emerge from a tremendous interpolation and pattern-matching engine trained on a massive corpus of the records of human thought?\n\nAgain and again we see examples of \"AI\" models that are relatively stupid in their design, but with a huge number of parameters and trained on a huge amount of data, matching or beating human performance in tasks that we assumed were too complicated for an \"AI\" model and required human-whatever-it-is that humans have and machines don't. So again and again we find *our own abilities* reduced to \"just\" pattern-matching and interpolation that can be learned and stored in a neural network.\n\nTLDR: yes, but so are we.",
      "body_html": "<div class=\"md\"><p>I think the big philosophical and neuro/biological question is: are <em>we</em> just extremely powerful interpolation machines?</p>\n\n<p>There are a lot of indications that, at least in part, our minds consist in no small part of interpolation and pattern-matching. There remains the question of qualia, and I don&#39;t think we are ever going to produce a neural network that is &quot;conscious&quot; in the way that we are conscious. But what we are seeing with the latest generation of models is, that, with enough parameters and enough data to train them, you can perform such powerful interpolation and pattern-matching that it begins to become indistinguishable from whatever human minds actually do, in a wider and wider range of tasks.</p>\n\n<p>Our best biological theories of life are essentially that life is the emergent result of a hierarchy increasingly-complicated units, design patterns, and abstractions, each unit taking millions of years to evolve out of simpler units. Again, there are hard philosophical questions here. But if it&#39;s all emergent self-organizing behavior anyway, why <em>shouldn&#39;t</em> we start to see behavior resembling human thought emerge from a tremendous interpolation and pattern-matching engine trained on a massive corpus of the records of human thought?</p>\n\n<p>Again and again we see examples of &quot;AI&quot; models that are relatively stupid in their design, but with a huge number of parameters and trained on a huge amount of data, matching or beating human performance in tasks that we assumed were too complicated for an &quot;AI&quot; model and required human-whatever-it-is that humans have and machines don&#39;t. So again and again we find <em>our own abilities</em> reduced to &quot;just&quot; pattern-matching and interpolation that can be learned and stored in a neural network.</p>\n\n<p>TLDR: yes, but so are we.</p>\n</div>",
      "created_utc": 1678377261.0,
      "score": 3,
      "ups": 3,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/jbjuqzd/",
      "parent_id": "t1_jbguvuc",
      "depth": 2,
      "is_submitter": false,
      "stickied": false,
      "edited": true,
      "distinguished": null,
      "timestamp": "2023-03-09T07:54:21"
    },
    {
      "id": "jnbymf2",
      "author": "cd_1999",
      "body": "3 months late, but this is my answer for what it's worth.  \nIt depends on the algorithm you're using in sci-kit learn. Some will allow you to pass categorical variables without preprocessing, but you need to tell the algorithm which ones are Categorical. I think it pretty much never pays off to use one-hot encoding though (unless the number of categories is really low...in which case it probably doesn't make much of a difference) and the memory requirements go crazy.   \n\n\nCheck the example bellow. They encode the categorical variables with one-hot encoding, ordinal encoding and then they don't do any pre-processing and just let the algorithm handle the categorical variables \"natively\".\n\nhttps://scikit-learn.org/stable/auto\\_examples/ensemble/plot\\_gradient\\_boosting\\_categorical.html",
      "body_html": "<div class=\"md\"><p>3 months late, but this is my answer for what it&#39;s worth.<br/>\nIt depends on the algorithm you&#39;re using in sci-kit learn. Some will allow you to pass categorical variables without preprocessing, but you need to tell the algorithm which ones are Categorical. I think it pretty much never pays off to use one-hot encoding though (unless the number of categories is really low...in which case it probably doesn&#39;t make much of a difference) and the memory requirements go crazy.   </p>\n\n<p>Check the example bellow. They encode the categorical variables with one-hot encoding, ordinal encoding and then they don&#39;t do any pre-processing and just let the algorithm handle the categorical variables &quot;natively&quot;.</p>\n\n<p><a href=\"https://scikit-learn.org/stable/auto%5C_examples/ensemble/plot%5C_gradient%5C_boosting%5C_categorical.html\">https://scikit-learn.org/stable/auto\\_examples/ensemble/plot\\_gradient\\_boosting\\_categorical.html</a></p>\n</div>",
      "created_utc": 1686184561.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/jnbymf2/",
      "parent_id": "t1_jauyr1f",
      "depth": 3,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-06-07T17:36:01"
    },
    {
      "id": "ja4haw6",
      "author": "Gawkies",
      "body": "no problem kind sir i hope you benefit from it and best of luck with your learning endeavors!",
      "body_html": "<div class=\"md\"><p>no problem kind sir i hope you benefit from it and best of luck with your learning endeavors!</p>\n</div>",
      "created_utc": 1677441175.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/ja4haw6/",
      "parent_id": "t1_ja4h5qa",
      "depth": 3,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-26T11:52:55"
    },
    {
      "id": "ja7ihcl",
      "author": "Gawkies",
      "body": "thank you so much! will have to look at that myself",
      "body_html": "<div class=\"md\"><p>thank you so much! will have to look at that myself</p>\n</div>",
      "created_utc": 1677501721.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/ja7ihcl/",
      "parent_id": "t1_ja585nn",
      "depth": 3,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-27T04:42:01"
    },
    {
      "id": "ja4ww8f",
      "author": "Disastrous-War-9675",
      "body": "I cannot really suggest the best way to sample, I think it's a problem best solved by trial and error imo (I bet there's some rule of thumb or sth, I'm just not aware of it). Equal spacing (non-random) would be my first experiment though.\n\nDo note that modeling optimization benchmark functions, especially high dimensional ones, is not an easy task. If your goal is to learn I'd pick an easier function first to familiarize myself with the whole NN modeling process. If you have to model that specific function, great, even more learning. It's just gonna be a bit more brutal.",
      "body_html": "<div class=\"md\"><p>I cannot really suggest the best way to sample, I think it&#39;s a problem best solved by trial and error imo (I bet there&#39;s some rule of thumb or sth, I&#39;m just not aware of it). Equal spacing (non-random) would be my first experiment though.</p>\n\n<p>Do note that modeling optimization benchmark functions, especially high dimensional ones, is not an easy task. If your goal is to learn I&#39;d pick an easier function first to familiarize myself with the whole NN modeling process. If you have to model that specific function, great, even more learning. It&#39;s just gonna be a bit more brutal.</p>\n</div>",
      "created_utc": 1677447420.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/ja4ww8f/",
      "parent_id": "t1_ja4u04m",
      "depth": 3,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-26T13:37:00"
    },
    {
      "id": "ja4jjci",
      "author": "Gawkies",
      "body": "ah i do not know how keras works exactly but i think you can set your learning rate, the default value is 0.001 [as shown here](https://keras.io/api/models/model_training_apis/)\n\n\n[This here](https://towardsdatascience.com/understanding-learning-rates-and-how-it-improves-performance-in-deep-learning-d0d4059c1c10) has a graph showing how different learning rates behave, being 'very high, high, good, low', useful incase you run into training loss problems with future models you run \n\n\nonce again best of luck!",
      "body_html": "<div class=\"md\"><p>ah i do not know how keras works exactly but i think you can set your learning rate, the default value is 0.001 <a href=\"https://keras.io/api/models/model_training_apis/\">as shown here</a></p>\n\n<p><a href=\"https://towardsdatascience.com/understanding-learning-rates-and-how-it-improves-performance-in-deep-learning-d0d4059c1c10\">This here</a> has a graph showing how different learning rates behave, being &#39;very high, high, good, low&#39;, useful incase you run into training loss problems with future models you run </p>\n\n<p>once again best of luck!</p>\n</div>",
      "created_utc": 1677442070.0,
      "score": 2,
      "ups": 2,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/ja4jjci/",
      "parent_id": "t1_ja4ipkg",
      "depth": 3,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-26T12:07:50"
    },
    {
      "id": "jnc2lqa",
      "author": "TinkerAndThinker",
      "body": "Thank you!",
      "body_html": "<div class=\"md\"><p>Thank you!</p>\n</div>",
      "created_utc": 1686186288.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/jnc2lqa/",
      "parent_id": "t1_jnbymf2",
      "depth": 4,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-06-07T18:04:48"
    },
    {
      "id": "ja4ypt0",
      "author": "SHOVIC23",
      "body": "I have to model this specific function. Would hyperparameter tuning be enough to model this function or would I need to experiment with neural network architecture as well? I would greatly appreciate any guidelines/ way forward. I am trying with artificial neural networks but would it be better to try with other methods such as physics informed neural network or reinforced learning etc.?",
      "body_html": "<div class=\"md\"><p>I have to model this specific function. Would hyperparameter tuning be enough to model this function or would I need to experiment with neural network architecture as well? I would greatly appreciate any guidelines/ way forward. I am trying with artificial neural networks but would it be better to try with other methods such as physics informed neural network or reinforced learning etc.?</p>\n</div>",
      "created_utc": 1677448162.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/ja4ypt0/",
      "parent_id": "t1_ja4ww8f",
      "depth": 4,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-26T13:49:22"
    },
    {
      "id": "ja5a5fh",
      "author": "Disastrous-War-9675",
      "body": "Regarding other methods: I'm not that well versed in PINNs. It heavily depends on what your goal is. Why do you want to model it if you can sample from it? Is it speed? Differentiability? What do you want to do with it? Find local/global minima? Regardless, RL sounds like a very bad fit.\n\nThere is not definite answer to your question but there are some useful rule of thumbs. I would simply scale the model and do an hparam search for a few architectures first.",
      "body_html": "<div class=\"md\"><p>Regarding other methods: I&#39;m not that well versed in PINNs. It heavily depends on what your goal is. Why do you want to model it if you can sample from it? Is it speed? Differentiability? What do you want to do with it? Find local/global minima? Regardless, RL sounds like a very bad fit.</p>\n\n<p>There is not definite answer to your question but there are some useful rule of thumbs. I would simply scale the model and do an hparam search for a few architectures first.</p>\n</div>",
      "created_utc": 1677452964.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/ja5a5fh/",
      "parent_id": "t1_ja4ypt0",
      "depth": 5,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-26T15:09:24"
    },
    {
      "id": "ja5eb2q",
      "author": "SHOVIC23",
      "body": "Thanks again! The function is an empirical equation that gives the root mean square error from the desired outcome in an experiment. The goal is to find the 5 input parameters that would give the least RMSE. So its an optimization problem.\n\nAlthough we have an empirical function, in experiment the function might be a bit different. So the goal is to build a neural network and train it on data to be collected in the experiment. The neural network will then be used to calculate the gradient to guide an optimization algorithm.\n\nPreviously I have tried different optimization algorithms. Now I am trying to see if neural network assisted optimization algorithm will decrease number of iterations but I don't have much experience in designing neural networks.\n\nBy scaling the model, do you mean increasing the number of neurons/layers. I just finished a run multiplying the number of neurons by 10 and also used Python's random.uniform function to sample the data but the results didn't seem to improve much. Do you think sampling more data would help?",
      "body_html": "<div class=\"md\"><p>Thanks again! The function is an empirical equation that gives the root mean square error from the desired outcome in an experiment. The goal is to find the 5 input parameters that would give the least RMSE. So its an optimization problem.</p>\n\n<p>Although we have an empirical function, in experiment the function might be a bit different. So the goal is to build a neural network and train it on data to be collected in the experiment. The neural network will then be used to calculate the gradient to guide an optimization algorithm.</p>\n\n<p>Previously I have tried different optimization algorithms. Now I am trying to see if neural network assisted optimization algorithm will decrease number of iterations but I don&#39;t have much experience in designing neural networks.</p>\n\n<p>By scaling the model, do you mean increasing the number of neurons/layers. I just finished a run multiplying the number of neurons by 10 and also used Python&#39;s random.uniform function to sample the data but the results didn&#39;t seem to improve much. Do you think sampling more data would help?</p>\n</div>",
      "created_utc": 1677454712.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/ja5eb2q/",
      "parent_id": "t1_ja5a5fh",
      "depth": 6,
      "is_submitter": false,
      "stickied": false,
      "edited": true,
      "distinguished": null,
      "timestamp": "2023-02-26T15:38:32"
    },
    {
      "id": "ja5htwf",
      "author": "Disastrous-War-9675",
      "body": "I don't fully understand the problem the way you describe it.\nIf the goal is to find 5 input parameters with the least <something>, and you can sample elements of your search space (experimentally evaluate this <something> given some fixed parameters), bayesian optimization immediately comes to mind, not neural networks. It was specifically invented for this type of problems, especially when your search space is not too large and experimentally evaluating the objective function is expensive. I don't see a straightforward way to use neural networks but maybe I am misinterpreting the problem.",
      "body_html": "<div class=\"md\"><p>I don&#39;t fully understand the problem the way you describe it.\nIf the goal is to find 5 input parameters with the least &lt;something&gt;, and you can sample elements of your search space (experimentally evaluate this &lt;something&gt; given some fixed parameters), bayesian optimization immediately comes to mind, not neural networks. It was specifically invented for this type of problems, especially when your search space is not too large and experimentally evaluating the objective function is expensive. I don&#39;t see a straightforward way to use neural networks but maybe I am misinterpreting the problem.</p>\n</div>",
      "created_utc": 1677456262.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/ja5htwf/",
      "parent_id": "t1_ja5eb2q",
      "depth": 7,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-26T16:04:22"
    },
    {
      "id": "ja5ovz4",
      "author": "SHOVIC23",
      "body": "We are trying to optimize a laser pulse shape. We can experimentally control the pulse shape using the five parameters. The empirical function gives us the error between the pulse shape and the optimum pulse shape. Our objective is to minimize the error by controlling the five parameters.\n\nWe have previously tried bayesian optimization, differential evolution, Nelder-Mead and particle swarm optimization. The algorithms work but we are trying to reduce the number of iterations further down. Recently there has been a paper titled \"GGA: A modified genetic algorithm with gradient-based local search for solving constrained optimization problems\". The paper talks about using a mixture of genetic algorithm and gradient descent. In our optimization problem, we don't know the gradient that is required for gradient descent. We have an empirical function but that might not match with the experiment. The purpose of the function is to test different optimization algorithms I think. So we are trying to build a neural network by sampling data from the equation. If the neural network works on the sampled data, it might also work on the experimental data. Finally, the plan is to calculate the gradients from the neural network and apply the algorithm in the paper mentioned above.\n\nWhat we are trying to is a bit similar to this paper:\n\n[https://www.cambridge.org/core/journals/high-power-laser-science-and-engineering/article/machinelearning-guided-optimization-of-laser-pulses-for-directdrive-implosions/A676A8A33E7123333EE0F74D24FAAE42](https://www.cambridge.org/core/journals/high-power-laser-science-and-engineering/article/machinelearning-guided-optimization-of-laser-pulses-for-directdrive-implosions/A676A8A33E7123333EE0F74D24FAAE42)\n\nIn the paper, the optimization was for one parameter only whereas in our case, the optimization is for 5 parameters. I am not sure how much success we will have.",
      "body_html": "<div class=\"md\"><p>We are trying to optimize a laser pulse shape. We can experimentally control the pulse shape using the five parameters. The empirical function gives us the error between the pulse shape and the optimum pulse shape. Our objective is to minimize the error by controlling the five parameters.</p>\n\n<p>We have previously tried bayesian optimization, differential evolution, Nelder-Mead and particle swarm optimization. The algorithms work but we are trying to reduce the number of iterations further down. Recently there has been a paper titled &quot;GGA: A modified genetic algorithm with gradient-based local search for solving constrained optimization problems&quot;. The paper talks about using a mixture of genetic algorithm and gradient descent. In our optimization problem, we don&#39;t know the gradient that is required for gradient descent. We have an empirical function but that might not match with the experiment. The purpose of the function is to test different optimization algorithms I think. So we are trying to build a neural network by sampling data from the equation. If the neural network works on the sampled data, it might also work on the experimental data. Finally, the plan is to calculate the gradients from the neural network and apply the algorithm in the paper mentioned above.</p>\n\n<p>What we are trying to is a bit similar to this paper:</p>\n\n<p><a href=\"https://www.cambridge.org/core/journals/high-power-laser-science-and-engineering/article/machinelearning-guided-optimization-of-laser-pulses-for-directdrive-implosions/A676A8A33E7123333EE0F74D24FAAE42\">https://www.cambridge.org/core/journals/high-power-laser-science-and-engineering/article/machinelearning-guided-optimization-of-laser-pulses-for-directdrive-implosions/A676A8A33E7123333EE0F74D24FAAE42</a></p>\n\n<p>In the paper, the optimization was for one parameter only whereas in our case, the optimization is for 5 parameters. I am not sure how much success we will have.</p>\n</div>",
      "created_utc": 1677459460.0,
      "score": 2,
      "ups": 2,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/ja5ovz4/",
      "parent_id": "t1_ja5htwf",
      "depth": 8,
      "is_submitter": false,
      "stickied": false,
      "edited": true,
      "distinguished": null,
      "timestamp": "2023-02-26T16:57:40"
    },
    {
      "id": "ja5ydqt",
      "author": "Disastrous-War-9675",
      "body": "Ah, this is not my field of expertise, sorry. My only suggestions would have been to try the optimization methods you already did, I don't know much about modern methods like GGA.",
      "body_html": "<div class=\"md\"><p>Ah, this is not my field of expertise, sorry. My only suggestions would have been to try the optimization methods you already did, I don&#39;t know much about modern methods like GGA.</p>\n</div>",
      "created_utc": 1677463917.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/ja5ydqt/",
      "parent_id": "t1_ja5ovz4",
      "depth": 9,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-26T18:11:57"
    },
    {
      "id": "ja62dq4",
      "author": "SHOVIC23",
      "body": "No problem, your suggestions are helping me a lot. I have been increasing the number of neurons per layer and the size of data by a factor of two and seeing some improvement. I will keep doing that. For neural networks, is higher number of neurons and layers always better if we don't take computational cost into account?",
      "body_html": "<div class=\"md\"><p>No problem, your suggestions are helping me a lot. I have been increasing the number of neurons per layer and the size of data by a factor of two and seeing some improvement. I will keep doing that. For neural networks, is higher number of neurons and layers always better if we don&#39;t take computational cost into account?</p>\n</div>",
      "created_utc": 1677465843.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/ja62dq4/",
      "parent_id": "t1_ja5ydqt",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-26T18:44:03"
    },
    {
      "id": "ja67nyy",
      "author": "Disastrous-War-9675",
      "body": "Always is a big word but usually, yes. You have to scale the data as well the bigger you go. These are the rule of thumbs:\n\nToo many neurons: overfits easily -> needs more data(easy to implement)/smarter regularization (hard to implement)\n\nToo few neurons: Not expressive enough to fit the data -> needs more representative data (smart subsampling, rarely done in practice) or more neurons.\n\nYou can follow common sense to find the right size for your network. If it overfits too easily, reduce its size. Otherwise, increase it. All of this assuming that you picked a good set of hyperparameters corresponding to each experiment and trained it to convergence, otherwise you cannot draw conclusions. \n\nFor real world datasets the golden rule is more data=better 99% of the time.\n\nThe exact scaling laws (what's the exact relationship between network size and data size) is an active research field in its own right. tldr; most ppl think it's a power law relationship, it has been shown pretty recently (only for vision AFAIK) that you can prune the data (see smart subsampling above) to achieve much better scaling than that. The main takeaway was the  -seemingly obvious- observation that not all datapoints carry the same importance.\n\nIf I continue this train of thought I'll have to start talking about inductive biases and different kinds of networks (feedforward, CNN, graph, transformer) which will probably just confuse you and won't really be useful to you I think.\n\nFinally, https://github.com/google-research/tuning_playbook this is the tuning Bible for the working scientist right now but it requires basic familiarity with ML concepts. ML tuning is more of an art than it is a science but the longer you do it the more the curves start speaking to you and your intuition guides you more efficiently.",
      "body_html": "<div class=\"md\"><p>Always is a big word but usually, yes. You have to scale the data as well the bigger you go. These are the rule of thumbs:</p>\n\n<p>Too many neurons: overfits easily -&gt; needs more data(easy to implement)/smarter regularization (hard to implement)</p>\n\n<p>Too few neurons: Not expressive enough to fit the data -&gt; needs more representative data (smart subsampling, rarely done in practice) or more neurons.</p>\n\n<p>You can follow common sense to find the right size for your network. If it overfits too easily, reduce its size. Otherwise, increase it. All of this assuming that you picked a good set of hyperparameters corresponding to each experiment and trained it to convergence, otherwise you cannot draw conclusions. </p>\n\n<p>For real world datasets the golden rule is more data=better 99% of the time.</p>\n\n<p>The exact scaling laws (what&#39;s the exact relationship between network size and data size) is an active research field in its own right. tldr; most ppl think it&#39;s a power law relationship, it has been shown pretty recently (only for vision AFAIK) that you can prune the data (see smart subsampling above) to achieve much better scaling than that. The main takeaway was the  -seemingly obvious- observation that not all datapoints carry the same importance.</p>\n\n<p>If I continue this train of thought I&#39;ll have to start talking about inductive biases and different kinds of networks (feedforward, CNN, graph, transformer) which will probably just confuse you and won&#39;t really be useful to you I think.</p>\n\n<p>Finally, <a href=\"https://github.com/google-research/tuning_playbook\">https://github.com/google-research/tuning_playbook</a> this is the tuning Bible for the working scientist right now but it requires basic familiarity with ML concepts. ML tuning is more of an art than it is a science but the longer you do it the more the curves start speaking to you and your intuition guides you more efficiently.</p>\n</div>",
      "created_utc": 1677468454.0,
      "score": 2,
      "ups": 2,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/ja67nyy/",
      "parent_id": "t1_ja62dq4",
      "depth": 2,
      "is_submitter": false,
      "stickied": false,
      "edited": true,
      "distinguished": null,
      "timestamp": "2023-02-26T19:27:34"
    },
    {
      "id": "ja9aqmk",
      "author": "SHOVIC23",
      "body": "Thank you so much for you help. I greatly appreciate it. Currently my training and validation mae are very close - around 0.27. I guess it is underfitting. \n\nAfter normalizing my dataset, the maximum value of the y (output)  training and test data was 10. When looking at the mae to see if my model is overfitting/underfitting, should I take the maximum y value in account? Would mape (mean absolute percentage error) be a better metric?",
      "body_html": "<div class=\"md\"><p>Thank you so much for you help. I greatly appreciate it. Currently my training and validation mae are very close - around 0.27. I guess it is underfitting. </p>\n\n<p>After normalizing my dataset, the maximum value of the y (output)  training and test data was 10. When looking at the mae to see if my model is overfitting/underfitting, should I take the maximum y value in account? Would mape (mean absolute percentage error) be a better metric?</p>\n</div>",
      "created_utc": 1677528458.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/ja9aqmk/",
      "parent_id": "t1_ja67nyy",
      "depth": 3,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-27T12:07:38"
    },
    {
      "id": "ja9dk93",
      "author": "Disastrous-War-9675",
      "body": "Normalizing the data matters, the Mae vs mape metric doesn't, it's up to you what's easier to interpret. MAPE is scale agnostic so even if people don't know what values your objective function usually takes you can share your results with others. For instance, we have no idea whether 0.27 is small or large in your case. If this was a house price prediction (measured in dollars), it would be perfect, if it estimated the energy of a photon at 1hz in electronvolts it would be abysmal.",
      "body_html": "<div class=\"md\"><p>Normalizing the data matters, the Mae vs mape metric doesn&#39;t, it&#39;s up to you what&#39;s easier to interpret. MAPE is scale agnostic so even if people don&#39;t know what values your objective function usually takes you can share your results with others. For instance, we have no idea whether 0.27 is small or large in your case. If this was a house price prediction (measured in dollars), it would be perfect, if it estimated the energy of a photon at 1hz in electronvolts it would be abysmal.</p>\n</div>",
      "created_utc": 1677529528.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/ja9dk93/",
      "parent_id": "t1_ja9aqmk",
      "depth": 4,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-27T12:25:28"
    },
    {
      "id": "jaaa6ul",
      "author": "SHOVIC23",
      "body": "In my dataset, the y value varies a lot. When I sample it can be in the range of 0.0003 to 0.56 but the actual minimums which optimization algorithms can find are in the rand of 1e-10. I think this variability of the y values are making it harder to model because simply by sampling, I may not be including the actual minimas in the dataset. Maybe I should build a dataset by running the optimization algorithm and collecting some minimas and put them in the dataset.",
      "body_html": "<div class=\"md\"><p>In my dataset, the y value varies a lot. When I sample it can be in the range of 0.0003 to 0.56 but the actual minimums which optimization algorithms can find are in the rand of 1e-10. I think this variability of the y values are making it harder to model because simply by sampling, I may not be including the actual minimas in the dataset. Maybe I should build a dataset by running the optimization algorithm and collecting some minimas and put them in the dataset.</p>\n</div>",
      "created_utc": 1677542408.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/jaaa6ul/",
      "parent_id": "t1_ja9aqmk",
      "depth": 4,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-27T16:00:08"
    }
  ],
  "total_comments": 145,
  "fetched_at": "2025-09-13T20:47:35.448489"
}