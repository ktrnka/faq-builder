{
  "submission": {
    "id": "1fted2g",
    "title": "When to build your own model and when to use GPT?\n",
    "author": "PlayboiCult",
    "selftext": "I'm not a ML expert by any means, but I was wondering if there are use-cases (NOT privacy-related) where it makes sense technologically to build your own ML model using something like TF/PyTorch instead of using an existing model's API.\n\nIf I needed my business to have, for example, an image classification system that classifies an image in 3 possible categories, I would just use an OpenAI endpoint and be very strict with the system prompt. I wouldn't make a model from scratch.\n\nDoes my question make sense? I'm curious to see what yall say. Thanks in advance.",
    "selftext_html": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;m not a ML expert by any means, but I was wondering if there are use-cases (NOT privacy-related) where it makes sense technologically to build your own ML model using something like TF/PyTorch instead of using an existing model&#39;s API.</p>\n\n<p>If I needed my business to have, for example, an image classification system that classifies an image in 3 possible categories, I would just use an OpenAI endpoint and be very strict with the system prompt. I wouldn&#39;t make a model from scratch.</p>\n\n<p>Does my question make sense? I&#39;m curious to see what yall say. Thanks in advance.</p>\n</div><!-- SC_ON -->",
    "url": "https://www.reddit.com/r/MLQuestions/comments/1fted2g/when_to_build_your_own_model_and_when_to_use_gpt/",
    "permalink": "/r/MLQuestions/comments/1fted2g/when_to_build_your_own_model_and_when_to_use_gpt/",
    "subreddit": "MLQuestions",
    "created_utc": 1727752356.0,
    "score": 3,
    "ups": 3,
    "downs": 0,
    "upvote_ratio": 0.67,
    "num_comments": 11,
    "is_self": true,
    "over_18": false,
    "spoiler": false,
    "stickied": false,
    "locked": false,
    "archived": false,
    "distinguished": null,
    "link_flair_text": "Beginner question 👶",
    "timestamp": "2024-09-30T20:12:36"
  },
  "comments": [
    {
      "id": "lprewjy",
      "author": "alew3",
      "body": "You would never build your own LLM model, as it's too expensive (dataset + hardware) to build anything better then whats already available. On the other hand, you could fine tune an existing model (such as chatgpt or open weights) for your specific use case to get better results than the general model.",
      "body_html": "<div class=\"md\"><p>You would never build your own LLM model, as it&#39;s too expensive (dataset + hardware) to build anything better then whats already available. On the other hand, you could fine tune an existing model (such as chatgpt or open weights) for your specific use case to get better results than the general model.</p>\n</div>",
      "created_utc": 1727754147.0,
      "score": 2,
      "ups": 2,
      "downs": 0,
      "permalink": "/r/MLQuestions/comments/1fted2g/when_to_build_your_own_model_and_when_to_use_gpt/lprewjy/",
      "parent_id": "t3_1fted2g",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2024-09-30T20:42:27"
    },
    {
      "id": "lprnw17",
      "author": "fasti-au",
      "body": "Never build an llm.  At production level your renting cloud GPUs and running llama 3.1/3.2 and tunneling to them.     That’s private in action.  \n\nTo give you my crazy conspiracy theory as a I know this is the worst of the wort but it’s more likely than best of best.  \n\nOpenAI released got to get hype for funding.   They didn’t expect it to be a big deal because it’s basically just the breaking up of words to their parameters like syllables in many ways.    Because no one had made sentence generation that worked before it was a big deal and they managed I get interest beyond what they thought.   \n\nThey rushed an api out and people kept asking for a way to add their data so they created embeddings api and basically learned of the users.  \n\nThat then created wave after wave of this is getting slightly better and more visual.   Let’s make sure t do some code and see if it can make something simple and fed it stack overflow.  It learned how people try life together code from.   This doesn’t work and then produced code that was close to working.  They realised it needed functioncalling and made that happen and at that moment it became useful rather than interesting and people started to try to code and interact with other data and got some success.  \n\nHype fund rape customer data rape public data.  See other ML try make it appear like llm can do by hiding functioncalls to dalle etc which is SD.  Use things like xtts and RVC to make voice llm. \n\nSign deal with military to get around the copyright issues.  Sign 150 billion in funding and have Microsoft buy a nuclear plant by proxy.    Delay voice chat to add military tracking.  Release.  \n\nOpenAI is now able to imitate your voice your persona track your location by gps on phone and very soon have access to your pcs via ms/apple.  \n\nAll while not actually producing anything that worked in a positive way for the general human.  \n\nThe best tech is deception and extortion based. The most hyped tech are techs that literally take away jobs that humans want to do\n\n\n\nSo basically build your own asap and try make something positive happen because OpenAI is now the USA vs china again and that whole control thing is well and truely down the line",
      "body_html": "<div class=\"md\"><p>Never build an llm.  At production level your renting cloud GPUs and running llama 3.1/3.2 and tunneling to them.     That’s private in action.  </p>\n\n<p>To give you my crazy conspiracy theory as a I know this is the worst of the wort but it’s more likely than best of best.  </p>\n\n<p>OpenAI released got to get hype for funding.   They didn’t expect it to be a big deal because it’s basically just the breaking up of words to their parameters like syllables in many ways.    Because no one had made sentence generation that worked before it was a big deal and they managed I get interest beyond what they thought.   </p>\n\n<p>They rushed an api out and people kept asking for a way to add their data so they created embeddings api and basically learned of the users.  </p>\n\n<p>That then created wave after wave of this is getting slightly better and more visual.   Let’s make sure t do some code and see if it can make something simple and fed it stack overflow.  It learned how people try life together code from.   This doesn’t work and then produced code that was close to working.  They realised it needed functioncalling and made that happen and at that moment it became useful rather than interesting and people started to try to code and interact with other data and got some success.  </p>\n\n<p>Hype fund rape customer data rape public data.  See other ML try make it appear like llm can do by hiding functioncalls to dalle etc which is SD.  Use things like xtts and RVC to make voice llm. </p>\n\n<p>Sign deal with military to get around the copyright issues.  Sign 150 billion in funding and have Microsoft buy a nuclear plant by proxy.    Delay voice chat to add military tracking.  Release.  </p>\n\n<p>OpenAI is now able to imitate your voice your persona track your location by gps on phone and very soon have access to your pcs via ms/apple.  </p>\n\n<p>All while not actually producing anything that worked in a positive way for the general human.  </p>\n\n<p>The best tech is deception and extortion based. The most hyped tech are techs that literally take away jobs that humans want to do</p>\n\n<p>So basically build your own asap and try make something positive happen because OpenAI is now the USA vs china again and that whole control thing is well and truely down the line</p>\n</div>",
      "created_utc": 1727758684.0,
      "score": 0,
      "ups": 0,
      "downs": 0,
      "permalink": "/r/MLQuestions/comments/1fted2g/when_to_build_your_own_model_and_when_to_use_gpt/lprnw17/",
      "parent_id": "t3_1fted2g",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2024-09-30T21:58:04"
    },
    {
      "id": "lptij7f",
      "author": "trnka",
      "body": "If the quality is good enough with LLMs, use that to start. Then build a custom non LLM once you need to reduce costs, latency, etc. That said, I'd still recommend just fine tuning a pretrained model if possible rather than creating a new architecture. \n\nThis approach won't work for everything though, because even multi modal LLMs can't handle all kinds of problems. Some that come to mind are genetic data and forecasting. I'm sure there are many others",
      "body_html": "<div class=\"md\"><p>If the quality is good enough with LLMs, use that to start. Then build a custom non LLM once you need to reduce costs, latency, etc. That said, I&#39;d still recommend just fine tuning a pretrained model if possible rather than creating a new architecture. </p>\n\n<p>This approach won&#39;t work for everything though, because even multi modal LLMs can&#39;t handle all kinds of problems. Some that come to mind are genetic data and forecasting. I&#39;m sure there are many others</p>\n</div>",
      "created_utc": 1727794073.0,
      "score": 0,
      "ups": 0,
      "downs": 0,
      "permalink": "/r/MLQuestions/comments/1fted2g/when_to_build_your_own_model_and_when_to_use_gpt/lptij7f/",
      "parent_id": "t3_1fted2g",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2024-10-01T07:47:53"
    },
    {
      "id": "lprfdhv",
      "author": "PlayboiCult",
      "body": "I guess I expressed myself wrong. My question was about using an LLM for a specific purpose (ex: an image classifier) vs using your own model (not an LLM specifically, maybe building your own image classifier for the sake of this example)",
      "body_html": "<div class=\"md\"><p>I guess I expressed myself wrong. My question was about using an LLM for a specific purpose (ex: an image classifier) vs using your own model (not an LLM specifically, maybe building your own image classifier for the sake of this example)</p>\n</div>",
      "created_utc": 1727754362.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MLQuestions/comments/1fted2g/when_to_build_your_own_model_and_when_to_use_gpt/lprfdhv/",
      "parent_id": "t1_lprewjy",
      "depth": 1,
      "is_submitter": true,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2024-09-30T20:46:02"
    },
    {
      "id": "lpsewh5",
      "author": "alew3",
      "body": "It makes a lot sense to use an Image Classifier ( not an llm), depending on what you are classifying.  You would also benefit from using an existing proven image classifier model architecture (and not create from scratch) and fine tune it to your use case to improve results. It would also be much much faster and run locally.  It all depends on your use case.",
      "body_html": "<div class=\"md\"><p>It makes a lot sense to use an Image Classifier ( not an llm), depending on what you are classifying.  You would also benefit from using an existing proven image classifier model architecture (and not create from scratch) and fine tune it to your use case to improve results. It would also be much much faster and run locally.  It all depends on your use case.</p>\n</div>",
      "created_utc": 1727776614.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MLQuestions/comments/1fted2g/when_to_build_your_own_model_and_when_to_use_gpt/lpsewh5/",
      "parent_id": "t1_lprfdhv",
      "depth": 2,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2024-10-01T02:56:54"
    },
    {
      "id": "lpsipmp",
      "author": "hammouse",
      "body": "Why would you use a *language model* for classification?",
      "body_html": "<div class=\"md\"><p>Why would you use a <em>language model</em> for classification?</p>\n</div>",
      "created_utc": 1727779039.0,
      "score": 0,
      "ups": 0,
      "downs": 0,
      "permalink": "/r/MLQuestions/comments/1fted2g/when_to_build_your_own_model_and_when_to_use_gpt/lpsipmp/",
      "parent_id": "t1_lprfdhv",
      "depth": 2,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2024-10-01T03:37:19"
    },
    {
      "id": "lpyrn7f",
      "author": "Hot-Profession4091",
      "body": "This doesn’t deserve downvotes. It’s a legit question. \n\nSentiment is a classic example of using a language model to do a binary classification. \n\nA real one I’ve used is to classify event types. Not all of our data feeds had a classification attached to them, but we could use the ones that did as training data to help us classify the ones that didn’t. \n\nI’ve also used language models for _regression_ tasks, predicting “event impact” based on the title of the event. We ended up feeding the output of that into a second network alongside some more traditional features, but just the LLM regression gave _surprisingly_ good results. Obviously not good enough on its own, but good none the less.",
      "body_html": "<div class=\"md\"><p>This doesn’t deserve downvotes. It’s a legit question. </p>\n\n<p>Sentiment is a classic example of using a language model to do a binary classification. </p>\n\n<p>A real one I’ve used is to classify event types. Not all of our data feeds had a classification attached to them, but we could use the ones that did as training data to help us classify the ones that didn’t. </p>\n\n<p>I’ve also used language models for <em>regression</em> tasks, predicting “event impact” based on the title of the event. We ended up feeding the output of that into a second network alongside some more traditional features, but just the LLM regression gave <em>surprisingly</em> good results. Obviously not good enough on its own, but good none the less.</p>\n</div>",
      "created_utc": 1727871838.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MLQuestions/comments/1fted2g/when_to_build_your_own_model_and_when_to_use_gpt/lpyrn7f/",
      "parent_id": "t1_lpsipmp",
      "depth": 3,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2024-10-02T05:23:58"
    },
    {
      "id": "lpt6q1c",
      "author": "PlayboiCult",
      "body": "A language and vision model (4o for example) does this job pretty good ime",
      "body_html": "<div class=\"md\"><p>A language and vision model (4o for example) does this job pretty good ime</p>\n</div>",
      "created_utc": 1727789951.0,
      "score": -1,
      "ups": -1,
      "downs": 0,
      "permalink": "/r/MLQuestions/comments/1fted2g/when_to_build_your_own_model_and_when_to_use_gpt/lpt6q1c/",
      "parent_id": "t1_lpsipmp",
      "depth": 3,
      "is_submitter": true,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2024-10-01T06:39:11"
    },
    {
      "id": "lpv2sg4",
      "author": "hammouse",
      "body": "They are trained on different data for a different data generating process, which will almost never beat your own model and risks hallucination. The only exception could be if you don't have much training data, in which case machine learning is likely not the right approach to begin with.",
      "body_html": "<div class=\"md\"><p>They are trained on different data for a different data generating process, which will almost never beat your own model and risks hallucination. The only exception could be if you don&#39;t have much training data, in which case machine learning is likely not the right approach to begin with.</p>\n</div>",
      "created_utc": 1727811921.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MLQuestions/comments/1fted2g/when_to_build_your_own_model_and_when_to_use_gpt/lpv2sg4/",
      "parent_id": "t1_lpt6q1c",
      "depth": 4,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2024-10-01T12:45:21"
    },
    {
      "id": "lpv3iug",
      "author": "PlayboiCult",
      "body": "Thank you",
      "body_html": "<div class=\"md\"><p>Thank you</p>\n</div>",
      "created_utc": 1727812145.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MLQuestions/comments/1fted2g/when_to_build_your_own_model_and_when_to_use_gpt/lpv3iug/",
      "parent_id": "t1_lpv2sg4",
      "depth": 5,
      "is_submitter": true,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2024-10-01T12:49:05"
    }
  ],
  "total_comments": 10,
  "fetched_at": "2025-09-13T20:47:07.659481"
}