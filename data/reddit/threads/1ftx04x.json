{
  "submission": {
    "id": "1ftx04x",
    "title": "[D] Why is Tree of Thought an impactful work?",
    "author": "StraightSpeech9295",
    "selftext": "My advisor recently asked me to read the tot paper, but it seems to me that it was just another \\*\\*fancy prompt engineering work\\*\\*. The tot process entails heavy human intelligence (we should manually divide the problem into separate steps and also design verifiers for this method to work), plus it's highly costly and I rarely see people use this method in their work.\n\nStill, this paper receives lots of citations and given the fact that my advisor asked me to read it, I'm wondering if I'm missing anything merits or important implications regarding this work.",
    "selftext_html": "<!-- SC_OFF --><div class=\"md\"><p>My advisor recently asked me to read the tot paper, but it seems to me that it was just another **fancy prompt engineering work**. The tot process entails heavy human intelligence (we should manually divide the problem into separate steps and also design verifiers for this method to work), plus it&#39;s highly costly and I rarely see people use this method in their work.</p>\n\n<p>Still, this paper receives lots of citations and given the fact that my advisor asked me to read it, I&#39;m wondering if I&#39;m missing anything merits or important implications regarding this work.</p>\n</div><!-- SC_ON -->",
    "url": "https://www.reddit.com/r/MachineLearning/comments/1ftx04x/d_why_is_tree_of_thought_an_impactful_work/",
    "permalink": "/r/MachineLearning/comments/1ftx04x/d_why_is_tree_of_thought_an_impactful_work/",
    "subreddit": "MachineLearning",
    "created_utc": 1727811531.0,
    "score": 88,
    "ups": 88,
    "downs": 0,
    "upvote_ratio": 0.94,
    "num_comments": 34,
    "is_self": true,
    "over_18": false,
    "spoiler": false,
    "stickied": false,
    "locked": false,
    "archived": false,
    "distinguished": null,
    "link_flair_text": "Discussion",
    "timestamp": "2024-10-01T12:38:51"
  },
  "comments": [
    {
      "id": "lpv2cj1",
      "author": null,
      "body": "I feel like these prompt engineer papers just massively cite each other and rack up huge citation counts. Also every ug interested in ml does a \"prompt engineering\" lit review paper",
      "body_html": "<div class=\"md\"><p>I feel like these prompt engineer papers just massively cite each other and rack up huge citation counts. Also every ug interested in ml does a &quot;prompt engineering&quot; lit review paper</p>\n</div>",
      "created_utc": 1727811787.0,
      "score": 103,
      "ups": 103,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/1ftx04x/d_why_is_tree_of_thought_an_impactful_work/lpv2cj1/",
      "parent_id": "t3_1ftx04x",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2024-10-01T12:43:07"
    },
    {
      "id": "lpvbp3s",
      "author": "currentscurrents",
      "body": "Tree of Thought is less \"prompt engineering\" and more \"tree search by calling an LLM many times\".\n\nThe idea of doing search over LLM outputs is currently very hot, as people try to use it to solve reasoning problems. Tree of thought specifically isn't used much but gets cited a lot as an early approach.",
      "body_html": "<div class=\"md\"><p>Tree of Thought is less &quot;prompt engineering&quot; and more &quot;tree search by calling an LLM many times&quot;.</p>\n\n<p>The idea of doing search over LLM outputs is currently very hot, as people try to use it to solve reasoning problems. Tree of thought specifically isn&#39;t used much but gets cited a lot as an early approach.</p>\n</div>",
      "created_utc": 1727814656.0,
      "score": 78,
      "ups": 78,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/1ftx04x/d_why_is_tree_of_thought_an_impactful_work/lpvbp3s/",
      "parent_id": "t3_1ftx04x",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2024-10-01T13:30:56"
    },
    {
      "id": "lpvvk9c",
      "author": null,
      "body": "It's not an IQ competition, the only important question is \"is it a contribution?\", i.e., \"is it interesting?\".\nAnd it is.",
      "body_html": "<div class=\"md\"><p>It&#39;s not an IQ competition, the only important question is &quot;is it a contribution?&quot;, i.e., &quot;is it interesting?&quot;.\nAnd it is.</p>\n</div>",
      "created_utc": 1727821128.0,
      "score": 24,
      "ups": 24,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/1ftx04x/d_why_is_tree_of_thought_an_impactful_work/lpvvk9c/",
      "parent_id": "t3_1ftx04x",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2024-10-01T15:18:48"
    },
    {
      "id": "lpwkef3",
      "author": "jalabulajangs",
      "body": "I get where you’re coming from. Coming from theoretical physics myself, I often find ml papers a bit disappointing when it comes to theoretical rigor. The majority of ml papers—honestly, even a lot of engineering research—tend to lack the depth and rigor that you’d see in more foundational sciences. It feels like a lot of it is “fancy prompt engineering” or just intuition-based tinkering without a real theoretical backbone.\n\nThat said, I’ve come to realize that ml/AI is fundamentally more engineering than pure science. The goal here isn’t always to understand everything at the most basic level. Instead, it’s to move the needle—build more powerful models, make progress in applications, make things that work even if we don’t fully understand why they work in detail. And that kind of progress has its own value.\n\nYou could ask the same thing about even the “best” papers introducing new architectures—no one truly understands the fundamentals of why some of these things work. There’s only a handful of people working on the true fundamentals of learning theory. But does that make the work done by everyone else trivial or meaningless? Absolutely not. It’s useful, and it contributes to the field.\n\nHonestly, I see this argument a lot in different contexts. Mathematicians used to (and still do) say the same thing about some of the theoretical physics work: “What’s the point if it doesn’t have absolute rigor?” But physics, like ml, has a lot of value in exploring intuition and in taking steps forward, even if it doesn’t meet the standards of mathematical rigor.\n\nPlus, a huge reason for this approach in ML is the relatively low cost of experiments. You can train models, tweak prompts, and run experiments without needing the kind of infrastructure or money required in other fields. I used to work in quantum machine learning, and the cost there is almost prohibitive—both the lack of tech and the expense of doing anything useful. In that community, it’s all about theoretical work understanding cost landscapes, trying to build a fundamental theory of learning, because experiments just aren’t feasible on a large scale yet. But I bet once qpus are as cheap as gpus, we’ll see people start prioritizing intuition-based experiments there too, just like in ML.\n\nI think it’s all about recognizing what kind of progress we’re aiming for. ML moves fast and it moves through iteration, intuition, and trial and error. It’s like art sometimes the beauty is in exploring without knowing exactly where you’re headed, but it’s critical to always publish and let the community know the results, be it trivial, wrong or exceptional.",
      "body_html": "<div class=\"md\"><p>I get where you’re coming from. Coming from theoretical physics myself, I often find ml papers a bit disappointing when it comes to theoretical rigor. The majority of ml papers—honestly, even a lot of engineering research—tend to lack the depth and rigor that you’d see in more foundational sciences. It feels like a lot of it is “fancy prompt engineering” or just intuition-based tinkering without a real theoretical backbone.</p>\n\n<p>That said, I’ve come to realize that ml/AI is fundamentally more engineering than pure science. The goal here isn’t always to understand everything at the most basic level. Instead, it’s to move the needle—build more powerful models, make progress in applications, make things that work even if we don’t fully understand why they work in detail. And that kind of progress has its own value.</p>\n\n<p>You could ask the same thing about even the “best” papers introducing new architectures—no one truly understands the fundamentals of why some of these things work. There’s only a handful of people working on the true fundamentals of learning theory. But does that make the work done by everyone else trivial or meaningless? Absolutely not. It’s useful, and it contributes to the field.</p>\n\n<p>Honestly, I see this argument a lot in different contexts. Mathematicians used to (and still do) say the same thing about some of the theoretical physics work: “What’s the point if it doesn’t have absolute rigor?” But physics, like ml, has a lot of value in exploring intuition and in taking steps forward, even if it doesn’t meet the standards of mathematical rigor.</p>\n\n<p>Plus, a huge reason for this approach in ML is the relatively low cost of experiments. You can train models, tweak prompts, and run experiments without needing the kind of infrastructure or money required in other fields. I used to work in quantum machine learning, and the cost there is almost prohibitive—both the lack of tech and the expense of doing anything useful. In that community, it’s all about theoretical work understanding cost landscapes, trying to build a fundamental theory of learning, because experiments just aren’t feasible on a large scale yet. But I bet once qpus are as cheap as gpus, we’ll see people start prioritizing intuition-based experiments there too, just like in ML.</p>\n\n<p>I think it’s all about recognizing what kind of progress we’re aiming for. ML moves fast and it moves through iteration, intuition, and trial and error. It’s like art sometimes the beauty is in exploring without knowing exactly where you’re headed, but it’s critical to always publish and let the community know the results, be it trivial, wrong or exceptional.</p>\n</div>",
      "created_utc": 1727830289.0,
      "score": 18,
      "ups": 18,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/1ftx04x/d_why_is_tree_of_thought_an_impactful_work/lpwkef3/",
      "parent_id": "t3_1ftx04x",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2024-10-01T17:51:29"
    },
    {
      "id": "lpvcsxx",
      "author": "trnka",
      "body": "I find the work interesting because it's combining modern approaches (LLMs) with classical AI approaches (ideas like planning or minimax search). I also find it interesting because AlphaGo's success was at least partly from finding a vaguely similar combination of modern approaches and classical approaches. I'm curious to see if there are additional, useful ways to combine the old and new.",
      "body_html": "<div class=\"md\"><p>I find the work interesting because it&#39;s combining modern approaches (LLMs) with classical AI approaches (ideas like planning or minimax search). I also find it interesting because AlphaGo&#39;s success was at least partly from finding a vaguely similar combination of modern approaches and classical approaches. I&#39;m curious to see if there are additional, useful ways to combine the old and new.</p>\n</div>",
      "created_utc": 1727814996.0,
      "score": 25,
      "ups": 25,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/1ftx04x/d_why_is_tree_of_thought_an_impactful_work/lpvcsxx/",
      "parent_id": "t3_1ftx04x",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2024-10-01T13:36:36"
    },
    {
      "id": "lpvdtb3",
      "author": "Triclops200",
      "body": "\\[caveat: I used to be a principal AI/ML researcher until health issues hit a couple years ago. Been keeping up with the literature since then, just haven't been doing AI/ML professionally again until the past few months or so\\]\n\nOne: there's a good bit of discussion around the fact that it's probably very similar to what's being used for o1, and some of the benchmarks behind that model are astonishingly good, imo.\n\nSecondly, I'm pretty sure  that the way it's set up it has a way to optimize (and I'm currently trying to formalize that it \\*tends to\\* under certain realistic conditions, maybe via a proximal optimization bound or PAC-bayes, both seem promising) such that it's essentially learning ways to embed approximate higher order gradients of regions of the loss landscape on the final output, basically learning how to generalize to out-of-domain data by learning patterns between various regions of the loss manifold. (Would love to chat more about that via email with you and/or your advisor if you shoot me a DM)",
      "body_html": "<div class=\"md\"><p>[caveat: I used to be a principal AI/ML researcher until health issues hit a couple years ago. Been keeping up with the literature since then, just haven&#39;t been doing AI/ML professionally again until the past few months or so]</p>\n\n<p>One: there&#39;s a good bit of discussion around the fact that it&#39;s probably very similar to what&#39;s being used for o1, and some of the benchmarks behind that model are astonishingly good, imo.</p>\n\n<p>Secondly, I&#39;m pretty sure  that the way it&#39;s set up it has a way to optimize (and I&#39;m currently trying to formalize that it *tends to* under certain realistic conditions, maybe via a proximal optimization bound or PAC-bayes, both seem promising) such that it&#39;s essentially learning ways to embed approximate higher order gradients of regions of the loss landscape on the final output, basically learning how to generalize to out-of-domain data by learning patterns between various regions of the loss manifold. (Would love to chat more about that via email with you and/or your advisor if you shoot me a DM)</p>\n</div>",
      "created_utc": 1727815303.0,
      "score": 12,
      "ups": 12,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/1ftx04x/d_why_is_tree_of_thought_an_impactful_work/lpvdtb3/",
      "parent_id": "t3_1ftx04x",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": true,
      "distinguished": null,
      "timestamp": "2024-10-01T13:41:43"
    },
    {
      "id": "lpyea3w",
      "author": null,
      "body": "Reasoning techniques such as CoT, ToT, ReACT, Self-Discover and whatnots are cheaper than reaching the next LLM scaling milestone, and they produce consistent results over a plethora of benchmarks.\n\nThe real issue here is that the beefy advancements in the field - fine-tuning reasoning models for improving those prompting techniques - are not published by ClosedAI and the likes and are kept as industry secret sauces. This doesn't preclude people from speculating and doing the good work of actively trying stuff: https://github.com/pseudotensor/open-strawberry",
      "body_html": "<div class=\"md\"><p>Reasoning techniques such as CoT, ToT, ReACT, Self-Discover and whatnots are cheaper than reaching the next LLM scaling milestone, and they produce consistent results over a plethora of benchmarks.</p>\n\n<p>The real issue here is that the beefy advancements in the field - fine-tuning reasoning models for improving those prompting techniques - are not published by ClosedAI and the likes and are kept as industry secret sauces. This doesn&#39;t preclude people from speculating and doing the good work of actively trying stuff: <a href=\"https://github.com/pseudotensor/open-strawberry\">https://github.com/pseudotensor/open-strawberry</a></p>\n</div>",
      "created_utc": 1727865085.0,
      "score": 3,
      "ups": 3,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/1ftx04x/d_why_is_tree_of_thought_an_impactful_work/lpyea3w/",
      "parent_id": "t3_1ftx04x",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2024-10-02T03:31:25"
    },
    {
      "id": "lpvfypd",
      "author": "Screye",
      "body": "2 different perspectives.\n\nLot of prompt engineering work reads like a philosophy or social science paper. It's understandable that you find it unprincipled, and feel a knee-jerk disdain for it. Starting 1990s, ML has kept moving away from its applied-math roots. Prompt engineering is another nail in that coffin. But, it is also another tool in your ML toolkit.\n\nGood systems engineers can use formal methods and build compilers, but they're also excellent software engineers. Similarly, excellent ML practitioners must know how to operate at the architecture level, data level, weights level and the prompts level. The number of ML teams doing foundational architecture work is going down by the year. On the other hand, knowing how to orchestrate LORAs, Routers, daisy-chained-SLMs, etc. allows you to leverage a bunch of low hanging fruit to provide disproportionate value. Ignoring it just because it is 'easy' is foolish.\n\nPersonally, effective prompt engineering loops give hints towards how to set up future RL/MDP workflows. What's most important is that it is effective and we don't understand why. Solutions that have this nature are usually high-potential areas ripe for exploitation by modelling them at a lower-level or earlier phase in training.",
      "body_html": "<div class=\"md\"><p>2 different perspectives.</p>\n\n<p>Lot of prompt engineering work reads like a philosophy or social science paper. It&#39;s understandable that you find it unprincipled, and feel a knee-jerk disdain for it. Starting 1990s, ML has kept moving away from its applied-math roots. Prompt engineering is another nail in that coffin. But, it is also another tool in your ML toolkit.</p>\n\n<p>Good systems engineers can use formal methods and build compilers, but they&#39;re also excellent software engineers. Similarly, excellent ML practitioners must know how to operate at the architecture level, data level, weights level and the prompts level. The number of ML teams doing foundational architecture work is going down by the year. On the other hand, knowing how to orchestrate LORAs, Routers, daisy-chained-SLMs, etc. allows you to leverage a bunch of low hanging fruit to provide disproportionate value. Ignoring it just because it is &#39;easy&#39; is foolish.</p>\n\n<p>Personally, effective prompt engineering loops give hints towards how to set up future RL/MDP workflows. What&#39;s most important is that it is effective and we don&#39;t understand why. Solutions that have this nature are usually high-potential areas ripe for exploitation by modelling them at a lower-level or earlier phase in training.</p>\n</div>",
      "created_utc": 1727815966.0,
      "score": 8,
      "ups": 8,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/1ftx04x/d_why_is_tree_of_thought_an_impactful_work/lpvfypd/",
      "parent_id": "t3_1ftx04x",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2024-10-01T13:52:46"
    },
    {
      "id": "lpvepd4",
      "author": null,
      "body": "[deleted]",
      "body_html": "<div class=\"md\"><p>[deleted]</p>\n</div>",
      "created_utc": 1727815579.0,
      "score": 8,
      "ups": 8,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/1ftx04x/d_why_is_tree_of_thought_an_impactful_work/lpvepd4/",
      "parent_id": "t3_1ftx04x",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2024-10-01T13:46:19"
    },
    {
      "id": "lpvel5z",
      "author": "SmolLM",
      "body": "It's not",
      "body_html": "<div class=\"md\"><p>It&#39;s not</p>\n</div>",
      "created_utc": 1727815543.0,
      "score": -4,
      "ups": -4,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/1ftx04x/d_why_is_tree_of_thought_an_impactful_work/lpvel5z/",
      "parent_id": "t3_1ftx04x",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2024-10-01T13:45:43"
    },
    {
      "id": "lpvi358",
      "author": null,
      "body": "The easier a paper is to read and implement, the larger citations it gathers. These prompt engineering papers can be easily reproduced by undergraduates with high school math understanding. So when they write introductory papers, they cite these as opposed to math heavy papers. Who cites matters more than the number. Today we do not have a way to measure who cites. Like an author with h index 40 citing your paper should have more weightage than an author with h index 5 citing your paper.",
      "body_html": "<div class=\"md\"><p>The easier a paper is to read and implement, the larger citations it gathers. These prompt engineering papers can be easily reproduced by undergraduates with high school math understanding. So when they write introductory papers, they cite these as opposed to math heavy papers. Who cites matters more than the number. Today we do not have a way to measure who cites. Like an author with h index 40 citing your paper should have more weightage than an author with h index 5 citing your paper.</p>\n</div>",
      "created_utc": 1727816628.0,
      "score": 43,
      "ups": 43,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/1ftx04x/d_why_is_tree_of_thought_an_impactful_work/lpvi358/",
      "parent_id": "t1_lpv2cj1",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2024-10-01T14:03:48"
    },
    {
      "id": "lpv6cb5",
      "author": "altmly",
      "body": "Welcome to any niche field where the authors already know each other from previous niche field ",
      "body_html": "<div class=\"md\"><p>Welcome to any niche field where the authors already know each other from previous niche field </p>\n</div>",
      "created_utc": 1727813003.0,
      "score": 9,
      "ups": 9,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/1ftx04x/d_why_is_tree_of_thought_an_impactful_work/lpv6cb5/",
      "parent_id": "t1_lpv2cj1",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2024-10-01T13:03:23"
    },
    {
      "id": "lq0a3k1",
      "author": "IDoCodingStuffs",
      "body": "> every ug interested in ml \n\nAbbreviating it like that makes them sound like hordes of cavemen",
      "body_html": "<div class=\"md\"><blockquote>\n<p>every ug interested in ml </p>\n</blockquote>\n\n<p>Abbreviating it like that makes them sound like hordes of cavemen</p>\n</div>",
      "created_utc": 1727890339.0,
      "score": 4,
      "ups": 4,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/1ftx04x/d_why_is_tree_of_thought_an_impactful_work/lq0a3k1/",
      "parent_id": "t1_lpv2cj1",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2024-10-02T10:32:19"
    },
    {
      "id": "lpvyk7g",
      "author": null,
      "body": "Also, I would probably just search for Tree of Thoughts: Deliberate Problem Solving with Large Language Models (Full Paper Review) in YouTube, there is not much 'depth' (the idea is simple) in the paper, a waste of time to read.\n\nAgain, the work is great, just simple enough to explain in the video.",
      "body_html": "<div class=\"md\"><p>Also, I would probably just search for Tree of Thoughts: Deliberate Problem Solving with Large Language Models (Full Paper Review) in YouTube, there is not much &#39;depth&#39; (the idea is simple) in the paper, a waste of time to read.</p>\n\n<p>Again, the work is great, just simple enough to explain in the video.</p>\n</div>",
      "created_utc": 1727822210.0,
      "score": 7,
      "ups": 7,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/1ftx04x/d_why_is_tree_of_thought_an_impactful_work/lpvyk7g/",
      "parent_id": "t1_lpvvk9c",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2024-10-01T15:36:50"
    },
    {
      "id": "lq0winw",
      "author": "new_name_who_dis_",
      "body": "Agreed. Prompt engineering sounds lazy but it works. Hell all of deep learning is built on laziness -- instead of actually studying linguistics for NLP / cameras, light, 3d geometry for computer vision / etc. you just throw a ton of compute and data at the problem and it works better.",
      "body_html": "<div class=\"md\"><p>Agreed. Prompt engineering sounds lazy but it works. Hell all of deep learning is built on laziness -- instead of actually studying linguistics for NLP / cameras, light, 3d geometry for computer vision / etc. you just throw a ton of compute and data at the problem and it works better.</p>\n</div>",
      "created_utc": 1727897477.0,
      "score": 2,
      "ups": 2,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/1ftx04x/d_why_is_tree_of_thought_an_impactful_work/lq0winw/",
      "parent_id": "t1_lpvvk9c",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2024-10-02T12:31:17"
    },
    {
      "id": "lpxvptx",
      "author": "idly",
      "body": "not every paper needs theoretical rigour, and often empirical L papers have too much 'theory' for an empirical study, but the majority of papers also lack empirical rigour. how many times have people been led down the wrong path because of believing the findings in a paper which don't reproduce or depend on an arbitrary random seed etc?",
      "body_html": "<div class=\"md\"><p>not every paper needs theoretical rigour, and often empirical L papers have too much &#39;theory&#39; for an empirical study, but the majority of papers also lack empirical rigour. how many times have people been led down the wrong path because of believing the findings in a paper which don&#39;t reproduce or depend on an arbitrary random seed etc?</p>\n</div>",
      "created_utc": 1727852194.0,
      "score": 2,
      "ups": 2,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/1ftx04x/d_why_is_tree_of_thought_an_impactful_work/lpxvptx/",
      "parent_id": "t1_lpwkef3",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2024-10-01T23:56:34"
    },
    {
      "id": "lpvi6ey",
      "author": "starfries",
      "body": "What is the loss you're talking about here?",
      "body_html": "<div class=\"md\"><p>What is the loss you&#39;re talking about here?</p>\n</div>",
      "created_utc": 1727816658.0,
      "score": 6,
      "ups": 6,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/1ftx04x/d_why_is_tree_of_thought_an_impactful_work/lpvi6ey/",
      "parent_id": "t1_lpvdtb3",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2024-10-01T14:04:18"
    },
    {
      "id": "lpvybjn",
      "author": "RedditLovingSun",
      "body": "We need an elo system!",
      "body_html": "<div class=\"md\"><p>We need an elo system!</p>\n</div>",
      "created_utc": 1727822122.0,
      "score": 24,
      "ups": 24,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/1ftx04x/d_why_is_tree_of_thought_an_impactful_work/lpvybjn/",
      "parent_id": "t1_lpvi358",
      "depth": 2,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2024-10-01T15:35:22"
    },
    {
      "id": "lpvjfk7",
      "author": null,
      "body": "I mean that's why people don't use Google scholar. All the bibliometrics databases universities pay for do a pagerank kind of thing",
      "body_html": "<div class=\"md\"><p>I mean that&#39;s why people don&#39;t use Google scholar. All the bibliometrics databases universities pay for do a pagerank kind of thing</p>\n</div>",
      "created_utc": 1727817059.0,
      "score": -4,
      "ups": -4,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/1ftx04x/d_why_is_tree_of_thought_an_impactful_work/lpvjfk7/",
      "parent_id": "t1_lpvi358",
      "depth": 2,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2024-10-01T14:10:59"
    },
    {
      "id": "lpvklb8",
      "author": "Triclops200",
      "body": "RLHF for PPO on both thought generation and valuation with standard simultaneous fine tuning on reasoning questions and human demonstrations. More or less standard loss functions (cross entropy, etc). I'm pretty sure there's a requirement for a regularizer as well (no surprises there) from some initial work.",
      "body_html": "<div class=\"md\"><p>RLHF for PPO on both thought generation and valuation with standard simultaneous fine tuning on reasoning questions and human demonstrations. More or less standard loss functions (cross entropy, etc). I&#39;m pretty sure there&#39;s a requirement for a regularizer as well (no surprises there) from some initial work.</p>\n</div>",
      "created_utc": 1727817434.0,
      "score": 5,
      "ups": 5,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/1ftx04x/d_why_is_tree_of_thought_an_impactful_work/lpvklb8/",
      "parent_id": "t1_lpvi6ey",
      "depth": 2,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2024-10-01T14:17:14"
    },
    {
      "id": "lpwk6vb",
      "author": "cosmic_timing",
      "body": "Hooohoo, that's gives me an idea",
      "body_html": "<div class=\"md\"><p>Hooohoo, that&#39;s gives me an idea</p>\n</div>",
      "created_utc": 1727830210.0,
      "score": 4,
      "ups": 4,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/1ftx04x/d_why_is_tree_of_thought_an_impactful_work/lpwk6vb/",
      "parent_id": "t1_lpvybjn",
      "depth": 3,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2024-10-01T17:50:10"
    },
    {
      "id": "lq9sizz",
      "author": "MachKeinDramaLlama",
      "body": "I mean, isn't PageRank pretty much perfect for meassuring the value of nodes based on the links to them?",
      "body_html": "<div class=\"md\"><p>I mean, isn&#39;t PageRank pretty much perfect for meassuring the value of nodes based on the links to them?</p>\n</div>",
      "created_utc": 1728030927.0,
      "score": 3,
      "ups": 3,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/1ftx04x/d_why_is_tree_of_thought_an_impactful_work/lq9sizz/",
      "parent_id": "t1_lpvybjn",
      "depth": 3,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2024-10-04T01:35:27"
    },
    {
      "id": "lpvkb55",
      "author": null,
      "body": "What do people use then if not google scholar for citations?",
      "body_html": "<div class=\"md\"><p>What do people use then if not google scholar for citations?</p>\n</div>",
      "created_utc": 1727817343.0,
      "score": 10,
      "ups": 10,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/1ftx04x/d_why_is_tree_of_thought_an_impactful_work/lpvkb55/",
      "parent_id": "t1_lpvjfk7",
      "depth": 3,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2024-10-01T14:15:43"
    },
    {
      "id": "lq4bbnj",
      "author": null,
      "body": "Which is ironic. You'd think google would use pagerank, seeing as its founders invented the algorithm.",
      "body_html": "<div class=\"md\"><p>Which is ironic. You&#39;d think google would use pagerank, seeing as its founders invented the algorithm.</p>\n</div>",
      "created_utc": 1727954305.0,
      "score": 2,
      "ups": 2,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/1ftx04x/d_why_is_tree_of_thought_an_impactful_work/lq4bbnj/",
      "parent_id": "t1_lpvjfk7",
      "depth": 3,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2024-10-03T04:18:25"
    },
    {
      "id": "lpvmdyd",
      "author": "starfries",
      "body": "Oh I see, like training it to act as both a policy network and value network? Honestly not a bad idea for agents. I'm still not following what you mean by learning patterns between regions of the loss manifold/approximating higher order gradients though",
      "body_html": "<div class=\"md\"><p>Oh I see, like training it to act as both a policy network and value network? Honestly not a bad idea for agents. I&#39;m still not following what you mean by learning patterns between regions of the loss manifold/approximating higher order gradients though</p>\n</div>",
      "created_utc": 1727818018.0,
      "score": 2,
      "ups": 2,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/1ftx04x/d_why_is_tree_of_thought_an_impactful_work/lpvmdyd/",
      "parent_id": "t1_lpvklb8",
      "depth": 3,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2024-10-01T14:26:58"
    },
    {
      "id": "lqwmxyh",
      "author": "Wheaties4brkfst",
      "body": "My first thought too",
      "body_html": "<div class=\"md\"><p>My first thought too</p>\n</div>",
      "created_utc": 1728372189.0,
      "score": 2,
      "ups": 2,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/1ftx04x/d_why_is_tree_of_thought_an_impactful_work/lqwmxyh/",
      "parent_id": "t1_lq9sizz",
      "depth": 4,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2024-10-08T00:23:09"
    },
    {
      "id": "lpxvqkz",
      "author": "Delacroid",
      "body": "Web of science",
      "body_html": "<div class=\"md\"><p>Web of science</p>\n</div>",
      "created_utc": 1727852208.0,
      "score": 2,
      "ups": 2,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/1ftx04x/d_why_is_tree_of_thought_an_impactful_work/lpxvqkz/",
      "parent_id": "t1_lpvkb55",
      "depth": 4,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2024-10-01T23:56:48"
    },
    {
      "id": "lpvpajc",
      "author": "Triclops200",
      "body": "Yeah exactly!  \nFor the second part:  \nMy reasoning is as follows:  \nSince ToT is using BFS/DFS (hell, any heuristic expanding graph search should work here), it can be thought of as learning to create good candidate thoughts to explore the space, and the V function can be considered a way of pruning the search heuristically, where the search is through the set of possible inputs to give to the model for the final answer/output. This can be seen as learning how to condition itself, based on task conditioning as provided by the user input, to better attempt to answer. This can be seen as modifying the error landscape, since the loss manifold is conditioned on both the input and the parameters of the model. Therefore, since it needs to both simultaneously optimize the model parameters for the final outputs \\*as well as\\* it's own thought generation (internal conditioning) into the same loss landscape during training, it can be seen as, in a way, encoding a representation of that gradient into its embedding space to make final answer generation more optimal under the standard LLM recurrence. (I.E. using the same model for V work tells it to learn how to not generate bad answers and G work tells it how to generate better answers/search the space simultaneously. The recurrance here let's it associate reasoning about its own performance and how to fix it with other signals in the data.)",
      "body_html": "<div class=\"md\"><p>Yeah exactly!<br/>\nFor the second part:<br/>\nMy reasoning is as follows:<br/>\nSince ToT is using BFS/DFS (hell, any heuristic expanding graph search should work here), it can be thought of as learning to create good candidate thoughts to explore the space, and the V function can be considered a way of pruning the search heuristically, where the search is through the set of possible inputs to give to the model for the final answer/output. This can be seen as learning how to condition itself, based on task conditioning as provided by the user input, to better attempt to answer. This can be seen as modifying the error landscape, since the loss manifold is conditioned on both the input and the parameters of the model. Therefore, since it needs to both simultaneously optimize the model parameters for the final outputs *as well as* it&#39;s own thought generation (internal conditioning) into the same loss landscape during training, it can be seen as, in a way, encoding a representation of that gradient into its embedding space to make final answer generation more optimal under the standard LLM recurrence. (I.E. using the same model for V work tells it to learn how to not generate bad answers and G work tells it how to generate better answers/search the space simultaneously. The recurrance here let&#39;s it associate reasoning about its own performance and how to fix it with other signals in the data.)</p>\n</div>",
      "created_utc": 1727818973.0,
      "score": 2,
      "ups": 2,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/1ftx04x/d_why_is_tree_of_thought_an_impactful_work/lpvpajc/",
      "parent_id": "t1_lpvmdyd",
      "depth": 4,
      "is_submitter": false,
      "stickied": false,
      "edited": true,
      "distinguished": null,
      "timestamp": "2024-10-01T14:42:53"
    },
    {
      "id": "lpvu7d5",
      "author": "starfries",
      "body": "Ah okay, thanks for explaining! I follow and agree with you up to here:\n> it's own thought generation (internal conditioning) into the same loss landscape during training\n\nbut I don't see how this follows:\n\n>encoding a representation of that gradient into its embedding space to make final answer generation more optimal under the standard LLM recurrence\n\nNormally I think of it as overlaying different loss functions (for example, L2 regularization is overlaying a particular loss function that only considers weights). So here I imagine the loss function of \"being a good value network\" and \"being a good policy network\" are being overlaid with the standard LLM loss of \"produce plausible outputs\". But I wouldn't say it necessarily learns to represent the gradients, unless I'm misunderstanding what you mean by encoding. (To be clear I don't think it *can't*, and actually it's an interesting question if there are gradients represented in there somewhere because it can already somewhat do this task, I just don't think it would be especially encouraged.)",
      "body_html": "<div class=\"md\"><p>Ah okay, thanks for explaining! I follow and agree with you up to here:</p>\n\n<blockquote>\n<p>it&#39;s own thought generation (internal conditioning) into the same loss landscape during training</p>\n</blockquote>\n\n<p>but I don&#39;t see how this follows:</p>\n\n<blockquote>\n<p>encoding a representation of that gradient into its embedding space to make final answer generation more optimal under the standard LLM recurrence</p>\n</blockquote>\n\n<p>Normally I think of it as overlaying different loss functions (for example, L2 regularization is overlaying a particular loss function that only considers weights). So here I imagine the loss function of &quot;being a good value network&quot; and &quot;being a good policy network&quot; are being overlaid with the standard LLM loss of &quot;produce plausible outputs&quot;. But I wouldn&#39;t say it necessarily learns to represent the gradients, unless I&#39;m misunderstanding what you mean by encoding. (To be clear I don&#39;t think it <em>can&#39;t</em>, and actually it&#39;s an interesting question if there are gradients represented in there somewhere because it can already somewhat do this task, I just don&#39;t think it would be especially encouraged.)</p>\n</div>",
      "created_utc": 1727820647.0,
      "score": 2,
      "ups": 2,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/1ftx04x/d_why_is_tree_of_thought_an_impactful_work/lpvu7d5/",
      "parent_id": "t1_lpvpajc",
      "depth": 5,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2024-10-01T15:10:47"
    },
    {
      "id": "lpw05rx",
      "author": "Triclops200",
      "body": "When I say the LLM \"encodes a representation of the gradient,\" I don’t mean it has explicit access to numerical gradients like backprop. But given the recursive structure, especially with the same model for thought generation and valuation, it starts to capture the relationships between how its generated paths influence the outcomes. Over time, it learns to optimize these paths, and this feedback loop essentially lets the model implicitly learn the gradient-like dynamics of the loss landscape. Despite not necessarily calculating higher-order gradients, it's building up a representation that approximates them as it optimizes both final outputs and intermediate thoughts. \n\n\nCurrently, I'm working on showing that this kind of behavior is expected under sufficient recursion and a large enough model. The system is not just overlaying losses, it’s recursively conditioning itself on its own outputs, which pushes it to develop an internal representation of how changes affect the entire process. This, in turn, impacts how it generalizes across different regions of the loss manifold, effectively encoding useful patterns that serve the same purpose as approximating higher-order gradients. Hope that makes more sense!",
      "body_html": "<div class=\"md\"><p>When I say the LLM &quot;encodes a representation of the gradient,&quot; I don’t mean it has explicit access to numerical gradients like backprop. But given the recursive structure, especially with the same model for thought generation and valuation, it starts to capture the relationships between how its generated paths influence the outcomes. Over time, it learns to optimize these paths, and this feedback loop essentially lets the model implicitly learn the gradient-like dynamics of the loss landscape. Despite not necessarily calculating higher-order gradients, it&#39;s building up a representation that approximates them as it optimizes both final outputs and intermediate thoughts. </p>\n\n<p>Currently, I&#39;m working on showing that this kind of behavior is expected under sufficient recursion and a large enough model. The system is not just overlaying losses, it’s recursively conditioning itself on its own outputs, which pushes it to develop an internal representation of how changes affect the entire process. This, in turn, impacts how it generalizes across different regions of the loss manifold, effectively encoding useful patterns that serve the same purpose as approximating higher-order gradients. Hope that makes more sense!</p>\n</div>",
      "created_utc": 1727822791.0,
      "score": 2,
      "ups": 2,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/1ftx04x/d_why_is_tree_of_thought_an_impactful_work/lpw05rx/",
      "parent_id": "t1_lpvu7d5",
      "depth": 6,
      "is_submitter": false,
      "stickied": false,
      "edited": true,
      "distinguished": null,
      "timestamp": "2024-10-01T15:46:31"
    },
    {
      "id": "lpxgzrc",
      "author": "wahnsinnwanscene",
      "body": "o1 supposedly uses golden traces of reasoning to boost its model during post training. But once training is done the representations are set within the model itself and there is no further generalization. Rather, i view the recursive boost the model gets when applying * of thoughts comes from pushing the model to explore/compose different segments of the manifold that just happens to output tokens that map to a coherent understanding of what an appropriate response might be.",
      "body_html": "<div class=\"md\"><p>o1 supposedly uses golden traces of reasoning to boost its model during post training. But once training is done the representations are set within the model itself and there is no further generalization. Rather, i view the recursive boost the model gets when applying * of thoughts comes from pushing the model to explore/compose different segments of the manifold that just happens to output tokens that map to a coherent understanding of what an appropriate response might be.</p>\n</div>",
      "created_utc": 1727843447.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/1ftx04x/d_why_is_tree_of_thought_an_impactful_work/lpxgzrc/",
      "parent_id": "t1_lpw05rx",
      "depth": 7,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2024-10-01T21:30:47"
    },
    {
      "id": "lpxilir",
      "author": "Triclops200",
      "body": "Interesting! Any sources on that? Because freezing weights during PPO without fine-tuning on the traces would certainly be a different scenario and very different than how RLHF is normally done (see here https://huggingface.co/blog/rlhf)",
      "body_html": "<div class=\"md\"><p>Interesting! Any sources on that? Because freezing weights during PPO without fine-tuning on the traces would certainly be a different scenario and very different than how RLHF is normally done (see here <a href=\"https://huggingface.co/blog/rlhf\">https://huggingface.co/blog/rlhf</a>)</p>\n</div>",
      "created_utc": 1727844284.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/1ftx04x/d_why_is_tree_of_thought_an_impactful_work/lpxilir/",
      "parent_id": "t1_lpxgzrc",
      "depth": 8,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2024-10-01T21:44:44"
    },
    {
      "id": "lpxt9b7",
      "author": "wahnsinnwanscene",
      "body": "o1 golden traces? It's from the various strawberry video explainers. I should be clearer.  The model once past all weight updates,rlhf,etc and relying only on queries & system prompts, can only index into its weights layer by layer. It stands to reason that it doesn't have a global data manifold, but features are disentangled enough that the different mechanistic processes are able to construct, compose and traverse manifolds that just happen to emit tokens that have a semblance of coherence. I'm pointing out the system doesn't learn in the sense of backprop or gradient descent but concede that a higher order form of learning takes place, but only in pushing the model into composing its own subspace.",
      "body_html": "<div class=\"md\"><p>o1 golden traces? It&#39;s from the various strawberry video explainers. I should be clearer.  The model once past all weight updates,rlhf,etc and relying only on queries &amp; system prompts, can only index into its weights layer by layer. It stands to reason that it doesn&#39;t have a global data manifold, but features are disentangled enough that the different mechanistic processes are able to construct, compose and traverse manifolds that just happen to emit tokens that have a semblance of coherence. I&#39;m pointing out the system doesn&#39;t learn in the sense of backprop or gradient descent but concede that a higher order form of learning takes place, but only in pushing the model into composing its own subspace.</p>\n</div>",
      "created_utc": 1727850589.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/1ftx04x/d_why_is_tree_of_thought_an_impactful_work/lpxt9b7/",
      "parent_id": "t1_lpxilir",
      "depth": 9,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2024-10-01T23:29:49"
    },
    {
      "id": "lpzf06z",
      "author": "Triclops200",
      "body": "I don't think that is correct reasoning: Everything I'm working on showing is during train-time (importantly including the rlhf stage). You can absolutely decompose the gradients of non-convex loss manifolds into more piecewise components (look up sub-gradients or fiber bundles. Even if those not exactly the techniques that it's optimizing for under the hood or explicitly introduced, the fact that those exist make the method possible. Other facts make it likely).  Lastly, being able to \"construct, compose and traverse manifolds that just happen to emit tokens that have a semblance of coherence\" during runtime explicitly requires the structures I'm discussing. You cannot do any of those without functional approximations/equivalents to gradients available, eapecially if you want to converge to something with the results it has shown on out of domain reasoning questions. Language has semantic meaning, that cannot be ignored when the semantics are tied to the loss function (as in RLHF)",
      "body_html": "<div class=\"md\"><p>I don&#39;t think that is correct reasoning: Everything I&#39;m working on showing is during train-time (importantly including the rlhf stage). You can absolutely decompose the gradients of non-convex loss manifolds into more piecewise components (look up sub-gradients or fiber bundles. Even if those not exactly the techniques that it&#39;s optimizing for under the hood or explicitly introduced, the fact that those exist make the method possible. Other facts make it likely).  Lastly, being able to &quot;construct, compose and traverse manifolds that just happen to emit tokens that have a semblance of coherence&quot; during runtime explicitly requires the structures I&#39;m discussing. You cannot do any of those without functional approximations/equivalents to gradients available, eapecially if you want to converge to something with the results it has shown on out of domain reasoning questions. Language has semantic meaning, that cannot be ignored when the semantics are tied to the loss function (as in RLHF)</p>\n</div>",
      "created_utc": 1727880467.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/1ftx04x/d_why_is_tree_of_thought_an_impactful_work/lpzf06z/",
      "parent_id": "t1_lpxt9b7",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": true,
      "distinguished": null,
      "timestamp": "2024-10-02T07:47:47"
    }
  ],
  "total_comments": 34,
  "fetched_at": "2025-09-13T20:47:28.522085"
}