{
  "submission": {
    "id": "11pgj86",
    "title": "[D] Simple Questions Thread",
    "author": "AutoModerator",
    "selftext": "Please post your questions here instead of creating a new thread. Encourage others who create new posts for questions to post here instead!\n\nThread will stay alive until next one so keep posting after the date in the title.\n\nThanks to everyone for answering questions in the previous thread!",
    "selftext_html": "<!-- SC_OFF --><div class=\"md\"><p>Please post your questions here instead of creating a new thread. Encourage others who create new posts for questions to post here instead!</p>\n\n<p>Thread will stay alive until next one so keep posting after the date in the title.</p>\n\n<p>Thanks to everyone for answering questions in the previous thread!</p>\n</div><!-- SC_ON -->",
    "url": "https://www.reddit.com/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/",
    "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/",
    "subreddit": "MachineLearning",
    "created_utc": 1678633225.0,
    "score": 31,
    "ups": 31,
    "downs": 0,
    "upvote_ratio": 0.88,
    "num_comments": 157,
    "is_self": true,
    "over_18": false,
    "spoiler": false,
    "stickied": false,
    "locked": false,
    "archived": false,
    "distinguished": null,
    "link_flair_text": "Discussion",
    "timestamp": "2023-03-12T08:00:25"
  },
  "comments": [
    {
      "id": "jbyrulz",
      "author": "kuraisle",
      "body": "Has anyone had any experience data mining BioArXiv? It's on a requester pays Amazon s3 bucket, which isn't something I've used before and I'm struggling to guess how much I would have to pay to retrieve a few thousand articles. Thanks!",
      "body_html": "<div class=\"md\"><p>Has anyone had any experience data mining BioArXiv? It&#39;s on a requester pays Amazon s3 bucket, which isn&#39;t something I&#39;ve used before and I&#39;m struggling to guess how much I would have to pay to retrieve a few thousand articles. Thanks!</p>\n</div>",
      "created_utc": 1678649951.0,
      "score": 5,
      "ups": 5,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jbyrulz/",
      "parent_id": "t3_11pgj86",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-12T12:39:11"
    },
    {
      "id": "jc5om1y",
      "author": "DreamMidnight",
      "body": "What is the basis of this rule of thumb in regression:\n\n\"a minimum of ten observations per predictor variable is required\"?\n\nWhat is the origin of this idea?",
      "body_html": "<div class=\"md\"><p>What is the basis of this rule of thumb in regression:</p>\n\n<p>&quot;a minimum of ten observations per predictor variable is required&quot;?</p>\n\n<p>What is the origin of this idea?</p>\n</div>",
      "created_utc": 1678772857.0,
      "score": 3,
      "ups": 3,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jc5om1y/",
      "parent_id": "t3_11pgj86",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-13T22:47:37"
    },
    {
      "id": "jca1rh1",
      "author": "Sonicxc",
      "body": "How can i train a model so that it detects severity of damage in a image. Which algo will suit for my need?",
      "body_html": "<div class=\"md\"><p>How can i train a model so that it detects severity of damage in a image. Which algo will suit for my need?</p>\n</div>",
      "created_utc": 1678878597.0,
      "score": 3,
      "ups": 3,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jca1rh1/",
      "parent_id": "t3_11pgj86",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-15T04:09:57"
    },
    {
      "id": "jd05tgt",
      "author": "djmaxm",
      "body": "I have a 4090 with 32GB of system RAM, but I am unable to run the 30B model because it exhausts the system memory and crashes. Is this expected? Do I need a bunch more RAM? Or am I doing something dumb and running the wrong model. I don't understand how the torrent model, the huggingface model, and the .pt file relate to each other...",
      "body_html": "<div class=\"md\"><p>I have a 4090 with 32GB of system RAM, but I am unable to run the 30B model because it exhausts the system memory and crashes. Is this expected? Do I need a bunch more RAM? Or am I doing something dumb and running the wrong model. I don&#39;t understand how the torrent model, the huggingface model, and the .pt file relate to each other...</p>\n</div>",
      "created_utc": 1679348536.0,
      "score": 3,
      "ups": 3,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jd05tgt/",
      "parent_id": "t3_11pgj86",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-20T14:42:16"
    },
    {
      "id": "jd07i7z",
      "author": null,
      "body": "Why is AI safety not a major topic of discussion here and in similar communities?\n\nI apologize if the non-technical nature of my question is inappropriate for the sub, but as you’ll see from my comment I think this is very important.\n\nI have been studying AI more and more over the past months (for perspective on my level that consists of Andrew Ng’s Deep Learning course, Kaggle competitions and simple projects, reading a few landmark papers and digging into transformers)\nThe more I learn, the more I am both concerned and hopeful. It seems all but certain to me that AI will completely change life as we know it in the next few decades, quite possibly the next few years if the current pace of progression continues. It could change life to something much, much better or much, much worse based on who develops it and how safely they do it.\n\nTo me safety is far and away to most important subfield in AI now, but is one of the least discussed. Even if you think there is a low chance of AI going haywire on its own, in my admittedly very non-expert view it’s obvious that we should be also concerned about the judgment and motives of the people developing and controlling the most powerful AIs, and the risks of such powerful tools being accessible to everyone. At the very least I would want discussion on actionable things we can all do as individuals. \n\nI feel a strong sense of duty to do what I can, even if that’s not much. I want to donate a percentage of my salary to funding AI safety, and I am looking whether I can effectively contribute with work to any AI safety organizations. I have a few of my own ideas along these lines; does anyone have any suggestions? I think we should also discuss ways to shift the incentives of major AI organizations. Maybe there isn’t a ton we can do (although there are a LOT of people looking, there is room for a major movement), but it’s certainly not zero.",
      "body_html": "<div class=\"md\"><p>Why is AI safety not a major topic of discussion here and in similar communities?</p>\n\n<p>I apologize if the non-technical nature of my question is inappropriate for the sub, but as you’ll see from my comment I think this is very important.</p>\n\n<p>I have been studying AI more and more over the past months (for perspective on my level that consists of Andrew Ng’s Deep Learning course, Kaggle competitions and simple projects, reading a few landmark papers and digging into transformers)\nThe more I learn, the more I am both concerned and hopeful. It seems all but certain to me that AI will completely change life as we know it in the next few decades, quite possibly the next few years if the current pace of progression continues. It could change life to something much, much better or much, much worse based on who develops it and how safely they do it.</p>\n\n<p>To me safety is far and away to most important subfield in AI now, but is one of the least discussed. Even if you think there is a low chance of AI going haywire on its own, in my admittedly very non-expert view it’s obvious that we should be also concerned about the judgment and motives of the people developing and controlling the most powerful AIs, and the risks of such powerful tools being accessible to everyone. At the very least I would want discussion on actionable things we can all do as individuals. </p>\n\n<p>I feel a strong sense of duty to do what I can, even if that’s not much. I want to donate a percentage of my salary to funding AI safety, and I am looking whether I can effectively contribute with work to any AI safety organizations. I have a few of my own ideas along these lines; does anyone have any suggestions? I think we should also discuss ways to shift the incentives of major AI organizations. Maybe there isn’t a ton we can do (although there are a LOT of people looking, there is room for a major movement), but it’s certainly not zero.</p>\n</div>",
      "created_utc": 1679349203.0,
      "score": 3,
      "ups": 3,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jd07i7z/",
      "parent_id": "t3_11pgj86",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-20T14:53:23"
    },
    {
      "id": "jcaary6",
      "author": "2lazy2buy",
      "body": "How is one achieving long context lengths for LLM? Chatgpt has a length 32k? Is the transformer decoder \"just\" that big?",
      "body_html": "<div class=\"md\"><p>How is one achieving long context lengths for LLM? Chatgpt has a length 32k? Is the transformer decoder &quot;just&quot; that big?</p>\n</div>",
      "created_utc": 1678883903.0,
      "score": 2,
      "ups": 2,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jcaary6/",
      "parent_id": "t3_11pgj86",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-15T05:38:23"
    },
    {
      "id": "jccin4h",
      "author": "BM-is-OP",
      "body": "When dealing with an imbalanced dataset, I have been taught to oversample on only the train  samples and not the entire dataset to avoid overfitting, however this was for structured text based data in pandas using simple models from sklearn. However is this still the case for image based datasets that will be trained on a CNN? I have been trying to oversample only the train data by applying augmentations to the images. However, for some reason I get a train accuracy of 1.0 and a validation accuracy of 0.25 which does not make sense to me on the very first epoch, where the numbers dont really change as the epochs progress which doesn't make sense to me. Should the image augmentations via oversamping be applied to the entire dataset? (fyi I am using PyTorch)",
      "body_html": "<div class=\"md\"><p>When dealing with an imbalanced dataset, I have been taught to oversample on only the train  samples and not the entire dataset to avoid overfitting, however this was for structured text based data in pandas using simple models from sklearn. However is this still the case for image based datasets that will be trained on a CNN? I have been trying to oversample only the train data by applying augmentations to the images. However, for some reason I get a train accuracy of 1.0 and a validation accuracy of 0.25 which does not make sense to me on the very first epoch, where the numbers dont really change as the epochs progress which doesn&#39;t make sense to me. Should the image augmentations via oversamping be applied to the entire dataset? (fyi I am using PyTorch)</p>\n</div>",
      "created_utc": 1678914746.0,
      "score": 2,
      "ups": 2,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jccin4h/",
      "parent_id": "t3_11pgj86",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-15T14:12:26"
    },
    {
      "id": "jce240r",
      "author": "rainnz",
      "body": "I have degree in CS but have not done anything with ML, AI, NN or CV.\n\nI want to create simple program, that I intend to run on Nvidia Jetson Nano,  that will process live HDMI video stream from a street video camera. If someone appears in the video feed, holding a sign with a specific sport's team symbol, like [Arizona Cardinals](https://content.sportslogos.net/logos/7/177/full/arizona_cardinals_logo_primary_20058304.png) - I want this to be detected right away and some action performed. Like sending an email. \n\nIs it something I can do with OpenCV's object detection? If not - please let me know what would be the appropriate framework I'd need to use for this.\n\nThank you.",
      "body_html": "<div class=\"md\"><p>I have degree in CS but have not done anything with ML, AI, NN or CV.</p>\n\n<p>I want to create simple program, that I intend to run on Nvidia Jetson Nano,  that will process live HDMI video stream from a street video camera. If someone appears in the video feed, holding a sign with a specific sport&#39;s team symbol, like <a href=\"https://content.sportslogos.net/logos/7/177/full/arizona_cardinals_logo_primary_20058304.png\">Arizona Cardinals</a> - I want this to be detected right away and some action performed. Like sending an email. </p>\n\n<p>Is it something I can do with OpenCV&#39;s object detection? If not - please let me know what would be the appropriate framework I&#39;d need to use for this.</p>\n\n<p>Thank you.</p>\n</div>",
      "created_utc": 1678938784.0,
      "score": 2,
      "ups": 2,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jce240r/",
      "parent_id": "t3_11pgj86",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-15T20:53:04"
    },
    {
      "id": "jcfidsx",
      "author": "Capital-Duty-744",
      "body": "What are the most important concepts that I need to know for ML? Possible courses are below:  \nAlgebra & Calculus II  \nAlgebra & Calculus III  \nBayesian Stats  \nProbability  \nMultivariate stats analysis  \nStochastic processes  \nTime series  \nStatistical inference  \n\n\nTo what extent should I know and be familiar with linear algebra?",
      "body_html": "<div class=\"md\"><p>What are the most important concepts that I need to know for ML? Possible courses are below:<br/>\nAlgebra &amp; Calculus II<br/>\nAlgebra &amp; Calculus III<br/>\nBayesian Stats<br/>\nProbability<br/>\nMultivariate stats analysis<br/>\nStochastic processes<br/>\nTime series<br/>\nStatistical inference  </p>\n\n<p>To what extent should I know and be familiar with linear algebra?</p>\n</div>",
      "created_utc": 1678974584.0,
      "score": 2,
      "ups": 2,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jcfidsx/",
      "parent_id": "t3_11pgj86",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-16T06:49:44"
    },
    {
      "id": "jcg3zlh",
      "author": "fteem",
      "body": "What happened with the WAYR (What Are You Reading) threads?",
      "body_html": "<div class=\"md\"><p>What happened with the WAYR (What Are You Reading) threads?</p>\n</div>",
      "created_utc": 1678983184.0,
      "score": 2,
      "ups": 2,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jcg3zlh/",
      "parent_id": "t3_11pgj86",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-16T09:13:04"
    },
    {
      "id": "jcgn73n",
      "author": "LeN3rd",
      "body": "Can anyone recommend a good, maintained and well organized MCMC python package? Everything i found was either not maintained, had only a single research group behind it, or had to many bugs for me to continue with that project. I want Tensorflow/Pytorch, but for MCMC sampling please.",
      "body_html": "<div class=\"md\"><p>Can anyone recommend a good, maintained and well organized MCMC python package? Everything i found was either not maintained, had only a single research group behind it, or had to many bugs for me to continue with that project. I want Tensorflow/Pytorch, but for MCMC sampling please.</p>\n</div>",
      "created_utc": 1678990405.0,
      "score": 2,
      "ups": 2,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jcgn73n/",
      "parent_id": "t3_11pgj86",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-16T11:13:25"
    },
    {
      "id": "jd59igg",
      "author": "asterisk2a",
      "body": "**Question about ML research breakthroughs and narratives.**\n\n[AlexNet](https://en.wikipedia.org/wiki/AlexNet) was not the first and not the fastest and not the CNN that won the most prices - using Nvidia GPU CUDA cores for acceleration. Then why is it so often named as the 'it' paper in the popular MSM & AI YouTube Channels narrative around AI? Even Jensen Huang, CEO of Nvidia mentioned it in his [keynote](https://youtu.be/DiGB5uAYKAg).\n\nIs it because AlexNet can be traced back to 'Made in America' and sold to Google? And co-author is Chief Science Officer at OpenAI? And the others aren't.",
      "body_html": "<div class=\"md\"><p><strong>Question about ML research breakthroughs and narratives.</strong></p>\n\n<p><a href=\"https://en.wikipedia.org/wiki/AlexNet\">AlexNet</a> was not the first and not the fastest and not the CNN that won the most prices - using Nvidia GPU CUDA cores for acceleration. Then why is it so often named as the &#39;it&#39; paper in the popular MSM &amp; AI YouTube Channels narrative around AI? Even Jensen Huang, CEO of Nvidia mentioned it in his <a href=\"https://youtu.be/DiGB5uAYKAg\">keynote</a>.</p>\n\n<p>Is it because AlexNet can be traced back to &#39;Made in America&#39; and sold to Google? And co-author is Chief Science Officer at OpenAI? And the others aren&#39;t.</p>\n</div>",
      "created_utc": 1679438707.0,
      "score": 2,
      "ups": 2,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jd59igg/",
      "parent_id": "t3_11pgj86",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-21T15:45:07"
    },
    {
      "id": "jd8qe6f",
      "author": "throwaway2676",
      "body": "When training LLMs to write code, is it standard to just make indentation and new line their own tokens?  Like '<\\n>' and <\\ind>' or something?\n\nFollow up: Are there any good models on HuggingFace that specialize in writing and explaining code?",
      "body_html": "<div class=\"md\"><p>When training LLMs to write code, is it standard to just make indentation and new line their own tokens?  Like &#39;&lt;\\n&gt;&#39; and &lt;\\ind&gt;&#39; or something?</p>\n\n<p>Follow up: Are there any good models on HuggingFace that specialize in writing and explaining code?</p>\n</div>",
      "created_utc": 1679505342.0,
      "score": 2,
      "ups": 2,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jd8qe6f/",
      "parent_id": "t3_11pgj86",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-22T10:15:42"
    },
    {
      "id": "jdbvolq",
      "author": "weaponized_lazyness",
      "body": "Is there a subreddit for more academic discussions on ML? This space has now been swarmed by LLM enthusiasts, which is fine but it's not the content I was looking for.",
      "body_html": "<div class=\"md\"><p>Is there a subreddit for more academic discussions on ML? This space has now been swarmed by LLM enthusiasts, which is fine but it&#39;s not the content I was looking for.</p>\n</div>",
      "created_utc": 1679559021.0,
      "score": 2,
      "ups": 2,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jdbvolq/",
      "parent_id": "t3_11pgj86",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-23T01:10:21"
    },
    {
      "id": "jdcb0vo",
      "author": "andrew21w",
      "body": "Why nobody uses polynomials as activation functions?\n\n\nMy mere perception is that polynomials are the best since they can approximate nearly any kind of function you like? So they're perfect.... \n\n\nBut why aren't they used?",
      "body_html": "<div class=\"md\"><p>Why nobody uses polynomials as activation functions?</p>\n\n<p>My mere perception is that polynomials are the best since they can approximate nearly any kind of function you like? So they&#39;re perfect.... </p>\n\n<p>But why aren&#39;t they used?</p>\n</div>",
      "created_utc": 1679571327.0,
      "score": 2,
      "ups": 2,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jdcb0vo/",
      "parent_id": "t3_11pgj86",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-23T04:35:27"
    },
    {
      "id": "jdfk435",
      "author": "JimiSlew3",
      "body": "Nublet question: is there anything linking LLMs and data analyst and visualizations yet? I saw a bit with MS Copilot and Excel. I want to know if there is anymore advanced in the works. Thanks!",
      "body_html": "<div class=\"md\"><p>Nublet question: is there anything linking LLMs and data analyst and visualizations yet? I saw a bit with MS Copilot and Excel. I want to know if there is anymore advanced in the works. Thanks!</p>\n</div>",
      "created_utc": 1679619199.0,
      "score": 2,
      "ups": 2,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jdfk435/",
      "parent_id": "t3_11pgj86",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-23T17:53:19"
    },
    {
      "id": "jdnwwdd",
      "author": "sampdoria_supporter",
      "body": "Does anybody else feel overwhelmed and frozen in the face of all this concurrent development and releases? I can't seem to even jump on much of what is going on because it seems like the next day will just flip the table.",
      "body_html": "<div class=\"md\"><p>Does anybody else feel overwhelmed and frozen in the face of all this concurrent development and releases? I can&#39;t seem to even jump on much of what is going on because it seems like the next day will just flip the table.</p>\n</div>",
      "created_utc": 1679776588.0,
      "score": 2,
      "ups": 2,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jdnwwdd/",
      "parent_id": "t3_11pgj86",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-25T13:36:28"
    },
    {
      "id": "jby8tfl",
      "author": null,
      "body": "Can machines learn to love",
      "body_html": "<div class=\"md\"><p>Can machines learn to love</p>\n</div>",
      "created_utc": 1678642068.0,
      "score": 4,
      "ups": 4,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jby8tfl/",
      "parent_id": "t3_11pgj86",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-12T10:27:48"
    },
    {
      "id": "jc1g0u9",
      "author": "I1onza",
      "body": "I'm a material engineering student and an outsider to the ML and AI community. During my studies I take notes on my laptop and don't have a quick and reliable solution for copying down simple graphs. With recent publicity of AI models I was wondering if someone already tried to train a model to draw graphs form natural language. DALL - E does it quite horribly (Cf. [picture](https://labs.openai.com/s/ivCMsF9hAV6KQUhfoyM8biqP) ). If you haven't heard of such a thing, maybe its a project you might find interesting to make.",
      "body_html": "<div class=\"md\"><p>I&#39;m a material engineering student and an outsider to the ML and AI community. During my studies I take notes on my laptop and don&#39;t have a quick and reliable solution for copying down simple graphs. With recent publicity of AI models I was wondering if someone already tried to train a model to draw graphs form natural language. DALL - E does it quite horribly (Cf. <a href=\"https://labs.openai.com/s/ivCMsF9hAV6KQUhfoyM8biqP\">picture</a> ). If you haven&#39;t heard of such a thing, maybe its a project you might find interesting to make.</p>\n</div>",
      "created_utc": 1678703089.0,
      "score": 0,
      "ups": 0,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jc1g0u9/",
      "parent_id": "t3_11pgj86",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-13T03:24:49"
    },
    {
      "id": "jd4ak8v",
      "author": "Gody_",
      "body": "Hello guys, would you consider this supervised or unsupervised learning?\n\n I am using Keras LSTM to generate new text, by tokenizing it, making n-grams from it and training the LSTM to predict the next word (token) by putting n-1 n-grams as a train sample, and as \"labels\" I am putting the last word (token) of the n-gram. Would you consider this supervised or unsupervised ML?  \n\nTechnically, I do have a label for every n-gram, its own last word, but the dataset itself was not labeled beforehand. As I am new to ML I am a little bit confused and even ChatGPT sometimes says that its supervised, and sometimes unsupervised ML. \n\nThanks for any answers.",
      "body_html": "<div class=\"md\"><p>Hello guys, would you consider this supervised or unsupervised learning?</p>\n\n<p>I am using Keras LSTM to generate new text, by tokenizing it, making n-grams from it and training the LSTM to predict the next word (token) by putting n-1 n-grams as a train sample, and as &quot;labels&quot; I am putting the last word (token) of the n-gram. Would you consider this supervised or unsupervised ML?  </p>\n\n<p>Technically, I do have a label for every n-gram, its own last word, but the dataset itself was not labeled beforehand. As I am new to ML I am a little bit confused and even ChatGPT sometimes says that its supervised, and sometimes unsupervised ML. </p>\n\n<p>Thanks for any answers.</p>\n</div>",
      "created_utc": 1679425236.0,
      "score": 0,
      "ups": 0,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jd4ak8v/",
      "parent_id": "t3_11pgj86",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-21T12:00:36"
    },
    {
      "id": "jbyl2wi",
      "author": "WesternLettuce0",
      "body": "I used distilbert and legalbert separately to produce embeddings for my documents. What is the best way to use the embeddings for classification? Do I create document level embeddings before training my classifiers? Do I combine the two embeddings?",
      "body_html": "<div class=\"md\"><p>I used distilbert and legalbert separately to produce embeddings for my documents. What is the best way to use the embeddings for classification? Do I create document level embeddings before training my classifiers? Do I combine the two embeddings?</p>\n</div>",
      "created_utc": 1678647117.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jbyl2wi/",
      "parent_id": "t3_11pgj86",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-12T11:51:57"
    },
    {
      "id": "jc1jts4",
      "author": "EcstaticStruggle",
      "body": "How do you combine hyper parameter optimization with early stopping in cross-validation for LightGBM?\n\nDo you: \n1) Use the same validation set for hyperparameter performance estimation as well as early stopping evaluation (e.g., 80% training, 20% early stopping + validation set)\n2) Create a separate fold within cross-validation for early stopping evaluation. (e.g. 80%, 10%, 10% training, early stopping, validation set)\n3) Set aside a different dataset altogether (like a test set) which is constantly used for early stopping across different cross-validation folds for early stopping evaluation.\n\nIn the case of 1) and 2), how would you use early stopping once you identified optimal hyperparameters? Normally, you would re-fit on the entire dataset with the best hyperparameters, but this removes the early stopping data.",
      "body_html": "<div class=\"md\"><p>How do you combine hyper parameter optimization with early stopping in cross-validation for LightGBM?</p>\n\n<p>Do you: \n1) Use the same validation set for hyperparameter performance estimation as well as early stopping evaluation (e.g., 80% training, 20% early stopping + validation set)\n2) Create a separate fold within cross-validation for early stopping evaluation. (e.g. 80%, 10%, 10% training, early stopping, validation set)\n3) Set aside a different dataset altogether (like a test set) which is constantly used for early stopping across different cross-validation folds for early stopping evaluation.</p>\n\n<p>In the case of 1) and 2), how would you use early stopping once you identified optimal hyperparameters? Normally, you would re-fit on the entire dataset with the best hyperparameters, but this removes the early stopping data.</p>\n</div>",
      "created_utc": 1678706035.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jc1jts4/",
      "parent_id": "t3_11pgj86",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-13T04:13:55"
    },
    {
      "id": "jc1uk2f",
      "author": "denxiaopin",
      "body": "How difficult and time consuming is it to teach AI how to choose glasses according to the type of face with tools we have today?",
      "body_html": "<div class=\"md\"><p>How difficult and time consuming is it to teach AI how to choose glasses according to the type of face with tools we have today?</p>\n</div>",
      "created_utc": 1678712551.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jc1uk2f/",
      "parent_id": "t3_11pgj86",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-13T06:02:31"
    },
    {
      "id": "jc21eac",
      "author": "bangbangwo",
      "body": "Hey, I'm new at ML and I have a question. I've created a LSTM and XGBoost model etc, trained it, evaluated it etc. But now, how do I actually forecast future data ? Do you have a notebook where the creator actually plot predictions?  I can't seem to find one !",
      "body_html": "<div class=\"md\"><p>Hey, I&#39;m new at ML and I have a question. I&#39;ve created a LSTM and XGBoost model etc, trained it, evaluated it etc. But now, how do I actually forecast future data ? Do you have a notebook where the creator actually plot predictions?  I can&#39;t seem to find one !</p>\n</div>",
      "created_utc": 1678715838.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jc21eac/",
      "parent_id": "t3_11pgj86",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-13T06:57:18"
    },
    {
      "id": "jc2ictg",
      "author": "AnomalyNexus",
      "body": "Do I need a specific GPU generation for 4bit weights? Or just anything that supports tensorflow/pytorch?",
      "body_html": "<div class=\"md\"><p>Do I need a specific GPU generation for 4bit weights? Or just anything that supports tensorflow/pytorch?</p>\n</div>",
      "created_utc": 1678722899.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jc2ictg/",
      "parent_id": "t3_11pgj86",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-13T08:54:59"
    },
    {
      "id": "jc2thhm",
      "author": "TwoTurnWin",
      "body": "So I'm working with the UrbanSound 8k set on Kaggle.\n\nI want to try two approaches:\n\n* MFCCs and Mels for image classification.\n* Raw audio data classification.\n\nWould a 1DCNN work for both approaches?",
      "body_html": "<div class=\"md\"><p>So I&#39;m working with the UrbanSound 8k set on Kaggle.</p>\n\n<p>I want to try two approaches:</p>\n\n<ul>\n<li>MFCCs and Mels for image classification.</li>\n<li>Raw audio data classification.</li>\n</ul>\n\n<p>Would a 1DCNN work for both approaches?</p>\n</div>",
      "created_utc": 1678727200.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jc2thhm/",
      "parent_id": "t3_11pgj86",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-13T10:06:40"
    },
    {
      "id": "jc4khxj",
      "author": "towsif110",
      "body": "What would be the way to detect any malicious nodes by machine learning? Let's say, I have datasets of RF signals of three kinds of drones. But my target is to detect any malicious drone except the drones I possess. I have two ideas: one is to use label two drones as good and the remaining one as malicious and my othe idea is to use unsupervised learning. Is there any better way?",
      "body_html": "<div class=\"md\"><p>What would be the way to detect any malicious nodes by machine learning? Let&#39;s say, I have datasets of RF signals of three kinds of drones. But my target is to detect any malicious drone except the drones I possess. I have two ideas: one is to use label two drones as good and the remaining one as malicious and my othe idea is to use unsupervised learning. Is there any better way?</p>\n</div>",
      "created_utc": 1678752350.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jc4khxj/",
      "parent_id": "t3_11pgj86",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-13T17:05:50"
    },
    {
      "id": "jc5a9kk",
      "author": "Anthony-Z-Z",
      "body": "What are some good YouTube channels to learn Machine learning?",
      "body_html": "<div class=\"md\"><p>What are some good YouTube channels to learn Machine learning?</p>\n</div>",
      "created_utc": 1678764095.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jc5a9kk/",
      "parent_id": "t3_11pgj86",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-13T20:21:35"
    },
    {
      "id": "jc5edo3",
      "author": "Neeraj666",
      "body": "I am looking to build a ML model which can analyse answers for behavioural interview questions and provide a rating? e.g. Talk about a challenging situation at work and how did you overcome that.. wondering where should I start and which algorithms to focus on etc.",
      "body_html": "<div class=\"md\"><p>I am looking to build a ML model which can analyse answers for behavioural interview questions and provide a rating? e.g. Talk about a challenging situation at work and how did you overcome that.. wondering where should I start and which algorithms to focus on etc.</p>\n</div>",
      "created_utc": 1678766294.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jc5edo3/",
      "parent_id": "t3_11pgj86",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-13T20:58:14"
    },
    {
      "id": "jc5g7vm",
      "author": "tiddysiddy",
      "body": "I have a codebase I want to train GPT on so that I can ask it questions. Is there any way to accomplish this with either GPT or any other LLM?\n\nMy current challenge is the tuneable davinci model from openAi is not as good as text-davinci and gpt turbo. But also the finetuning is only based on simple labelled data. I want it to be able to interpret my codebase on its own and train up a version of an LLM which understands and can come up with ideas \n\nIs this a long shot? I've noticed Bing can sometimes search up pages of documentation and gives decent instructions",
      "body_html": "<div class=\"md\"><p>I have a codebase I want to train GPT on so that I can ask it questions. Is there any way to accomplish this with either GPT or any other LLM?</p>\n\n<p>My current challenge is the tuneable davinci model from openAi is not as good as text-davinci and gpt turbo. But also the finetuning is only based on simple labelled data. I want it to be able to interpret my codebase on its own and train up a version of an LLM which understands and can come up with ideas </p>\n\n<p>Is this a long shot? I&#39;ve noticed Bing can sometimes search up pages of documentation and gives decent instructions</p>\n</div>",
      "created_utc": 1678767345.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jc5g7vm/",
      "parent_id": "t3_11pgj86",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-13T21:15:45"
    },
    {
      "id": "jc5gfc3",
      "author": "nitdit",
      "body": "What is stroke data? (sure, it is not the heart stroke)",
      "body_html": "<div class=\"md\"><p>What is stroke data? (sure, it is not the heart stroke)</p>\n</div>",
      "created_utc": 1678767467.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jc5gfc3/",
      "parent_id": "t3_11pgj86",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-13T21:17:47"
    },
    {
      "id": "jc5s85o",
      "author": "mmmfritz",
      "body": "Fact checking. Any open source models or people working on fact checking?",
      "body_html": "<div class=\"md\"><p>Fact checking. Any open source models or people working on fact checking?</p>\n</div>",
      "created_utc": 1678775672.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jc5s85o/",
      "parent_id": "t3_11pgj86",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-13T23:34:32"
    },
    {
      "id": "jc7szbg",
      "author": "No_Complaint_1304",
      "body": "Complete beginner looking for insight\n\nI made an extremely efficient algorithm in C that skim through a data base and search for words, I want to add a feature that if it is not found the program can somehow understand  the context and predict what is the actual word intended and also conjugate the verbs accordingly. I have no idea if what I am saying is crazy hard to implement or can easily be done by someone with experience. This field interest me a lot and i will definitely come back to this sub sooner or later, but right now i don’t have time to dig in this subject, I just want to finish this project, slap a good looking gui and get over with it. Can I achieve what i stated above in a week or am i just dreaming? If it is possible what resources do you think I should be looking at? Ty :>",
      "body_html": "<div class=\"md\"><p>Complete beginner looking for insight</p>\n\n<p>I made an extremely efficient algorithm in C that skim through a data base and search for words, I want to add a feature that if it is not found the program can somehow understand  the context and predict what is the actual word intended and also conjugate the verbs accordingly. I have no idea if what I am saying is crazy hard to implement or can easily be done by someone with experience. This field interest me a lot and i will definitely come back to this sub sooner or later, but right now i don’t have time to dig in this subject, I just want to finish this project, slap a good looking gui and get over with it. Can I achieve what i stated above in a week or am i just dreaming? If it is possible what resources do you think I should be looking at? Ty :&gt;</p>\n</div>",
      "created_utc": 1678815993.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jc7szbg/",
      "parent_id": "t3_11pgj86",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-14T10:46:33"
    },
    {
      "id": "jc8ynrt",
      "author": "Abradolf--Lincler",
      "body": "Learning about language transformers and I’m a bit confused.\n\nIt seems like the tutorials on transformers always make input sequences (ie. Text files batched to 100 words per window) the same length to help with batching.\n\nDoesn’t that mean that the model will only work with that exact sequence length? How do you efficiently train a model to work with any sequence length, such as shorter sequences with no padding and longer sequences than the batched sequence length?\n\nI see attention models advertised as having an infinite window, are there any good resources/tutorials to explain how to make a model like this?",
      "body_html": "<div class=\"md\"><p>Learning about language transformers and I’m a bit confused.</p>\n\n<p>It seems like the tutorials on transformers always make input sequences (ie. Text files batched to 100 words per window) the same length to help with batching.</p>\n\n<p>Doesn’t that mean that the model will only work with that exact sequence length? How do you efficiently train a model to work with any sequence length, such as shorter sequences with no padding and longer sequences than the batched sequence length?</p>\n\n<p>I see attention models advertised as having an infinite window, are there any good resources/tutorials to explain how to make a model like this?</p>\n</div>",
      "created_utc": 1678850807.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jc8ynrt/",
      "parent_id": "t3_11pgj86",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-14T20:26:47"
    },
    {
      "id": "jcc0m1l",
      "author": null,
      "body": "What's the place, if any, to post a job opening?",
      "body_html": "<div class=\"md\"><p>What&#39;s the place, if any, to post a job opening?</p>\n</div>",
      "created_utc": 1678908089.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jcc0m1l/",
      "parent_id": "t3_11pgj86",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-15T12:21:29"
    },
    {
      "id": "jccbh4w",
      "author": null,
      "body": "[deleted]",
      "body_html": "<div class=\"md\"><p>[deleted]</p>\n</div>",
      "created_utc": 1678912088.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jccbh4w/",
      "parent_id": "t3_11pgj86",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-15T13:28:08"
    },
    {
      "id": "jccekvp",
      "author": "ViceOA",
      "body": "Precious Advices About AI-supported Audio Classification Model  \n\n\nHello everyone,I'm Omer.  \nI am new in this group and writing from Turkey. I need very valuable advice from you precious researchers.  \nI am a PhD program student in the department of music technology. I have been working in the field of sound design and audio post-production for about 8 years. For the last 6 months, I have been doing research on AI-supported audio classification.My goal is to design an audio classifier to be used in the classification of audio libraries. Let me explain with an example as follows; I have a sound bank with 30 different classes and 1000 sounds in each class (such as bird, wind, door closing, footsteps etc.).  \nI want to train an artificial neural network with this sound bank. This network will produce labels as output. I also have various complex signals (imagine a single sound track with different sound sources like bird, wind, fire, etc.). When I give a complex signal to this network for testing, it will give me the relevant labels.I have been doing research on this system for 6 months and if I succeed, I want to write my PhD thesis on this subject. I need some advice from you, my dear friends, about this network. For example, which features should I look at for classification? Or what kind of artificial intelligence algorithm should I use?  \nAny advice you say you should definitely read this article or that article on this subject.I apologize if I've given you a headache. I really need your advice. Please guide me. Thank you very much in advance.",
      "body_html": "<div class=\"md\"><p>Precious Advices About AI-supported Audio Classification Model  </p>\n\n<p>Hello everyone,I&#39;m Omer.<br/>\nI am new in this group and writing from Turkey. I need very valuable advice from you precious researchers.<br/>\nI am a PhD program student in the department of music technology. I have been working in the field of sound design and audio post-production for about 8 years. For the last 6 months, I have been doing research on AI-supported audio classification.My goal is to design an audio classifier to be used in the classification of audio libraries. Let me explain with an example as follows; I have a sound bank with 30 different classes and 1000 sounds in each class (such as bird, wind, door closing, footsteps etc.).<br/>\nI want to train an artificial neural network with this sound bank. This network will produce labels as output. I also have various complex signals (imagine a single sound track with different sound sources like bird, wind, fire, etc.). When I give a complex signal to this network for testing, it will give me the relevant labels.I have been doing research on this system for 6 months and if I succeed, I want to write my PhD thesis on this subject. I need some advice from you, my dear friends, about this network. For example, which features should I look at for classification? Or what kind of artificial intelligence algorithm should I use?<br/>\nAny advice you say you should definitely read this article or that article on this subject.I apologize if I&#39;ve given you a headache. I really need your advice. Please guide me. Thank you very much in advance.</p>\n</div>",
      "created_utc": 1678913229.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jccekvp/",
      "parent_id": "t3_11pgj86",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-15T13:47:09"
    },
    {
      "id": "jccqitv",
      "author": "Batteredcode",
      "body": "I'm looking to be able to train a model that is suited to taking an image and reconstructing it with additional information, for example, taking R&G channels for an image and recreating it with the addition of the B channel. On first glance it seems like an in-painting model would be best suited to this, and treat the missing information as the mask, however I don't know if this assumption is correct as I've not got too much experience with those kinds of models. Additionally, I'm looking to progress from a really simple baseline to something more complex, so I was wondering if an architecture of a simple CNN or an autoencoder trained to output the target image given image missing information, but I may be way off here. Any help greatly appreciated!",
      "body_html": "<div class=\"md\"><p>I&#39;m looking to be able to train a model that is suited to taking an image and reconstructing it with additional information, for example, taking R&amp;G channels for an image and recreating it with the addition of the B channel. On first glance it seems like an in-painting model would be best suited to this, and treat the missing information as the mask, however I don&#39;t know if this assumption is correct as I&#39;ve not got too much experience with those kinds of models. Additionally, I&#39;m looking to progress from a really simple baseline to something more complex, so I was wondering if an architecture of a simple CNN or an autoencoder trained to output the target image given image missing information, but I may be way off here. Any help greatly appreciated!</p>\n</div>",
      "created_utc": 1678917785.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jccqitv/",
      "parent_id": "t3_11pgj86",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-15T15:03:05"
    },
    {
      "id": "jcf9ag7",
      "author": "ilrazziatore",
      "body": "In your job as data scientists have you ever had to compare the quality of the probabilistic forecasts of 2 different models? if so, how do you proceed?",
      "body_html": "<div class=\"md\"><p>In your job as data scientists have you ever had to compare the quality of the probabilistic forecasts of 2 different models? if so, how do you proceed?</p>\n</div>",
      "created_utc": 1678970235.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jcf9ag7/",
      "parent_id": "t3_11pgj86",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-16T05:37:15"
    },
    {
      "id": "jcjovuc",
      "author": "shiva_2176",
      "body": "Could someone please recommend a machine learning algorithm to create a \"Flood Risk Matrix\"? Additionally, any article or video tutorial on this subject that elaborates on methodology is highly desired.",
      "body_html": "<div class=\"md\"><p>Could someone please recommend a machine learning algorithm to create a &quot;Flood Risk Matrix&quot;? Additionally, any article or video tutorial on this subject that elaborates on methodology is highly desired.</p>\n</div>",
      "created_utc": 1679046354.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jcjovuc/",
      "parent_id": "t3_11pgj86",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-17T02:45:54"
    },
    {
      "id": "jckpovo",
      "author": "f-d-t777",
      "body": "**Subject: Spacecraft image analysis using computer vision**\n\n&#x200B;\n\nHi guys,\n\nIm looking to develop a system that uses computer vision algorithms to analyze images captured by spacecraft cameras and identify potential safety hazards or security threats. For example, the system could detect debris or other objects in orbit that could pose a risk to spacecraft.\n\nI am looking to do this using all AWS tools. I am pretty new to this and am developing a technology architecture project around this topic to present for a program I'm doing.\n\nHow would I go about approaching/doing this? I am looking to find/create my own mock datasets as well as present the alogrithm/code I used to train my model. More specifically, I am focusing on these aspects for my project:  \n\n\nPreprocess the images: Preprocess the images to improve their quality and prepare them for analysis. This could include cropping, resizing, and adjusting the brightness and contrast of the images.\r  \n\r  \nTrain the computer vision algorithms: Train the computer vision algorithms using the dataset of images. There are various computer vision techniques that could be used, such as object detection, segmentation, or classification. The specific technique will depend on the requirements of the system.\n\n&#x200B;\n\n In addition, it would be cool to have some sort of hardware/interactive portion that actually utilizes a camera to detect things in space. That can be implemented into the system. Once the computer vision algorithms have been trained and evaluated, implement the system. This could involve integrating the algorithms into a larger software system that can process images captured by spacecraft cameras in real-time.\n\nThank you",
      "body_html": "<div class=\"md\"><p><strong>Subject: Spacecraft image analysis using computer vision</strong></p>\n\n<p>&#x200B;</p>\n\n<p>Hi guys,</p>\n\n<p>Im looking to develop a system that uses computer vision algorithms to analyze images captured by spacecraft cameras and identify potential safety hazards or security threats. For example, the system could detect debris or other objects in orbit that could pose a risk to spacecraft.</p>\n\n<p>I am looking to do this using all AWS tools. I am pretty new to this and am developing a technology architecture project around this topic to present for a program I&#39;m doing.</p>\n\n<p>How would I go about approaching/doing this? I am looking to find/create my own mock datasets as well as present the alogrithm/code I used to train my model. More specifically, I am focusing on these aspects for my project:  </p>\n\n<p>Preprocess the images: Preprocess the images to improve their quality and prepare them for analysis. This could include cropping, resizing, and adjusting the brightness and contrast of the images.</p>\n\n<p>Train the computer vision algorithms: Train the computer vision algorithms using the dataset of images. There are various computer vision techniques that could be used, such as object detection, segmentation, or classification. The specific technique will depend on the requirements of the system.</p>\n\n<p>&#x200B;</p>\n\n<p>In addition, it would be cool to have some sort of hardware/interactive portion that actually utilizes a camera to detect things in space. That can be implemented into the system. Once the computer vision algorithms have been trained and evaluated, implement the system. This could involve integrating the algorithms into a larger software system that can process images captured by spacecraft cameras in real-time.</p>\n\n<p>Thank you</p>\n</div>",
      "created_utc": 1679066273.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jckpovo/",
      "parent_id": "t3_11pgj86",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": true,
      "distinguished": null,
      "timestamp": "2023-03-17T08:17:53"
    },
    {
      "id": "jclwgtg",
      "author": "gonomon",
      "body": "**Subject: Generating Synthetic Data for Human Action Recognition**  \nHello,\n\n  \nIn my master's thesis, I generated a realistic dataset that  \ncan be used for human action recognition (using the Unity engine). The dataset  \ncontains 2D - 3D pose information and RGB videos. I wanted to test the effects  \nof this dataset on real-world action detection (directly on videosYouTube) when  \nthe classifier is trained with synthetic data in addition to real-data (NTU  \n120).  \nI want to use skeleton-based action recognition methodology  \n(since it outperforms RGB-only methodologies for NTU 120) and to achieve this I  \napplied a pose estimator to videos from YouTube, our synthetic dataset, and  \nNTU120 and trained them since I believe instead of using directly sterile  \nground truth information of our dataset, I can apply pose estimator and use  \nthose pose informations directly instead of worrying with domain adaptation  \nstrategies.  \nQuestion is: Should I have directly used ground truth pose  \ninformation of our synthetic data in trainings with real-data, or the thing I  \ndid does make sense? If there is any usage of pose estimators as domain  \nadaptation methods, I would be extremely happy if you can share the papers when  \ncommenting.  \nBest,",
      "body_html": "<div class=\"md\"><p><strong>Subject: Generating Synthetic Data for Human Action Recognition</strong><br/>\nHello,</p>\n\n<p>In my master&#39;s thesis, I generated a realistic dataset that<br/>\ncan be used for human action recognition (using the Unity engine). The dataset<br/>\ncontains 2D - 3D pose information and RGB videos. I wanted to test the effects<br/>\nof this dataset on real-world action detection (directly on videosYouTube) when<br/>\nthe classifier is trained with synthetic data in addition to real-data (NTU<br/>\n120).<br/>\nI want to use skeleton-based action recognition methodology<br/>\n(since it outperforms RGB-only methodologies for NTU 120) and to achieve this I<br/>\napplied a pose estimator to videos from YouTube, our synthetic dataset, and<br/>\nNTU120 and trained them since I believe instead of using directly sterile<br/>\nground truth information of our dataset, I can apply pose estimator and use<br/>\nthose pose informations directly instead of worrying with domain adaptation<br/>\nstrategies.<br/>\nQuestion is: Should I have directly used ground truth pose<br/>\ninformation of our synthetic data in trainings with real-data, or the thing I<br/>\ndid does make sense? If there is any usage of pose estimators as domain<br/>\nadaptation methods, I would be extremely happy if you can share the papers when<br/>\ncommenting.<br/>\nBest,</p>\n</div>",
      "created_utc": 1679082758.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jclwgtg/",
      "parent_id": "t3_11pgj86",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-17T12:52:38"
    },
    {
      "id": "jcmhn3k",
      "author": "myself991",
      "body": "Hi everybody,\n\nI forgot to submit my file for a conference, but cmt3 submission section was open about 45 minutes passed the deadline. Therefore, I could upload it there.\n\nI was wondering if anybody had any experience with submitting supplementary material to cmt3 for a conference an hour after the deadline? Are they going to remove the paper, although they kept the uploading section open? \n\nAlso, do conferences normally set deadline in cmt3 a little more than after deadline?\n\nThanks,",
      "body_html": "<div class=\"md\"><p>Hi everybody,</p>\n\n<p>I forgot to submit my file for a conference, but cmt3 submission section was open about 45 minutes passed the deadline. Therefore, I could upload it there.</p>\n\n<p>I was wondering if anybody had any experience with submitting supplementary material to cmt3 for a conference an hour after the deadline? Are they going to remove the paper, although they kept the uploading section open? </p>\n\n<p>Also, do conferences normally set deadline in cmt3 a little more than after deadline?</p>\n\n<p>Thanks,</p>\n</div>",
      "created_utc": 1679091349.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jcmhn3k/",
      "parent_id": "t3_11pgj86",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-17T15:15:49"
    },
    {
      "id": "jcuh7ya",
      "author": "Jonathan358",
      "body": "Hello, I have a very simple question but cannot find any info on:\n\nHow to create an exponential range (squared) for hyperparameter values to be tuned? E.g. from 2-64, increament in steps of 2^2?\n\nNot looking for a complicated solution involving lists, ect.\n\n    ff_dim=hp.Int('ff_dim', min_value=2, max_value=64, step=n^2)\n\nedit: solved with, sampling=\"log\"",
      "body_html": "<div class=\"md\"><p>Hello, I have a very simple question but cannot find any info on:</p>\n\n<p>How to create an exponential range (squared) for hyperparameter values to be tuned? E.g. from 2-64, increament in steps of 2<sup>2?</sup></p>\n\n<p>Not looking for a complicated solution involving lists, ect.</p>\n\n<pre><code>ff_dim=hp.Int(&#39;ff_dim&#39;, min_value=2, max_value=64, step=n^2)\n</code></pre>\n\n<p>edit: solved with, sampling=&quot;log&quot;</p>\n</div>",
      "created_utc": 1679247375.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jcuh7ya/",
      "parent_id": "t3_11pgj86",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": true,
      "distinguished": null,
      "timestamp": "2023-03-19T10:36:15"
    },
    {
      "id": "jcvak4c",
      "author": "rylo_ren_",
      "body": "Hi everyone! This is a simple troubleshooting question. I'm in my master's program for python and I  keep running into an issue when I try running this code for a linear regression model: \n\n    airfares_lm = LinearRegression(normalize=True)\nairfares_lm.fit(train_X, train_y)\n\nprint('intercept ', airfares_lm.intercept_)\nprint(pd.DataFrame({'Predictor': X.columns, 'coefficient': airfares_lm.coef_}))\n\nprint('Training set')\nregressionSummary(train_y, airfares_lm.predict(train_X))\nprint('Validation set')\nregressionSummary(valid_y, airfares_lm.predict(valid_X))\n\nIt keeps returning this error:\n\n    ---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\n/var/folders/j1/1b6bkxw165zbtsk8tyf9y8dc0000gn/T/ipykernel_21423/2993181547.py in <cell line: 1>()\n----> 1 airfares_lm = LinearRegression(normalize=True)\n      2 airfares_lm.fit(train_X, train_y)\n      3 \n      4 # print coefficients\n      5 print('intercept ', airfares_lm.intercept_)\n\nTypeError: __init__() got an unexpected keyword argument 'normalize'\n\n\nI'm really lost, any help would be greatly appreciated! I know there's other ways to do this but I was hoping to try to use this technique since it's the primary way that my TA codes regression models. Thank you!",
      "body_html": "<div class=\"md\"><p>Hi everyone! This is a simple troubleshooting question. I&#39;m in my master&#39;s program for python and I  keep running into an issue when I try running this code for a linear regression model: </p>\n\n<pre><code>airfares_lm = LinearRegression(normalize=True)\n</code></pre>\n\n<p>airfares_lm.fit(train_X, train_y)</p>\n\n<p>print(&#39;intercept &#39;, airfares<em>lm.intercept</em>)\nprint(pd.DataFrame({&#39;Predictor&#39;: X.columns, &#39;coefficient&#39;: airfares<em>lm.coef</em>}))</p>\n\n<p>print(&#39;Training set&#39;)\nregressionSummary(train_y, airfares_lm.predict(train_X))\nprint(&#39;Validation set&#39;)\nregressionSummary(valid_y, airfares_lm.predict(valid_X))</p>\n\n<p>It keeps returning this error:</p>\n\n<pre><code>---------------------------------------------------------------------------\n</code></pre>\n\n<p>TypeError                                 Traceback (most recent call last)\n/var/folders/j1/1b6bkxw165zbtsk8tyf9y8dc0000gn/T/ipykernel<em>21423/2993181547.py in &lt;cell line: 1&gt;()\n----&gt; 1 airfares_lm = LinearRegression(normalize=True)\n      2 airfares_lm.fit(train_X, train_y)\n      3 \n      4 # print coefficients\n      5 print(&#39;intercept &#39;, airfares_lm.intercept</em>)</p>\n\n<p>TypeError: <strong>init</strong>() got an unexpected keyword argument &#39;normalize&#39;</p>\n\n<p>I&#39;m really lost, any help would be greatly appreciated! I know there&#39;s other ways to do this but I was hoping to try to use this technique since it&#39;s the primary way that my TA codes regression models. Thank you!</p>\n</div>",
      "created_utc": 1679259088.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jcvak4c/",
      "parent_id": "t3_11pgj86",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-19T13:51:28"
    },
    {
      "id": "jcwhvs3",
      "author": "suineg",
      "body": "I'm curious on the feasibility of a concept before I start going down the road. I am also unsure if maybe there is already a project that I should look into.  \n\n\nThere is a fantasy book series that I enjoy and it's 10 books and 3.3M words (I don't have a character count). The world and characters are complicated and their interactions with other characters is sometimes pretty obscure. I want to make a dynamic wiki and search tool for two things.   \n\n\nPhase 1 - Ingest all of the text and start building out character profiles, book profiles, etc. The front end would tag information based on what book so if you've only ready up to book 7 you don't get 8-10 spoiled. You could give it a parameter like \"list all the battles character a and character b are in together\".   \n\n\nPhase 2 - This would be the difficult portion much later on and I'm not focused on it yet. You could get ask it something like \"give me a view of character b after event\\_32\" and based on the descriptions it would generate art. You could also give it things like \"give me a scene of character b, d, and h at the battle of event\\_40\" and it would generate one based on that stored event.",
      "body_html": "<div class=\"md\"><p>I&#39;m curious on the feasibility of a concept before I start going down the road. I am also unsure if maybe there is already a project that I should look into.  </p>\n\n<p>There is a fantasy book series that I enjoy and it&#39;s 10 books and 3.3M words (I don&#39;t have a character count). The world and characters are complicated and their interactions with other characters is sometimes pretty obscure. I want to make a dynamic wiki and search tool for two things.   </p>\n\n<p>Phase 1 - Ingest all of the text and start building out character profiles, book profiles, etc. The front end would tag information based on what book so if you&#39;ve only ready up to book 7 you don&#39;t get 8-10 spoiled. You could give it a parameter like &quot;list all the battles character a and character b are in together&quot;.   </p>\n\n<p>Phase 2 - This would be the difficult portion much later on and I&#39;m not focused on it yet. You could get ask it something like &quot;give me a view of character b after event_32&quot; and based on the descriptions it would generate art. You could also give it things like &quot;give me a scene of character b, d, and h at the battle of event_40&quot; and it would generate one based on that stored event.</p>\n</div>",
      "created_utc": 1679278800.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jcwhvs3/",
      "parent_id": "t3_11pgj86",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-19T19:20:00"
    },
    {
      "id": "jcwyjyv",
      "author": "disastorm",
      "body": "I noticed that \"text-generation\" models have variable output but alot of other models like chatbots and other models often give the exact same response for the same input prompt. Is there a reason for this, or perhaps is there a setting that would allow a chatbot for example to have variable responses, or is my understanding of this just wrong?",
      "body_html": "<div class=\"md\"><p>I noticed that &quot;text-generation&quot; models have variable output but alot of other models like chatbots and other models often give the exact same response for the same input prompt. Is there a reason for this, or perhaps is there a setting that would allow a chatbot for example to have variable responses, or is my understanding of this just wrong?</p>\n</div>",
      "created_utc": 1679288093.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jcwyjyv/",
      "parent_id": "t3_11pgj86",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-19T21:54:53"
    },
    {
      "id": "jcxqcgw",
      "author": "darthstargazer",
      "body": "Subject : Variational inference and genarative networks\n\n\nI've been trying to grasp the ideas behind Variational auto encoders (Kingma et al) vs normalized flows (E.G RealNVP)\n\nIf someone can explain the link between the two I'd be thankful! Aren't they trying to do the same thing?",
      "body_html": "<div class=\"md\"><p>Subject : Variational inference and genarative networks</p>\n\n<p>I&#39;ve been trying to grasp the ideas behind Variational auto encoders (Kingma et al) vs normalized flows (E.G RealNVP)</p>\n\n<p>If someone can explain the link between the two I&#39;d be thankful! Aren&#39;t they trying to do the same thing?</p>\n</div>",
      "created_utc": 1679311041.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jcxqcgw/",
      "parent_id": "t3_11pgj86",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-20T04:17:21"
    },
    {
      "id": "jczkfku",
      "author": "Xotchkass",
      "body": "What are the input length of the Llama model? Can't find it anywhere.",
      "body_html": "<div class=\"md\"><p>What are the input length of the Llama model? Can&#39;t find it anywhere.</p>\n</div>",
      "created_utc": 1679340234.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jczkfku/",
      "parent_id": "t3_11pgj86",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": true,
      "distinguished": null,
      "timestamp": "2023-03-20T12:23:54"
    },
    {
      "id": "jd0yzdj",
      "author": "killerstorm",
      "body": "Have people tried doing \"textual inversion\" for language models? (i.e not in a context of StableDiffusion)",
      "body_html": "<div class=\"md\"><p>Have people tried doing &quot;textual inversion&quot; for language models? (i.e not in a context of StableDiffusion)</p>\n</div>",
      "created_utc": 1679360912.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jd0yzdj/",
      "parent_id": "t3_11pgj86",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-20T18:08:32"
    },
    {
      "id": "jd1hjeo",
      "author": "VS2ute",
      "body": "Are Nvidia Tesla GPUs made for immersion cooling?\nI notice these things don't have fans going back quite a few models. So you would need to add screaming server fans to cool them by air. I presume new datacentres use immersion cooling to reduce electricity consumption.",
      "body_html": "<div class=\"md\"><p>Are Nvidia Tesla GPUs made for immersion cooling?\nI notice these things don&#39;t have fans going back quite a few models. So you would need to add screaming server fans to cool them by air. I presume new datacentres use immersion cooling to reduce electricity consumption.</p>\n</div>",
      "created_utc": 1679369570.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jd1hjeo/",
      "parent_id": "t3_11pgj86",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-20T20:32:50"
    },
    {
      "id": "jd5j1co",
      "author": "Lucas_Matheus",
      "body": "In few-shot learning, are there gradient updates from the examples? If not, what difference does it make?",
      "body_html": "<div class=\"md\"><p>In few-shot learning, are there gradient updates from the examples? If not, what difference does it make?</p>\n</div>",
      "created_utc": 1679442667.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jd5j1co/",
      "parent_id": "t3_11pgj86",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-21T16:51:07"
    },
    {
      "id": "jd5se2v",
      "author": "neriticzone",
      "body": "Feedback on stratified k fold validation\n\nI am doing some applied work with CNNs in the academic world. \n\nI have a relatively small dataset. \n\nI am doing 10 fold stratified cross validation(?) where I do an initial test-train split, and then the data in the train split is further cross validated to a 10 fold train-validate split. \n\nI then run the ensemble of 10 train models against the test split, and I select the results from the best performing model against the test data as the predicted values for the test data. \n\nIs this a reasonable strategy? Thank you!",
      "body_html": "<div class=\"md\"><p>Feedback on stratified k fold validation</p>\n\n<p>I am doing some applied work with CNNs in the academic world. </p>\n\n<p>I have a relatively small dataset. </p>\n\n<p>I am doing 10 fold stratified cross validation(?) where I do an initial test-train split, and then the data in the train split is further cross validated to a 10 fold train-validate split. </p>\n\n<p>I then run the ensemble of 10 train models against the test split, and I select the results from the best performing model against the test data as the predicted values for the test data. </p>\n\n<p>Is this a reasonable strategy? Thank you!</p>\n</div>",
      "created_utc": 1679446755.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jd5se2v/",
      "parent_id": "t3_11pgj86",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-21T17:59:15"
    },
    {
      "id": "jd64o4e",
      "author": "RainbowRedditForum",
      "body": "A CRNN is trained with logmel as input, calculated as follows:  \nthe input audio is split in 30ms frames with 10ms hop size, and 40 logmel are calculated for each frame.  \nThe CRNN performs a binary classification.  \nWith this setup, are these two considerations true?\n\n* two consecutive output labels generated by the CRNN are associated with two overlapped audio frames (each of size 30ms (0.03s) and hop size 10ms);\n* for 10 minutes audio the CRNN should generate about 30000 output labels, each one associated with a 30ms frame with 10ms of overlap",
      "body_html": "<div class=\"md\"><p>A CRNN is trained with logmel as input, calculated as follows:<br/>\nthe input audio is split in 30ms frames with 10ms hop size, and 40 logmel are calculated for each frame.<br/>\nThe CRNN performs a binary classification.<br/>\nWith this setup, are these two considerations true?</p>\n\n<ul>\n<li>two consecutive output labels generated by the CRNN are associated with two overlapped audio frames (each of size 30ms (0.03s) and hop size 10ms);</li>\n<li>for 10 minutes audio the CRNN should generate about 30000 output labels, each one associated with a 30ms frame with 10ms of overlap</li>\n</ul>\n</div>",
      "created_utc": 1679452299.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jd64o4e/",
      "parent_id": "t3_11pgj86",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-21T19:31:39"
    },
    {
      "id": "jd7f50p",
      "author": "Bornaia",
      "body": "Everyone is speaking about AI content, creative stories, texts.. but do companies or people in the real world actually use it for their products?",
      "body_html": "<div class=\"md\"><p>Everyone is speaking about AI content, creative stories, texts.. but do companies or people in the real world actually use it for their products?</p>\n</div>",
      "created_utc": 1679485319.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jd7f50p/",
      "parent_id": "t3_11pgj86",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-22T04:41:59"
    },
    {
      "id": "jd9tanf",
      "author": "GaryS2000",
      "body": "For my final year uni project I need to train a TensorFlow CNN on the FER-2013 dataset. When training the model on data from the .csv file instead of locally stored images the model trains significantly faster, with around 10 seconds per epoch as opposed to 10 minutes or so for the images. My question is it okay for me to use .csv data instead of locally stored images for this image classification task? I know I won't be able to apply data augmentation as easily but I can't think of any other downsides which would disqualify me from using the .csv data instead of the images",
      "body_html": "<div class=\"md\"><p>For my final year uni project I need to train a TensorFlow CNN on the FER-2013 dataset. When training the model on data from the .csv file instead of locally stored images the model trains significantly faster, with around 10 seconds per epoch as opposed to 10 minutes or so for the images. My question is it okay for me to use .csv data instead of locally stored images for this image classification task? I know I won&#39;t be able to apply data augmentation as easily but I can&#39;t think of any other downsides which would disqualify me from using the .csv data instead of the images</p>\n</div>",
      "created_utc": 1679520097.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jd9tanf/",
      "parent_id": "t3_11pgj86",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-22T14:21:37"
    },
    {
      "id": "jdaskxp",
      "author": "sore__",
      "body": "I want to make an AI Chatbot similar to OpenAI's DaVinci 3 but my own version & offline. I'm trying to use Python but I don't know what intents I should add to it, because I want it to know basically everything. Is it possible to just feed the code everything on Wikipedia? I'm VERY VERY new to machine learning so this might be overambitious but idk it just seems fun. Anyways, if anyone has ideas, please reply :)",
      "body_html": "<div class=\"md\"><p>I want to make an AI Chatbot similar to OpenAI&#39;s DaVinci 3 but my own version &amp; offline. I&#39;m trying to use Python but I don&#39;t know what intents I should add to it, because I want it to know basically everything. Is it possible to just feed the code everything on Wikipedia? I&#39;m VERY VERY new to machine learning so this might be overambitious but idk it just seems fun. Anyways, if anyone has ideas, please reply :)</p>\n</div>",
      "created_utc": 1679534944.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jdaskxp/",
      "parent_id": "t3_11pgj86",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-22T18:29:04"
    },
    {
      "id": "jddmvp9",
      "author": "jarmosie",
      "body": "What are you some informative blogs, RSS feed or newsletter you've subscribed to for regular content on Machine Learning? In general, the Software Development community has an abundance of people maintaining high quality online content through individual blogs or newsletter.\n\nI know there's [Towards Data Science](https://towardsdatascience.com) & [Machine Learning Mastery](https://machinelearningmastery.com/) to name a few but what other lesser known yet VERY informative resource did you stumble across & one which has help you further you knowledge even more?",
      "body_html": "<div class=\"md\"><p>What are you some informative blogs, RSS feed or newsletter you&#39;ve subscribed to for regular content on Machine Learning? In general, the Software Development community has an abundance of people maintaining high quality online content through individual blogs or newsletter.</p>\n\n<p>I know there&#39;s <a href=\"https://towardsdatascience.com\">Towards Data Science</a> &amp; <a href=\"https://machinelearningmastery.com/\">Machine Learning Mastery</a> to name a few but what other lesser known yet VERY informative resource did you stumble across &amp; one which has help you further you knowledge even more?</p>\n</div>",
      "created_utc": 1679591870.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jddmvp9/",
      "parent_id": "t3_11pgj86",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-23T10:17:50"
    },
    {
      "id": "jde6kby",
      "author": "mcAlt009",
      "body": "What's the VM I can rent out with a GPU. \nIdeally I want a VM where I can train models, host websites, etc. Location isn't too important",
      "body_html": "<div class=\"md\"><p>What&#39;s the VM I can rent out with a GPU. \nIdeally I want a VM where I can train models, host websites, etc. Location isn&#39;t too important</p>\n</div>",
      "created_utc": 1679599288.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jde6kby/",
      "parent_id": "t3_11pgj86",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-23T12:21:28"
    },
    {
      "id": "jde9kv5",
      "author": null,
      "body": "[removed]",
      "body_html": "<div class=\"md\"><p>[removed]</p>\n</div>",
      "created_utc": 1679600456.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jde9kv5/",
      "parent_id": "t3_11pgj86",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-23T12:40:56"
    },
    {
      "id": "jdezz4h",
      "author": "doodyswappy",
      "body": "Is this a bug in google scholar https://scholar.google.com/citations?view_op=view_citation&hl=en&user=TDk_NfkAAAAJ&citation_for_view=TDk_NfkAAAAJ:vRqMK49ujn8C\n\nMany of tiles by Joseph Redmon seem to be some random title\nhttps://scholar.google.com/citations?view_op=view_citation&hl=en&user=TDk_NfkAAAAJ&citation_for_view=TDk_NfkAAAAJ:mvPsJ3kp5DgC",
      "body_html": "<div class=\"md\"><p>Is this a bug in google scholar <a href=\"https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=TDk_NfkAAAAJ&amp;citation_for_view=TDk_NfkAAAAJ:vRqMK49ujn8C\">https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=TDk_NfkAAAAJ&amp;citation_for_view=TDk_NfkAAAAJ:vRqMK49ujn8C</a></p>\n\n<p>Many of tiles by Joseph Redmon seem to be some random title\n<a href=\"https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=TDk_NfkAAAAJ&amp;citation_for_view=TDk_NfkAAAAJ:mvPsJ3kp5DgC\">https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=TDk_NfkAAAAJ&amp;citation_for_view=TDk_NfkAAAAJ:mvPsJ3kp5DgC</a></p>\n</div>",
      "created_utc": 1679610705.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jdezz4h/",
      "parent_id": "t3_11pgj86",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-23T15:31:45"
    },
    {
      "id": "jdf31vk",
      "author": "TiredMoose69",
      "body": "Why does LlaMa 7B (pure) perform so MUCH better than Alpaca 30B (4bit)?",
      "body_html": "<div class=\"md\"><p>Why does LlaMa 7B (pure) perform so MUCH better than Alpaca 30B (4bit)?</p>\n</div>",
      "created_utc": 1679611994.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jdf31vk/",
      "parent_id": "t3_11pgj86",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-23T15:53:14"
    },
    {
      "id": "jdgqv13",
      "author": "dotnethero",
      "body": "Hey everyone, I'm trying to figure out which parts of my code are using CPU and which are using GPU. During training, I've noticed that only about 5% of my usage is on the GPU, while the CPU usage is high. Any tips on how I can better understand what's going on with my code? Thanks in advance!",
      "body_html": "<div class=\"md\"><p>Hey everyone, I&#39;m trying to figure out which parts of my code are using CPU and which are using GPU. During training, I&#39;ve noticed that only about 5% of my usage is on the GPU, while the CPU usage is high. Any tips on how I can better understand what&#39;s going on with my code? Thanks in advance!</p>\n</div>",
      "created_utc": 1679644368.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jdgqv13/",
      "parent_id": "t3_11pgj86",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-24T00:52:48"
    },
    {
      "id": "jdgutr0",
      "author": "kross00",
      "body": "Is it feasible to train Llama 65B (or smaller models) to engage in chit-chatting in a manner that would not readily reveal whether one is conversing with an AI or a human? The AI does not need to answer highly complex questions and could decline them similarly to how a human would.",
      "body_html": "<div class=\"md\"><p>Is it feasible to train Llama 65B (or smaller models) to engage in chit-chatting in a manner that would not readily reveal whether one is conversing with an AI or a human? The AI does not need to answer highly complex questions and could decline them similarly to how a human would.</p>\n</div>",
      "created_utc": 1679647864.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jdgutr0/",
      "parent_id": "t3_11pgj86",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-24T01:51:04"
    },
    {
      "id": "jdhcnlf",
      "author": "Kaasfee",
      "body": "Im trying to train yolov7 to detect football(european one) players and the ball. In a typical frame there are lots of players and only one ball. After training it only detects the players. My guess is that it learned to ignore guessing the ball since its statistically irrelevant. Is this assumption correct, and if so how would I go about changing it?",
      "body_html": "<div class=\"md\"><p>Im trying to train yolov7 to detect football(european one) players and the ball. In a typical frame there are lots of players and only one ball. After training it only detects the players. My guess is that it learned to ignore guessing the ball since its statistically irrelevant. Is this assumption correct, and if so how would I go about changing it?</p>\n</div>",
      "created_utc": 1679660510.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jdhcnlf/",
      "parent_id": "t3_11pgj86",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-24T05:21:50"
    },
    {
      "id": "jdjhln9",
      "author": "Prometheushunter2",
      "body": "Here’s an oddly specific question: a few years ago I read about a neural network that could both classify an image and, if ran in reverse, could generate synthetic examples of the classes it has learned. Th e problem is I’ve forgotten the name and it’s been haunting me lately, so I ask does anyone know what kind of neural network this might be?",
      "body_html": "<div class=\"md\"><p>Here’s an oddly specific question: a few years ago I read about a neural network that could both classify an image and, if ran in reverse, could generate synthetic examples of the classes it has learned. Th e problem is I’ve forgotten the name and it’s been haunting me lately, so I ask does anyone know what kind of neural network this might be?</p>\n</div>",
      "created_utc": 1679691383.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jdjhln9/",
      "parent_id": "t3_11pgj86",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-24T13:56:23"
    },
    {
      "id": "jdk0xl8",
      "author": "jay_hoenes",
      "body": "I was wondering if there are any new models like StyleGAN?  \nI mean, image generation recently became much easier with Text-to-Image models like Stable Diffusion, Midjourney and Dall-E and so on. But I like the general idea of training an own model with a unique input dataset.  \nI found that there is StyleGAN3, but except one google colab notebook which doesn't work for me, it doesn't seem to be well supported and not really used by people.  \nAre there any recent alternatives to create a variety of images only based on my personal input images without being trained on huge datasets? Or is it maybe possible with stable diffusion?",
      "body_html": "<div class=\"md\"><p>I was wondering if there are any new models like StyleGAN?<br/>\nI mean, image generation recently became much easier with Text-to-Image models like Stable Diffusion, Midjourney and Dall-E and so on. But I like the general idea of training an own model with a unique input dataset.<br/>\nI found that there is StyleGAN3, but except one google colab notebook which doesn&#39;t work for me, it doesn&#39;t seem to be well supported and not really used by people.<br/>\nAre there any recent alternatives to create a variety of images only based on my personal input images without being trained on huge datasets? Or is it maybe possible with stable diffusion?</p>\n</div>",
      "created_utc": 1679699664.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jdk0xl8/",
      "parent_id": "t3_11pgj86",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-24T16:14:24"
    },
    {
      "id": "jdloewa",
      "author": "loly0ss",
      "body": "Hello everyone,\n\nI had a very ignorant question which I’m trying to find an answer too but i still couldn’t find it.\n\nIn terms of the deep learning model in supervised segmentation vs semi-superised segmentation. \n\nIs the model itself the same in both cases, for example using Unet++ for both? \nAnd the only diffference comes during training where we use psuedo-labels for example for semi-supervised segmentation?\n\nOr is the model different when it comes between supervised vs semi-supervised segmentation?\n\n\nThank you!",
      "body_html": "<div class=\"md\"><p>Hello everyone,</p>\n\n<p>I had a very ignorant question which I’m trying to find an answer too but i still couldn’t find it.</p>\n\n<p>In terms of the deep learning model in supervised segmentation vs semi-superised segmentation. </p>\n\n<p>Is the model itself the same in both cases, for example using Unet++ for both? \nAnd the only diffference comes during training where we use psuedo-labels for example for semi-supervised segmentation?</p>\n\n<p>Or is the model different when it comes between supervised vs semi-supervised segmentation?</p>\n\n<p>Thank you!</p>\n</div>",
      "created_utc": 1679735501.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jdloewa/",
      "parent_id": "t3_11pgj86",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-25T02:11:41"
    },
    {
      "id": "jdmhn6h",
      "author": "RiotSia",
      "body": "Hey,\n\nI got the 7B llama model running on my machine. Now I want it to analyze a large text for me (a pdf file) like hamata.ai does. How can I do it ? Does any one has like a site with resources on how I can learn to do that or even tell me?",
      "body_html": "<div class=\"md\"><p>Hey,</p>\n\n<p>I got the 7B llama model running on my machine. Now I want it to analyze a large text for me (a pdf file) like hamata.ai does. How can I do it ? Does any one has like a site with resources on how I can learn to do that or even tell me?</p>\n</div>",
      "created_utc": 1679754537.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jdmhn6h/",
      "parent_id": "t3_11pgj86",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-25T07:28:57"
    },
    {
      "id": "jdn17j5",
      "author": "yaru22",
      "body": "Hello,\n\nGPT4 has context length of 32K tokens while some others have 2-4K tokens. What decides the limit on these context lengths? Is it simply bigger the model, larger the context length? Or is it possible to have a large context length even on a smaller model like LLaMA 7/13/30B?\n\nThank you!",
      "body_html": "<div class=\"md\"><p>Hello,</p>\n\n<p>GPT4 has context length of 32K tokens while some others have 2-4K tokens. What decides the limit on these context lengths? Is it simply bigger the model, larger the context length? Or is it possible to have a large context length even on a smaller model like LLaMA 7/13/30B?</p>\n\n<p>Thank you!</p>\n</div>",
      "created_utc": 1679762996.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jdn17j5/",
      "parent_id": "t3_11pgj86",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-25T09:49:56"
    },
    {
      "id": "jdn5uwr",
      "author": "ajingnk",
      "body": "What is the minimum hardware requirement to fine tune like Stanford Alpaca? I am thinking to build a workstation to do some DL exploration and fine-tuning work. For fine-tuning, I have around 10k samples.",
      "body_html": "<div class=\"md\"><p>What is the minimum hardware requirement to fine tune like Stanford Alpaca? I am thinking to build a workstation to do some DL exploration and fine-tuning work. For fine-tuning, I have around 10k samples.</p>\n</div>",
      "created_utc": 1679764979.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jdn5uwr/",
      "parent_id": "t3_11pgj86",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-25T10:22:59"
    },
    {
      "id": "jdp6z6y",
      "author": "LacedDecal",
      "body": "If one is trying to model something where the “correct” answer for a given set of features is inherently probabilistic—for example the outcome of a baseball plate appearance—how should you tell a neural network to grade it’s accuracy? \n\nFor those who aren’t familiar with baseball, the most likely outcome for any plate appearance — even the leagues best batter against the leagues worst pitcher — is some kind of out. Generally somewhere on the order of 60-75% that will be the outcome.  So I’m realizing that the most “accurate” set of predictions against literally any dataset of at bats were to predict “out” for every one.  \n\nWhat I’m realizing is that the “correct” answer I’m looking for is a set of probabilities.  But how does one apply, say, a loss function involving categorical cross entropy, in any kind of meaningful way? Is there even a way to do supervised learning when the data points “label” isn’t the actual probability distribution but rather one collapsed event for each “true” probability distribution? \n\nAm I even making sense?\n\nEdit: I know I need something like softmax but when I start training it quickly spirals into a case of exploding gradients no matter what I do. I think it’s because the “labels” I’m using aren’t the true probabilities each outcome had, but rather a single hard max real life outcome that actually occurred (home run, out, double, etc).",
      "body_html": "<div class=\"md\"><p>If one is trying to model something where the “correct” answer for a given set of features is inherently probabilistic—for example the outcome of a baseball plate appearance—how should you tell a neural network to grade it’s accuracy? </p>\n\n<p>For those who aren’t familiar with baseball, the most likely outcome for any plate appearance — even the leagues best batter against the leagues worst pitcher — is some kind of out. Generally somewhere on the order of 60-75% that will be the outcome.  So I’m realizing that the most “accurate” set of predictions against literally any dataset of at bats were to predict “out” for every one.  </p>\n\n<p>What I’m realizing is that the “correct” answer I’m looking for is a set of probabilities.  But how does one apply, say, a loss function involving categorical cross entropy, in any kind of meaningful way? Is there even a way to do supervised learning when the data points “label” isn’t the actual probability distribution but rather one collapsed event for each “true” probability distribution? </p>\n\n<p>Am I even making sense?</p>\n\n<p>Edit: I know I need something like softmax but when I start training it quickly spirals into a case of exploding gradients no matter what I do. I think it’s because the “labels” I’m using aren’t the true probabilities each outcome had, but rather a single hard max real life outcome that actually occurred (home run, out, double, etc).</p>\n</div>",
      "created_utc": 1679797615.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jdp6z6y/",
      "parent_id": "t3_11pgj86",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": true,
      "distinguished": null,
      "timestamp": "2023-03-25T19:26:55"
    },
    {
      "id": "jdq1t5p",
      "author": "AntelopeStatus8176",
      "body": "I have a set of 20.000 raw measurement data slices, each of which   \ncontains 3.000 measurement samplepoints. For each of the data slices,   \nthere is a target value assigned to it. The target values are continous.  \n My first approach was to do feature engineering on the raw   \nmeasurement slices to reduce data and to speed up ML-teaching. This   \napproach works reasonably well in estimating the target value for   \nunknown data slices of the testing data set.  \n My second approach would be to use the raw data slices as input.  \n On a second thought, this appears to be dramatically computing power   \nintensive, or at least way more than i can handle with my standard-PC.   \nTo my understanding, this would mean to construct an ANN with 3.000   \ninput nodes and several deep layers.  \nCan anyone give advice whether teaching with raw measurement data   \nwith this kind of huge datasets does even make sense and if so, which   \nalgorithms to use? Preferably examples in python",
      "body_html": "<div class=\"md\"><p>I have a set of 20.000 raw measurement data slices, each of which<br/>\ncontains 3.000 measurement samplepoints. For each of the data slices,<br/>\nthere is a target value assigned to it. The target values are continous.<br/>\n My first approach was to do feature engineering on the raw<br/>\nmeasurement slices to reduce data and to speed up ML-teaching. This<br/>\napproach works reasonably well in estimating the target value for<br/>\nunknown data slices of the testing data set.<br/>\n My second approach would be to use the raw data slices as input.<br/>\n On a second thought, this appears to be dramatically computing power<br/>\nintensive, or at least way more than i can handle with my standard-PC.<br/>\nTo my understanding, this would mean to construct an ANN with 3.000<br/>\ninput nodes and several deep layers.<br/>\nCan anyone give advice whether teaching with raw measurement data<br/>\nwith this kind of huge datasets does even make sense and if so, which<br/>\nalgorithms to use? Preferably examples in python</p>\n</div>",
      "created_utc": 1679818515.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jdq1t5p/",
      "parent_id": "t3_11pgj86",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-26T01:15:15"
    },
    {
      "id": "jdqjtbp",
      "author": "Camillo_Trevisan",
      "body": "Hello everyone,\r  \nI state that I am a neophyte.\r  \nI'm looking for a Machine Learning software that can analyze large datasets composed as follows: 3D surface defined by triplets of XYZ values (at least 150 triplets or more, defined on a regular and constant grid or, possibly, also on an irregular grid, different for each set) and the related outputs, produced by my software, which contain about seventy calculated numerical parameters on that surface. I would like to analyze a few thousand datasets, each consisting of at least 500/600 or more numerical values.\r  \nThe idea is both to analyze the entered data and also to carry out simulations such as: if I define a new set of output values, which 3D surface could generate them using my software?\r  \nThe utility is given by the fact that my software takes many hours of calculation to generate a set of output values and also it only works in one direction (input grid -> output values).\r  \nThanks in advance for any suggestion\r  \nCamillo",
      "body_html": "<div class=\"md\"><p>Hello everyone,</p>\n\n<p>I state that I am a neophyte.</p>\n\n<p>I&#39;m looking for a Machine Learning software that can analyze large datasets composed as follows: 3D surface defined by triplets of XYZ values (at least 150 triplets or more, defined on a regular and constant grid or, possibly, also on an irregular grid, different for each set) and the related outputs, produced by my software, which contain about seventy calculated numerical parameters on that surface. I would like to analyze a few thousand datasets, each consisting of at least 500/600 or more numerical values.</p>\n\n<p>The idea is both to analyze the entered data and also to carry out simulations such as: if I define a new set of output values, which 3D surface could generate them using my software?</p>\n\n<p>The utility is given by the fact that my software takes many hours of calculation to generate a set of output values and also it only works in one direction (input grid -&gt; output values).</p>\n\n<p>Thanks in advance for any suggestion</p>\n\n<p>Camillo</p>\n</div>",
      "created_utc": 1679833255.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jdqjtbp/",
      "parent_id": "t3_11pgj86",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-26T05:20:55"
    },
    {
      "id": "jc0ltpb",
      "author": "Simusid",
      "body": "I downloaded over 1M and it cost me about $110",
      "body_html": "<div class=\"md\"><p>I downloaded over 1M and it cost me about $110</p>\n</div>",
      "created_utc": 1678679827.0,
      "score": 5,
      "ups": 5,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jc0ltpb/",
      "parent_id": "t1_jbyrulz",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-12T20:57:07"
    },
    {
      "id": "jcgqzvo",
      "author": "LeN3rd",
      "body": "If you have more variables than datapoints, you will run into problems, if your model starts learning by heart. Your models overfits to the training data: [https://en.wikipedia.org/wiki/Overfitting](https://en.wikipedia.org/wiki/Overfitting)\n\nYou can either reduce the number of parameters in your model, or apply a prior (a constraint on your model parameters) to improve test dataset performance. \n\nSince neural networks (the standard emperical machine learning tools nowadays) have a structure for their parameters, this means they can have much more parameters than simple linear regression models, but seem to run into problems, when the number of parameters in the network matches the number of datapoints. This is just empirically shown, i do not know any mathematical proves for it.",
      "body_html": "<div class=\"md\"><p>If you have more variables than datapoints, you will run into problems, if your model starts learning by heart. Your models overfits to the training data: <a href=\"https://en.wikipedia.org/wiki/Overfitting\">https://en.wikipedia.org/wiki/Overfitting</a></p>\n\n<p>You can either reduce the number of parameters in your model, or apply a prior (a constraint on your model parameters) to improve test dataset performance. </p>\n\n<p>Since neural networks (the standard emperical machine learning tools nowadays) have a structure for their parameters, this means they can have much more parameters than simple linear regression models, but seem to run into problems, when the number of parameters in the network matches the number of datapoints. This is just empirically shown, i do not know any mathematical proves for it.</p>\n</div>",
      "created_utc": 1678991830.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jcgqzvo/",
      "parent_id": "t1_jc5om1y",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-16T11:37:10"
    },
    {
      "id": "jcotnis",
      "author": "jakderrida",
      "body": "The basis of this rule of thumb is that having too few observations relative to the number of predictor variables can lead to unstable estimates of the model parameters, making it difficult to generalize to new data. In particular, if the number of observations is small relative to the number of predictor variables, the model may fit the noise in the data rather than the underlying signal, leading to overfitting.",
      "body_html": "<div class=\"md\"><p>The basis of this rule of thumb is that having too few observations relative to the number of predictor variables can lead to unstable estimates of the model parameters, making it difficult to generalize to new data. In particular, if the number of observations is small relative to the number of predictor variables, the model may fit the noise in the data rather than the underlying signal, leading to overfitting.</p>\n</div>",
      "created_utc": 1679142762.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jcotnis/",
      "parent_id": "t1_jc5om1y",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-18T05:32:42"
    },
    {
      "id": "jcgp44s",
      "author": "LeN3rd",
      "body": "How big is your dataset? Before you start anything wild, i would look at kernel clustering methods. Or even clustering without kernels. Just cluster your broken and non broken images and calculate some distance (can be done with kernels if it needs to be nonlinear).\n\nAlso Nearest neighbor could work pretty well in your case. Just compare your new image to the closest (according to some metric) in your two datasets and bobs your uncle.\n\nIf you need a number, look at simple CNNs. you need more training data though for this to work well.",
      "body_html": "<div class=\"md\"><p>How big is your dataset? Before you start anything wild, i would look at kernel clustering methods. Or even clustering without kernels. Just cluster your broken and non broken images and calculate some distance (can be done with kernels if it needs to be nonlinear).</p>\n\n<p>Also Nearest neighbor could work pretty well in your case. Just compare your new image to the closest (according to some metric) in your two datasets and bobs your uncle.</p>\n\n<p>If you need a number, look at simple CNNs. you need more training data though for this to work well.</p>\n</div>",
      "created_utc": 1678991130.0,
      "score": 2,
      "ups": 2,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jcgp44s/",
      "parent_id": "t1_jca1rh1",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-16T11:25:30"
    },
    {
      "id": "jco1xea",
      "author": "josejo9423",
      "body": "Maybe trying image classification? CNN pytorch",
      "body_html": "<div class=\"md\"><p>Maybe trying image classification? CNN pytorch</p>\n</div>",
      "created_utc": 1679120454.0,
      "score": 0,
      "ups": 0,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jco1xea/",
      "parent_id": "t1_jca1rh1",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-17T23:20:54"
    },
    {
      "id": "jddanig",
      "author": "rikiiyer",
      "body": "The 30B params of the model are going onto your GPUs VRAM (which should be 24GB), which is causing the issue. You can try loading the model in 8bit which could reduce size",
      "body_html": "<div class=\"md\"><p>The 30B params of the model are going onto your GPUs VRAM (which should be 24GB), which is causing the issue. You can try loading the model in 8bit which could reduce size</p>\n</div>",
      "created_utc": 1679587248.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jddanig/",
      "parent_id": "t1_jd05tgt",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-23T09:00:48"
    },
    {
      "id": "jdeltnm",
      "author": "Nyanraltotlapun",
      "body": "Long story short, main property of complex systems is the ability to pretend and mimic.\nSo the real safety of AI lies in its physical limitations (compute power algos etc.) the same limitations that makes them less useful less capable.\nSo the more powerful AI is the less safe it is. There more danger it poses. And it is dangerous alright. More dangerous than nuclear weapons is.",
      "body_html": "<div class=\"md\"><p>Long story short, main property of complex systems is the ability to pretend and mimic.\nSo the real safety of AI lies in its physical limitations (compute power algos etc.) the same limitations that makes them less useful less capable.\nSo the more powerful AI is the less safe it is. There more danger it poses. And it is dangerous alright. More dangerous than nuclear weapons is.</p>\n</div>",
      "created_utc": 1679605117.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jdeltnm/",
      "parent_id": "t1_jd07i7z",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-23T13:58:37"
    },
    {
      "id": "jchq421",
      "author": "josejo9423",
      "body": "I am not quite familiar with deep learning but don’t you have loss function where you can maximize recall precision or AUC? I believe accuracy would not apply in this case since you have imbalanced dataset, also over sampling as it dealed in random forest you are making up new images i don’t know how good is that, why don’t you try under sampling better or weight adjustments?",
      "body_html": "<div class=\"md\"><p>I am not quite familiar with deep learning but don’t you have loss function where you can maximize recall precision or AUC? I believe accuracy would not apply in this case since you have imbalanced dataset, also over sampling as it dealed in random forest you are making up new images i don’t know how good is that, why don’t you try under sampling better or weight adjustments?</p>\n</div>",
      "created_utc": 1679005481.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jchq421/",
      "parent_id": "t1_jccin4h",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-16T15:24:41"
    },
    {
      "id": "jcj24kc",
      "author": "Odibbla",
      "body": "I did this when I was in Robomaster AI challenge. My solution is to use YOLOv3, which should be enough for the task you are asking for. The flow is: you mark the symbol by yourself, train YOLO step by step(all version should work actually, v3 is just my option). Take in video stream, YOLO will output the exact location of that sign in the frames. I did it on Jetson Nano and that is smooth. Since you got a degree, you shouuld be fully capable of doing this. Good luck!",
      "body_html": "<div class=\"md\"><p>I did this when I was in Robomaster AI challenge. My solution is to use YOLOv3, which should be enough for the task you are asking for. The flow is: you mark the symbol by yourself, train YOLO step by step(all version should work actually, v3 is just my option). Take in video stream, YOLO will output the exact location of that sign in the frames. I did it on Jetson Nano and that is smooth. Since you got a degree, you shouuld be fully capable of doing this. Good luck!</p>\n</div>",
      "created_utc": 1679028086.0,
      "score": 2,
      "ups": 2,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jcj24kc/",
      "parent_id": "t1_jce240r",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-16T21:41:26"
    },
    {
      "id": "jdd33ha",
      "author": "dwarfarchist9001",
      "body": "Short answer: Polynomials can have very large derivatives compared to sigmoid or rectified linear functions which leads to exploding gradients.\n\n[https://en.wikipedia.org/wiki/Vanishing\\_gradient\\_problem#Recurrent\\_network\\_model](https://en.wikipedia.org/wiki/Vanishing_gradient_problem#Recurrent_network_model)",
      "body_html": "<div class=\"md\"><p>Short answer: Polynomials can have very large derivatives compared to sigmoid or rectified linear functions which leads to exploding gradients.</p>\n\n<p><a href=\"https://en.wikipedia.org/wiki/Vanishing_gradient_problem#Recurrent_network_model\">https://en.wikipedia.org/wiki/Vanishing_gradient_problem#Recurrent_network_model</a></p>\n</div>",
      "created_utc": 1679584346.0,
      "score": 2,
      "ups": 2,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jdd33ha/",
      "parent_id": "t1_jdcb0vo",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": true,
      "distinguished": null,
      "timestamp": "2023-03-23T08:12:26"
    },
    {
      "id": "jddpryu",
      "author": "underPanther",
      "body": "Another reason: wide single-layer MLPs with polynomials cannot be universal. But lots of other activations do give universality with a single hidden layer.\n\nThe technical reason behind this is that ~~non-discriminatory~~  discriminatory activations can give universality with a single hidden layer (Cybenko 1989 is the reference).\n\nBut polynomials are not discriminatory ([https://math.stackexchange.com/questions/3216437/non-trivial-examples-of-non-discriminatory-functions](https://math.stackexchange.com/questions/3216437/non-trivial-examples-of-non-discriminatory-functions)), so they fail to reach this criterion.\n\nAlso, if you craft a multilayer percepteron with polynomials, does this offer any benefit over fitting a Taylor series directly?",
      "body_html": "<div class=\"md\"><p>Another reason: wide single-layer MLPs with polynomials cannot be universal. But lots of other activations do give universality with a single hidden layer.</p>\n\n<p>The technical reason behind this is that <del>non-discriminatory</del>  discriminatory activations can give universality with a single hidden layer (Cybenko 1989 is the reference).</p>\n\n<p>But polynomials are not discriminatory (<a href=\"https://math.stackexchange.com/questions/3216437/non-trivial-examples-of-non-discriminatory-functions\">https://math.stackexchange.com/questions/3216437/non-trivial-examples-of-non-discriminatory-functions</a>), so they fail to reach this criterion.</p>\n\n<p>Also, if you craft a multilayer percepteron with polynomials, does this offer any benefit over fitting a Taylor series directly?</p>\n</div>",
      "created_utc": 1679592957.0,
      "score": 2,
      "ups": 2,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jddpryu/",
      "parent_id": "t1_jdcb0vo",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": true,
      "distinguished": null,
      "timestamp": "2023-03-23T10:35:57"
    },
    {
      "id": "jdhecq5",
      "author": "LeN3rd",
      "body": "I dont think so. OpenAI has overtaken any research done on LLMs by a long shot.",
      "body_html": "<div class=\"md\"><p>I dont think so. OpenAI has overtaken any research done on LLMs by a long shot.</p>\n</div>",
      "created_utc": 1679661399.0,
      "score": 2,
      "ups": 2,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jdhecq5/",
      "parent_id": "t1_jdfk435",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-24T05:36:39"
    },
    {
      "id": "jbybye9",
      "author": "tdgros",
      "body": "what is love?",
      "body_html": "<div class=\"md\"><p>what is love?</p>\n</div>",
      "created_utc": 1678643355.0,
      "score": 6,
      "ups": 6,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jbybye9/",
      "parent_id": "t1_jby8tfl",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-12T10:49:15"
    },
    {
      "id": "jd58x06",
      "author": "Optimal-Asshole",
      "body": "Since you are training the LSTM by using labels, it is supervised or perhaps self-supervised depending on the specifics",
      "body_html": "<div class=\"md\"><p>Since you are training the LSTM by using labels, it is supervised or perhaps self-supervised depending on the specifics</p>\n</div>",
      "created_utc": 1679438454.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jd58x06/",
      "parent_id": "t1_jd4ak8v",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-21T15:40:54"
    },
    {
      "id": "jbz0x4x",
      "author": "clementiasparrow",
      "body": "I think the standard solution would be concatting the two embeddings an putting a dense layer on top",
      "body_html": "<div class=\"md\"><p>I think the standard solution would be concatting the two embeddings an putting a dense layer on top</p>\n</div>",
      "created_utc": 1678653724.0,
      "score": 5,
      "ups": 5,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jbz0x4x/",
      "parent_id": "t1_jbyl2wi",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-12T13:42:04"
    },
    {
      "id": "jcpu2pe",
      "author": "josejo9423",
      "body": "I would go with 1 but I would no tune early stopping just the number of estimators , xgbboost has the option of stopping iterations (early stopping) when there are no improvements in the metric, if you plot then what model believes and realizes that could have been stopped early , step up that number that you consider before overfitting",
      "body_html": "<div class=\"md\"><p>I would go with 1 but I would no tune early stopping just the number of estimators , xgbboost has the option of stopping iterations (early stopping) when there are no improvements in the metric, if you plot then what model believes and realizes that could have been stopped early , step up that number that you consider before overfitting</p>\n</div>",
      "created_utc": 1679159054.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jcpu2pe/",
      "parent_id": "t1_jc1jts4",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-18T10:04:14"
    },
    {
      "id": "jcgrxfp",
      "author": "LeN3rd",
      "body": "Strongly depends on your constraints. There are ways to get 3d geometry from a photo/video. If you have the geometry of your glasses you should be able to see if they fit, though you might have some problems with actually adjusting the glasses to fit on the face geometry. But you could also just do what you optician does and take a frontal photo of your face in a controlled environment.",
      "body_html": "<div class=\"md\"><p>Strongly depends on your constraints. There are ways to get 3d geometry from a photo/video. If you have the geometry of your glasses you should be able to see if they fit, though you might have some problems with actually adjusting the glasses to fit on the face geometry. But you could also just do what you optician does and take a frontal photo of your face in a controlled environment.</p>\n</div>",
      "created_utc": 1678992175.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jcgrxfp/",
      "parent_id": "t1_jc1uk2f",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-16T11:42:55"
    },
    {
      "id": "jcgrhlm",
      "author": "LeN3rd",
      "body": "Be a little more coherent in your question please. No one has any idea about your specific setup unless you tell us what you want to achieve. I.e. RF is usually short for reinforcement learning in the AI community, not radiofrequency. If you want to classify data streams coming from drones, take a look at pattern matching and nearest neighbour methods, before you start to train up a large neural network.",
      "body_html": "<div class=\"md\"><p>Be a little more coherent in your question please. No one has any idea about your specific setup unless you tell us what you want to achieve. I.e. RF is usually short for reinforcement learning in the AI community, not radiofrequency. If you want to classify data streams coming from drones, take a look at pattern matching and nearest neighbour methods, before you start to train up a large neural network.</p>\n</div>",
      "created_utc": 1678992011.0,
      "score": 3,
      "ups": 3,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jcgrhlm/",
      "parent_id": "t1_jc4khxj",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-16T11:40:11"
    },
    {
      "id": "jc5s5r1",
      "author": "mmmfritz",
      "body": "Jabrils. If you want to be swallowed up and eaten whole while you binge 20 hours on machine learning, it’s Jabrils.",
      "body_html": "<div class=\"md\"><p>Jabrils. If you want to be swallowed up and eaten whole while you binge 20 hours on machine learning, it’s Jabrils.</p>\n</div>",
      "created_utc": 1678775617.0,
      "score": 2,
      "ups": 2,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jc5s5r1/",
      "parent_id": "t1_jc5a9kk",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-13T23:33:37"
    },
    {
      "id": "jc8csxm",
      "author": "trnka",
      "body": "If you have significant data, I'd suggest starting with BERT (and including some basic baselines).\n\nIf you only have a small amount of data, you might be able to use GPT models with a fair amount of prompt engineering.\n\nAlso, you'll probably face different challenges if the candidate types the response vs an interviewer is summarizing a response. If it's an interviewer's notes, you might find simple proxies like certain interviewers will type more for good candidates.",
      "body_html": "<div class=\"md\"><p>If you have significant data, I&#39;d suggest starting with BERT (and including some basic baselines).</p>\n\n<p>If you only have a small amount of data, you might be able to use GPT models with a fair amount of prompt engineering.</p>\n\n<p>Also, you&#39;ll probably face different challenges if the candidate types the response vs an interviewer is summarizing a response. If it&#39;s an interviewer&#39;s notes, you might find simple proxies like certain interviewers will type more for good candidates.</p>\n</div>",
      "created_utc": 1678841665.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jc8csxm/",
      "parent_id": "t1_jc5edo3",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-14T17:54:25"
    },
    {
      "id": "jcb26j2",
      "author": "PersonifiedAI",
      "body": "Yes :) - you should try out [Personified](https://www.personified.me)  \n\n\nAMA",
      "body_html": "<div class=\"md\"><p>Yes :) - you should try out <a href=\"https://www.personified.me\">Personified</a>  </p>\n\n<p>AMA</p>\n</div>",
      "created_utc": 1678895376.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jcb26j2/",
      "parent_id": "t1_jc5g7vm",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-15T08:49:36"
    },
    {
      "id": "jcxlf74",
      "author": "henkje112",
      "body": "Look into the Fact Extraction and VERification ([FEVER](https://fever.ai/)) workshop :)",
      "body_html": "<div class=\"md\"><p>Look into the Fact Extraction and VERification (<a href=\"https://fever.ai/\">FEVER</a>) workshop :)</p>\n</div>",
      "created_utc": 1679307299.0,
      "score": 2,
      "ups": 2,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jcxlf74/",
      "parent_id": "t1_jc5s85o",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-20T03:14:59"
    },
    {
      "id": "jcgq97y",
      "author": "LeN3rd",
      "body": "You will need more than a week. If you just want to predict the next word in a sentence, take a look at large language models. ChatGPT being one of them. BERT is a research alternative afaik. If you aim to learn the probabilities yourself, you will need at least a few months. \n\nIn general what you want is a generative model that can sample from the conditional probability distribution. In sequences usually transformers like BERT and chatgpt are state of the art. You can also take a look at normalizing flows and diffusion models to learn probability distributions. But this needs some maths, and i unfortunatly do not know what smaller models can be used for computational linguistic applications like this.",
      "body_html": "<div class=\"md\"><p>You will need more than a week. If you just want to predict the next word in a sentence, take a look at large language models. ChatGPT being one of them. BERT is a research alternative afaik. If you aim to learn the probabilities yourself, you will need at least a few months. </p>\n\n<p>In general what you want is a generative model that can sample from the conditional probability distribution. In sequences usually transformers like BERT and chatgpt are state of the art. You can also take a look at normalizing flows and diffusion models to learn probability distributions. But this needs some maths, and i unfortunatly do not know what smaller models can be used for computational linguistic applications like this.</p>\n</div>",
      "created_utc": 1678991557.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jcgq97y/",
      "parent_id": "t1_jc7szbg",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-16T11:32:37"
    },
    {
      "id": "jcalqfm",
      "author": "trnka",
      "body": "Converting the text to fixed-size windows is done to make training more efficient. If the inputs are shorter, they're padded up to the correct length with null tokens. Otherwise they're clipped. It's done so that you can combine multiple examples into a single batch, which becomes an additional dimension on your tensors. It's a common technique even for LSTMs/CNNs.\n\nIt's often possible to take the trained model and apply it to variable-length testing data so long as you're dealing with a single example at a time rather than a batch. But keep in mind with transformers that attention does N\\^2 comparisons, where N is the number of tokens, so it doesn't scale well to long texts.\n\nIt's possible that the positional encoding may be specific to the input length, depending on the transformer implementation. For instance in Karpathy's GPT recreation video he made the positional encoding learnable by position, so it wouldn't have defined values for longer sequences.\n\nOne common alternative in training is to create batches of examples that are mostly the same text length, then pad to the max length. You can get training speedups that way but it takes a bit of extra code.",
      "body_html": "<div class=\"md\"><p>Converting the text to fixed-size windows is done to make training more efficient. If the inputs are shorter, they&#39;re padded up to the correct length with null tokens. Otherwise they&#39;re clipped. It&#39;s done so that you can combine multiple examples into a single batch, which becomes an additional dimension on your tensors. It&#39;s a common technique even for LSTMs/CNNs.</p>\n\n<p>It&#39;s often possible to take the trained model and apply it to variable-length testing data so long as you&#39;re dealing with a single example at a time rather than a batch. But keep in mind with transformers that attention does N^2 comparisons, where N is the number of tokens, so it doesn&#39;t scale well to long texts.</p>\n\n<p>It&#39;s possible that the positional encoding may be specific to the input length, depending on the transformer implementation. For instance in Karpathy&#39;s GPT recreation video he made the positional encoding learnable by position, so it wouldn&#39;t have defined values for longer sequences.</p>\n\n<p>One common alternative in training is to create batches of examples that are mostly the same text length, then pad to the max length. You can get training speedups that way but it takes a bit of extra code.</p>\n</div>",
      "created_utc": 1678888938.0,
      "score": 2,
      "ups": 2,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jcalqfm/",
      "parent_id": "t1_jc8ynrt",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-15T07:02:18"
    },
    {
      "id": "jcgo5ro",
      "author": "LeN3rd",
      "body": "You should take a look at uncertainty in general. What you are trying to do is calculate epistemic uncertainty. (google epistemic vs aleatoric uncertainty). \n\nOne thing that works well is to have a dropout layer, that is active during prediction!! (in tensorflow you have to feed training=True into the call to activate it during prediction). Sample like 100 times and calculate the standard deviation. This gives you a general \"i do not know\" function from the network. You can also do so by training 20 models and letting them output 20 different results. With this you can assign the 101 label, when the uncertainty is too high.\n\nIn my experience you should stay away from bayesian neural networks, since the are extremly hard to train, and cannot model multimodal uncertainty. (dropout can neither, but is WAAAAYYY easier to train).",
      "body_html": "<div class=\"md\"><p>You should take a look at uncertainty in general. What you are trying to do is calculate epistemic uncertainty. (google epistemic vs aleatoric uncertainty). </p>\n\n<p>One thing that works well is to have a dropout layer, that is active during prediction!! (in tensorflow you have to feed training=True into the call to activate it during prediction). Sample like 100 times and calculate the standard deviation. This gives you a general &quot;i do not know&quot; function from the network. You can also do so by training 20 models and letting them output 20 different results. With this you can assign the 101 label, when the uncertainty is too high.</p>\n\n<p>In my experience you should stay away from bayesian neural networks, since the are extremly hard to train, and cannot model multimodal uncertainty. (dropout can neither, but is WAAAAYYY easier to train).</p>\n</div>",
      "created_utc": 1678990773.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jcgo5ro/",
      "parent_id": "t1_jccbh4w",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-16T11:19:33"
    },
    {
      "id": "jcxlc7t",
      "author": "henkje112",
      "body": "Look into Convolutional Neural Networks as your architecture type and different types of spectrograms as your input features. The different layers of the CNN should do the feature transformation, and your final layer should be dense, with a softmax (or any other desired) activation function.",
      "body_html": "<div class=\"md\"><p>Look into Convolutional Neural Networks as your architecture type and different types of spectrograms as your input features. The different layers of the CNN should do the feature transformation, and your final layer should be dense, with a softmax (or any other desired) activation function.</p>\n</div>",
      "created_utc": 1679307231.0,
      "score": 2,
      "ups": 2,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jcxlc7t/",
      "parent_id": "t1_jccekvp",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-20T03:13:51"
    },
    {
      "id": "jcgu1z5",
      "author": "LeN3rd",
      "body": "This is possible in multiple ways. Old methods for this would be to view this as an inverse problem and apply some optimization method to it, like ADMM or FISTA. \n\nIf lots of data is missing (in your case the complete R&G channels) you should use a neural network for this. You are on the right track, though it could get hairy. If you have a prior (You have a dataset and you want it to work on similar images), a (cycle) GAN, or a retrained Stable diffusion model could work. \n\nI am unsure about VAEs for your problem, since you usually train them by having the same input and output. You shouldn't enforce the latent to be only the blue channel, since the the encoder is useless. Training only the decoder site is essentially what GANs and diffusion networks do so i would start there.",
      "body_html": "<div class=\"md\"><p>This is possible in multiple ways. Old methods for this would be to view this as an inverse problem and apply some optimization method to it, like ADMM or FISTA. </p>\n\n<p>If lots of data is missing (in your case the complete R&amp;G channels) you should use a neural network for this. You are on the right track, though it could get hairy. If you have a prior (You have a dataset and you want it to work on similar images), a (cycle) GAN, or a retrained Stable diffusion model could work. </p>\n\n<p>I am unsure about VAEs for your problem, since you usually train them by having the same input and output. You shouldn&#39;t enforce the latent to be only the blue channel, since the the encoder is useless. Training only the decoder site is essentially what GANs and diffusion networks do so i would start there.</p>\n</div>",
      "created_utc": 1678992960.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jcgu1z5/",
      "parent_id": "t1_jccqitv",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-16T11:56:00"
    },
    {
      "id": "jcgsjxq",
      "author": "LeN3rd",
      "body": "define probabilistic. Is it model uncertainty, or data uncertainty? Either way you should get a standard deviation from your model (either as an output parameter, or implicitly by ensembles), that you can compare.",
      "body_html": "<div class=\"md\"><p>define probabilistic. Is it model uncertainty, or data uncertainty? Either way you should get a standard deviation from your model (either as an output parameter, or implicitly by ensembles), that you can compare.</p>\n</div>",
      "created_utc": 1678992413.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jcgsjxq/",
      "parent_id": "t1_jcf9ag7",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-16T11:46:53"
    },
    {
      "id": "jcmql4c",
      "author": "ggf31416",
      "body": "At the speeds these things move, when you see them coming it's already too late to do any corrective maneuver. It's the same reason you don't use your eyeballs to detect aircraft 100km away.\nSee https://en.wikipedia.org/wiki/Space_debris#Tracking_and_measurement, \n[Algorithms to Antenna: Tracking Space Debris with a Radar Network](https://www.mwrf.com/technologies/systems/article/21145361/mathworks-algorithms-to-antenna-tracking-space-debris-with-a-radar-network), RADAR and LIDAR are used.",
      "body_html": "<div class=\"md\"><p>At the speeds these things move, when you see them coming it&#39;s already too late to do any corrective maneuver. It&#39;s the same reason you don&#39;t use your eyeballs to detect aircraft 100km away.\nSee <a href=\"https://en.wikipedia.org/wiki/Space_debris#Tracking_and_measurement\">https://en.wikipedia.org/wiki/Space_debris#Tracking_and_measurement</a>, \n<a href=\"https://www.mwrf.com/technologies/systems/article/21145361/mathworks-algorithms-to-antenna-tracking-space-debris-with-a-radar-network\">Algorithms to Antenna: Tracking Space Debris with a Radar Network</a>, RADAR and LIDAR are used.</p>\n</div>",
      "created_utc": 1679095234.0,
      "score": 2,
      "ups": 2,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jcmql4c/",
      "parent_id": "t1_jckpovo",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-17T16:20:34"
    },
    {
      "id": "jcxjx44",
      "author": "henkje112",
      "body": "I'm assuming you're using sklearn for LinearRegression. You're initializing an instance of the LinearRegression class with a `normalize` parameter, but this is not valid for this class (for a list of possible parameters, see [the documentation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)).\n\nI'm not sure what you're trying to do, but I think you want to normalize your input data? In that case you should ook at [MinMaxScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html). This transforms your features by scaling each feature to a given range.",
      "body_html": "<div class=\"md\"><p>I&#39;m assuming you&#39;re using sklearn for LinearRegression. You&#39;re initializing an instance of the LinearRegression class with a <code>normalize</code> parameter, but this is not valid for this class (for a list of possible parameters, see <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html\">the documentation</a>).</p>\n\n<p>I&#39;m not sure what you&#39;re trying to do, but I think you want to normalize your input data? In that case you should ook at <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html\">MinMaxScaler</a>. This transforms your features by scaling each feature to a given range.</p>\n</div>",
      "created_utc": 1679306043.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jcxjx44/",
      "parent_id": "t1_jcvak4c",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-20T02:54:03"
    },
    {
      "id": "jdgl589",
      "author": "nth_citizen",
      "body": "I'm not aware of anything like this and depending on your vision I can certainly see something like the first step being reasonable - might be willing to help as it sounds kind of interesting.",
      "body_html": "<div class=\"md\"><p>I&#39;m not aware of anything like this and depending on your vision I can certainly see something like the first step being reasonable - might be willing to help as it sounds kind of interesting.</p>\n</div>",
      "created_utc": 1679639559.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jdgl589/",
      "parent_id": "t1_jcwhvs3",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-23T23:32:39"
    },
    {
      "id": "jcyped6",
      "author": "trnka",
      "body": "Some systems output the most probable token in each context, so those will be consistent given a prompt. Traditionally that could lead to very generic responses.\n\nSo it's common to add a bit of randomness into it. The simplest approach is to generate tokens according to their probability. There are many other variations on this to allow more control over how \"creative\" the generator can be.",
      "body_html": "<div class=\"md\"><p>Some systems output the most probable token in each context, so those will be consistent given a prompt. Traditionally that could lead to very generic responses.</p>\n\n<p>So it&#39;s common to add a bit of randomness into it. The simplest approach is to generate tokens according to their probability. There are many other variations on this to allow more control over how &quot;creative&quot; the generator can be.</p>\n</div>",
      "created_utc": 1679328292.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jcyped6/",
      "parent_id": "t1_jcwyjyv",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-20T09:04:52"
    },
    {
      "id": "jd2qmh1",
      "author": "YouAgainShmidhoobuh",
      "body": "Not entirely the same thing. VAEs offer **approximate** likelihood estimation, but not **exact**. The difference here is key - VAEs do not optimize the log-likelihood directly but they do so through the evidence lower bound, an approximation. Flow based methods are exact methods - we go from an easy tractable distribution to a more complex one, guaranteeing at each level that the learned distribution is actually a legit distribution through the change of variables theorem.\n\nOf course, the both (try) to learn some probability distribution of the training data, and that is how they would differ from GAN approaches that do not directly learn a probability distribution.\n\nFor more insight you might want to look at https://openreview.net/pdf?id=HklKEUUY\\_E",
      "body_html": "<div class=\"md\"><p>Not entirely the same thing. VAEs offer <strong>approximate</strong> likelihood estimation, but not <strong>exact</strong>. The difference here is key - VAEs do not optimize the log-likelihood directly but they do so through the evidence lower bound, an approximation. Flow based methods are exact methods - we go from an easy tractable distribution to a more complex one, guaranteeing at each level that the learned distribution is actually a legit distribution through the change of variables theorem.</p>\n\n<p>Of course, the both (try) to learn some probability distribution of the training data, and that is how they would differ from GAN approaches that do not directly learn a probability distribution.</p>\n\n<p>For more insight you might want to look at <a href=\"https://openreview.net/pdf?id=HklKEUUY%5C_E\">https://openreview.net/pdf?id=HklKEUUY\\_E</a></p>\n</div>",
      "created_utc": 1679402673.0,
      "score": 2,
      "ups": 2,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jd2qmh1/",
      "parent_id": "t1_jcxqcgw",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-21T05:44:33"
    },
    {
      "id": "jd2ojml",
      "author": "YouAgainShmidhoobuh",
      "body": "If you mean the context/sequence length, it's 2048 (https://github.com/facebookresearch/llama/pull/127).",
      "body_html": "<div class=\"md\"><p>If you mean the context/sequence length, it&#39;s 2048 (<a href=\"https://github.com/facebookresearch/llama/pull/127\">https://github.com/facebookresearch/llama/pull/127</a>).</p>\n</div>",
      "created_utc": 1679401571.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jd2ojml/",
      "parent_id": "t1_jczkfku",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-21T05:26:11"
    },
    {
      "id": "jdbtg4x",
      "author": "fnordstar",
      "body": "That is an image dataset. What are you even training on if you're not using the images?",
      "body_html": "<div class=\"md\"><p>That is an image dataset. What are you even training on if you&#39;re not using the images?</p>\n</div>",
      "created_utc": 1679557034.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jdbtg4x/",
      "parent_id": "t1_jd9tanf",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-23T00:37:14"
    },
    {
      "id": "jdhvzy3",
      "author": "trnka",
      "body": "Eh, we've gone through a lot of hype cycles before and the field still exists. For example, deep learning was hyped to replace all feature engineering for all problems and then NLP would be trivialized. In practice, that was overhyped and you still need to understand NLP to get value out of deep learning for NLP. And in practice, there's still quite a bit of feature engineering (and practices like it).\n\nI think LLMs will turn out to be similar. They'll change the way we approach many problems, but you'll still need to understand both LLMs and more problem-specific aspects of ML.\n\nBack to your question, if you enjoy AI/ML and you're worried about jobs in a few years, I think it's still worth pursuing your interests.\n\nIf anything, the bigger challenge in jobs in the next year or two is the current job market.",
      "body_html": "<div class=\"md\"><p>Eh, we&#39;ve gone through a lot of hype cycles before and the field still exists. For example, deep learning was hyped to replace all feature engineering for all problems and then NLP would be trivialized. In practice, that was overhyped and you still need to understand NLP to get value out of deep learning for NLP. And in practice, there&#39;s still quite a bit of feature engineering (and practices like it).</p>\n\n<p>I think LLMs will turn out to be similar. They&#39;ll change the way we approach many problems, but you&#39;ll still need to understand both LLMs and more problem-specific aspects of ML.</p>\n\n<p>Back to your question, if you enjoy AI/ML and you&#39;re worried about jobs in a few years, I think it&#39;s still worth pursuing your interests.</p>\n\n<p>If anything, the bigger challenge in jobs in the next year or two is the current job market.</p>\n</div>",
      "created_utc": 1679669161.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jdhvzy3/",
      "parent_id": "t1_jde9kv5",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-24T07:46:01"
    },
    {
      "id": "jdhe9qb",
      "author": "LeN3rd",
      "body": "What language/suite are you using? You can take a look at profilers in your language. I know Tensorflow has some profiling tools and you can look at what operations are running on what device. Probably Torch has some as well. If its more esoteric, just use general language profilers and take a look at what your code is doing most of the time.",
      "body_html": "<div class=\"md\"><p>What language/suite are you using? You can take a look at profilers in your language. I know Tensorflow has some profiling tools and you can look at what operations are running on what device. Probably Torch has some as well. If its more esoteric, just use general language profilers and take a look at what your code is doing most of the time.</p>\n</div>",
      "created_utc": 1679661357.0,
      "score": 2,
      "ups": 2,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jdhe9qb/",
      "parent_id": "t1_jdgqv13",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-24T05:35:57"
    },
    {
      "id": "jdhe09x",
      "author": "LeN3rd",
      "body": "From what i have heard, it should be possible. But only with the 7B model. Unless you own a few A/H 100s.",
      "body_html": "<div class=\"md\"><p>From what i have heard, it should be possible. But only with the 7B model. Unless you own a few A/H 100s.</p>\n</div>",
      "created_utc": 1679661220.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jdhe09x/",
      "parent_id": "t1_jdgutr0",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-24T05:33:40"
    },
    {
      "id": "jdnag2i",
      "author": "Simusid",
      "body": "I’m unable to connect to hamata.so. Can you tell me what kind of analysis you want to do?",
      "body_html": "<div class=\"md\"><p>I’m unable to connect to hamata.so. Can you tell me what kind of analysis you want to do?</p>\n</div>",
      "created_utc": 1679766895.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jdnag2i/",
      "parent_id": "t1_jdmhn6h",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-25T10:54:55"
    },
    {
      "id": "jdq0nsn",
      "author": "LowPressureUsername",
      "body": "It’s mostly computational power available AFAIK. More context = more tokens = more processing power required.",
      "body_html": "<div class=\"md\"><p>It’s mostly computational power available AFAIK. More context = more tokens = more processing power required.</p>\n</div>",
      "created_utc": 1679817510.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jdq0nsn/",
      "parent_id": "t1_jdn17j5",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-26T00:58:30"
    },
    {
      "id": "jdpaf54",
      "author": "LacedDecal",
      "body": "After posting this here I decided to ask chatgpt something similar.  I am continually floored by how good it is every time I use it.  For those interested: https://ibb.co/4F1QPJ7",
      "body_html": "<div class=\"md\"><p>After posting this here I decided to ask chatgpt something similar.  I am continually floored by how good it is every time I use it.  For those interested: <a href=\"https://ibb.co/4F1QPJ7\">https://ibb.co/4F1QPJ7</a></p>\n</div>",
      "created_utc": 1679799343.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jdpaf54/",
      "parent_id": "t1_jdp6z6y",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-25T19:55:43"
    },
    {
      "id": "jc11j00",
      "author": "kuraisle",
      "body": "That's really helpful, thank you!",
      "body_html": "<div class=\"md\"><p>That&#39;s really helpful, thank you!</p>\n</div>",
      "created_utc": 1678690648.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jc11j00/",
      "parent_id": "t1_jc0ltpb",
      "depth": 2,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-12T23:57:28"
    },
    {
      "id": "jchxtfy",
      "author": "DreamMidnight",
      "body": "Yes, although I am specifically looking into the reasoning of \"at least 10 datapoints per variable.\"\n\nWhat is the mathematical reasoning of this minimum?",
      "body_html": "<div class=\"md\"><p>Yes, although I am specifically looking into the reasoning of &quot;at least 10 datapoints per variable.&quot;</p>\n\n<p>What is the mathematical reasoning of this minimum?</p>\n</div>",
      "created_utc": 1679008652.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jchxtfy/",
      "parent_id": "t1_jcgqzvo",
      "depth": 2,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-16T16:17:32"
    },
    {
      "id": "jcleo4j",
      "author": "Sonicxc",
      "body": "Hey man, thanks for the input. I will look into what you have mentioned",
      "body_html": "<div class=\"md\"><p>Hey man, thanks for the input. I will look into what you have mentioned</p>\n</div>",
      "created_utc": 1679075819.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jcleo4j/",
      "parent_id": "t1_jcgp44s",
      "depth": 2,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-17T10:56:59"
    },
    {
      "id": "jcj2q3v",
      "author": "rainnz",
      "body": "Thank you kind Redditor!",
      "body_html": "<div class=\"md\"><p>Thank you kind Redditor!</p>\n</div>",
      "created_utc": 1679028474.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jcj2q3v/",
      "parent_id": "t1_jcj24kc",
      "depth": 2,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-16T21:47:54"
    },
    {
      "id": "jde4ayx",
      "author": "andrew21w",
      "body": "The thread you sent me says that polynomials are non discriminatory.\n\n\nAre there other kinds of functions that are non discriminatory?",
      "body_html": "<div class=\"md\"><p>The thread you sent me says that polynomials are non discriminatory.</p>\n\n<p>Are there other kinds of functions that are non discriminatory?</p>\n</div>",
      "created_utc": 1679598434.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jde4ayx/",
      "parent_id": "t1_jddpryu",
      "depth": 2,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-23T12:07:14"
    },
    {
      "id": "jdi0izc",
      "author": "JimiSlew3",
      "body": "Thanks. I'm curious once we get it to do things. Like, tell it to analyze a giant dataset, and produce a visual of interesting stuff. Some tools I use will offer suggestions and I'm thinking the link between asking a question and getting information will be significantly shortened and wanted to know if anyone had done that yet.",
      "body_html": "<div class=\"md\"><p>Thanks. I&#39;m curious once we get it to do things. Like, tell it to analyze a giant dataset, and produce a visual of interesting stuff. Some tools I use will offer suggestions and I&#39;m thinking the link between asking a question and getting information will be significantly shortened and wanted to know if anyone had done that yet.</p>\n</div>",
      "created_utc": 1679670921.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jdi0izc/",
      "parent_id": "t1_jdhecq5",
      "depth": 2,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-24T08:15:21"
    },
    {
      "id": "jbybzoo",
      "author": "wikipedia_answer_bot",
      "body": "baby don't hurt me\n\n\n\n\n\n*This comment was left automatically (by a bot). If I don't get this right, don't get mad at me, I'm still learning!*\n\n[^(opt out)](https://www.reddit.com/r/wikipedia_answer_bot/comments/ozztfy/post_for_opting_out/) ^(|) [^(delete)](https://www.reddit.com/r/wikipedia_answer_bot/comments/q79g2t/delete_feature_added/) ^(|) [^(report/suggest)](https://www.reddit.com/r/wikipedia_answer_bot) ^(|) [^(GitHub)](https://github.com/TheBugYouCantFix/wiki-reddit-bot)",
      "body_html": "<div class=\"md\"><p>baby don&#39;t hurt me</p>\n\n<p><em>This comment was left automatically (by a bot). If I don&#39;t get this right, don&#39;t get mad at me, I&#39;m still learning!</em></p>\n\n<p><a href=\"https://www.reddit.com/r/wikipedia_answer_bot/comments/ozztfy/post_for_opting_out/\"><sup>opt out</sup></a> <sup>|</sup> <a href=\"https://www.reddit.com/r/wikipedia_answer_bot/comments/q79g2t/delete_feature_added/\"><sup>delete</sup></a> <sup>|</sup> <a href=\"https://www.reddit.com/r/wikipedia_answer_bot\"><sup>report/suggest</sup></a> <sup>|</sup> <a href=\"https://github.com/TheBugYouCantFix/wiki-reddit-bot\"><sup>GitHub</sup></a></p>\n</div>",
      "created_utc": 1678643370.0,
      "score": 8,
      "ups": 8,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jbybzoo/",
      "parent_id": "t1_jbybye9",
      "depth": 2,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-12T10:49:30"
    },
    {
      "id": "jcthdzz",
      "author": "EcstaticStruggle",
      "body": "Thanks. This was something I tried earlier. I noticed that using the maximum number of estimators almost always lead to the highest cross validation score. I was worried there would be some overfitting as a result.",
      "body_html": "<div class=\"md\"><p>Thanks. This was something I tried earlier. I noticed that using the maximum number of estimators almost always lead to the highest cross validation score. I was worried there would be some overfitting as a result.</p>\n</div>",
      "created_utc": 1679231642.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jcthdzz/",
      "parent_id": "t1_jcpu2pe",
      "depth": 2,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-19T06:14:02"
    },
    {
      "id": "jcgshk7",
      "author": "No_Complaint_1304",
      "body": "Well I did expect this but still **month’s**!   I’ll look into everything you mentioned. And I’ll drop the project for now, if I can’t finish it by studying heavily, I might as well learn slowly but surely, absorb all the information and then go back to make a project that involve predictions and analyzing data. ty4ur help",
      "body_html": "<div class=\"md\"><p>Well I did expect this but still <strong>month’s</strong>!   I’ll look into everything you mentioned. And I’ll drop the project for now, if I can’t finish it by studying heavily, I might as well learn slowly but surely, absorb all the information and then go back to make a project that involve predictions and analyzing data. ty4ur help</p>\n</div>",
      "created_utc": 1678992387.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jcgshk7/",
      "parent_id": "t1_jcgq97y",
      "depth": 2,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-16T11:46:27"
    },
    {
      "id": "jd20dzj",
      "author": "ViceOA",
      "body": ">Look into Convolutional Neural Networks as your architecture type and different types of spectrograms as your input features. The different layers of the CNN should do the feature transformation, and your final layer should be dense, with a softmax (or any other desired) activation function.\n\nThanks for your precios advices, im grateful!",
      "body_html": "<div class=\"md\"><blockquote>\n<p>Look into Convolutional Neural Networks as your architecture type and different types of spectrograms as your input features. The different layers of the CNN should do the feature transformation, and your final layer should be dense, with a softmax (or any other desired) activation function.</p>\n</blockquote>\n\n<p>Thanks for your precios advices, im grateful!</p>\n</div>",
      "created_utc": 1679382861.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jd20dzj/",
      "parent_id": "t1_jcxlc7t",
      "depth": 2,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-21T00:14:21"
    },
    {
      "id": "jci3t9m",
      "author": "Batteredcode",
      "body": "Great, thank you so much for a detailed answer. Do you have anything you could point me to (or explain further) about how I could modify a diffusion method to do this?  \nAlso, in terms of the VAE, I was thinking I'd be able to feed 2 channels in and train it to output 3 channels, I believe the encoder wouldn't be useless in this case and hence my latent would be more than merely the missing channel? Feel free to correct me if I'm wrong! My assumption is that even with this a NN may well perform better, or at least a simpler baseline. That said, my images will be similar in certain ways, so being able to model a distribution of the latents could prove useful presumably?",
      "body_html": "<div class=\"md\"><p>Great, thank you so much for a detailed answer. Do you have anything you could point me to (or explain further) about how I could modify a diffusion method to do this?<br/>\nAlso, in terms of the VAE, I was thinking I&#39;d be able to feed 2 channels in and train it to output 3 channels, I believe the encoder wouldn&#39;t be useless in this case and hence my latent would be more than merely the missing channel? Feel free to correct me if I&#39;m wrong! My assumption is that even with this a NN may well perform better, or at least a simpler baseline. That said, my images will be similar in certain ways, so being able to model a distribution of the latents could prove useful presumably?</p>\n</div>",
      "created_utc": 1679011223.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jci3t9m/",
      "parent_id": "t1_jcgu1z5",
      "depth": 2,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-16T17:00:23"
    },
    {
      "id": "jcgy9ya",
      "author": "ilrazziatore",
      "body": "Model uncertainty.  One model is a calibrated bnn ( i splitted the dataset in a training, a calibration and a test set), the other model is a mathematical model developed considering some physical relation.\nFor computational reasons the bnn assume iid samples normally distributed around their true values and maximize the likelihood (modeled as a product of normal distribution), the mathematical model instead  rely on 4 coefficients and is fitted using Monte Carlo with a multivariate likelihood with the full covariance matrix. I wanted to compare the quality of the model uncertainty estimates but I don't know if I should do it on the test dataset for both. Afterall, models calibrated with mcmc methods do not overfit so why split the dataset?",
      "body_html": "<div class=\"md\"><p>Model uncertainty.  One model is a calibrated bnn ( i splitted the dataset in a training, a calibration and a test set), the other model is a mathematical model developed considering some physical relation.\nFor computational reasons the bnn assume iid samples normally distributed around their true values and maximize the likelihood (modeled as a product of normal distribution), the mathematical model instead  rely on 4 coefficients and is fitted using Monte Carlo with a multivariate likelihood with the full covariance matrix. I wanted to compare the quality of the model uncertainty estimates but I don&#39;t know if I should do it on the test dataset for both. Afterall, models calibrated with mcmc methods do not overfit so why split the dataset?</p>\n</div>",
      "created_utc": 1678994553.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jcgy9ya/",
      "parent_id": "t1_jcgsjxq",
      "depth": 2,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-16T12:22:33"
    },
    {
      "id": "jcn2oye",
      "author": "f-d-t777",
      "body": "Interesting, how would you alter my project idea then?",
      "body_html": "<div class=\"md\"><p>Interesting, how would you alter my project idea then?</p>\n</div>",
      "created_utc": 1679100604.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jcn2oye/",
      "parent_id": "t1_jcmql4c",
      "depth": 2,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-17T17:50:04"
    },
    {
      "id": "jdyw4pf",
      "author": "rylo_ren_",
      "body": "Thank you!! I’ll give it a try. And yes I’m using sklearn",
      "body_html": "<div class=\"md\"><p>Thank you!! I’ll give it a try. And yes I’m using sklearn</p>\n</div>",
      "created_utc": 1679979578.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jdyw4pf/",
      "parent_id": "t1_jcxjx44",
      "depth": 2,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-27T21:59:38"
    },
    {
      "id": "jd66swu",
      "author": "disastorm",
      "body": "I see thanks, is that basically the equivallent of having \"top\\_k\" = 1?\n\nCan you explain what these mean. From what I understand top\\_k means it considers the top K number of possible words at each step.\n\nI can't exactly understand what top\\_p means, can they be use together?",
      "body_html": "<div class=\"md\"><p>I see thanks, is that basically the equivallent of having &quot;top_k&quot; = 1?</p>\n\n<p>Can you explain what these mean. From what I understand top_k means it considers the top K number of possible words at each step.</p>\n\n<p>I can&#39;t exactly understand what top_p means, can they be use together?</p>\n</div>",
      "created_utc": 1679453312.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jd66swu/",
      "parent_id": "t1_jcyped6",
      "depth": 2,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-21T19:48:32"
    },
    {
      "id": "jd4ts2d",
      "author": "darthstargazer",
      "body": "Awesome! Thanks for the explanation. \"exact\" vs \"approximate\"!",
      "body_html": "<div class=\"md\"><p>Awesome! Thanks for the explanation. &quot;exact&quot; vs &quot;approximate&quot;!</p>\n</div>",
      "created_utc": 1679432474.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jd4ts2d/",
      "parent_id": "t1_jd2qmh1",
      "depth": 2,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-21T14:01:14"
    },
    {
      "id": "jd3alix",
      "author": "Xotchkass",
      "body": "thanks",
      "body_html": "<div class=\"md\"><p>thanks</p>\n</div>",
      "created_utc": 1679411523.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jd3alix/",
      "parent_id": "t1_jd2ojml",
      "depth": 2,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-21T08:12:03"
    },
    {
      "id": "jdc74v5",
      "author": "GaryS2000",
      "body": "Like I said the .csv data. Its the same data as the image dataset with one of thr columns containing the pixel values of the images, meaning it can reconstruct the image from the file.",
      "body_html": "<div class=\"md\"><p>Like I said the .csv data. Its the same data as the image dataset with one of thr columns containing the pixel values of the images, meaning it can reconstruct the image from the file.</p>\n</div>",
      "created_utc": 1679568769.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jdc74v5/",
      "parent_id": "t1_jdbtg4x",
      "depth": 2,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-23T03:52:49"
    },
    {
      "id": "jdjg4gq",
      "author": "kross00",
      "body": "Do you know which datasets they use?",
      "body_html": "<div class=\"md\"><p>Do you know which datasets they use?</p>\n</div>",
      "created_utc": 1679690793.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jdjg4gq/",
      "parent_id": "t1_jdhe09x",
      "depth": 2,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-24T13:46:33"
    },
    {
      "id": "jdron1b",
      "author": "yaru22",
      "body": "So it's not an inherent limitation on the number of parameters the model has? Or is that what you meant by more processing power? Do you or does anyone have some pointers to papers that talk about this?",
      "body_html": "<div class=\"md\"><p>So it&#39;s not an inherent limitation on the number of parameters the model has? Or is that what you meant by more processing power? Do you or does anyone have some pointers to papers that talk about this?</p>\n</div>",
      "created_utc": 1679852377.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jdron1b/",
      "parent_id": "t1_jdq0nsn",
      "depth": 2,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-26T10:39:37"
    },
    {
      "id": "jcislrk",
      "author": "LeN3rd",
      "body": "I have not heard this before. Where is it from? I know that you should have more datapoints than parameters in classical models.",
      "body_html": "<div class=\"md\"><p>I have not heard this before. Where is it from? I know that you should have more datapoints than parameters in classical models.</p>\n</div>",
      "created_utc": 1679022713.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jcislrk/",
      "parent_id": "t1_jchxtfy",
      "depth": 3,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-16T20:11:53"
    },
    {
      "id": "jd1irhb",
      "author": "VS2ute",
      "body": "If you have random noise on a variable, it can have a substantial effect when too few samples.",
      "body_html": "<div class=\"md\"><p>If you have random noise on a variable, it can have a substantial effect when too few samples.</p>\n</div>",
      "created_utc": 1679370237.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jd1irhb/",
      "parent_id": "t1_jchxtfy",
      "depth": 3,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-20T20:43:57"
    },
    {
      "id": "jdeofve",
      "author": "underPanther",
      "body": "Sorry for the confusion! It's discriminatory activations that lead to universality in wide single layer networks. I've editted post to reflect this.\n\nAs an aside, you might also find the following interesting which is also extremely well-cited: [https://www.sciencedirect.com/science/article/abs/pii/S0893608005801315](https://www.sciencedirect.com/science/article/abs/pii/S0893608005801315)",
      "body_html": "<div class=\"md\"><p>Sorry for the confusion! It&#39;s discriminatory activations that lead to universality in wide single layer networks. I&#39;ve editted post to reflect this.</p>\n\n<p>As an aside, you might also find the following interesting which is also extremely well-cited: <a href=\"https://www.sciencedirect.com/science/article/abs/pii/S0893608005801315\">https://www.sciencedirect.com/science/article/abs/pii/S0893608005801315</a></p>\n</div>",
      "created_utc": 1679606120.0,
      "score": 2,
      "ups": 2,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jdeofve/",
      "parent_id": "t1_jde4ayx",
      "depth": 3,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-23T14:15:20"
    },
    {
      "id": "jcgs51v",
      "author": "LeN3rd",
      "body": "don't hurt me",
      "body_html": "<div class=\"md\"><p>don&#39;t hurt me</p>\n</div>",
      "created_utc": 1678992255.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jcgs51v/",
      "parent_id": "t1_jbybzoo",
      "depth": 3,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-16T11:44:15"
    },
    {
      "id": "jcguoiy",
      "author": "LeN3rd",
      "body": "I didn't mean to discourage you. Its a fascinating field, but it is its own field of research for a reason. Start with BERT and see where that gets you. \n\nThese ones are also a nice small watch: \n\n[https://www.youtube.com/watch?v=gQddtTdmG\\_8](https://www.youtube.com/watch?v=gQddtTdmG_8)\n\n[https://www.youtube.com/watch?v=rURRYI66E54](https://www.youtube.com/watch?v=rURRYI66E54)",
      "body_html": "<div class=\"md\"><p>I didn&#39;t mean to discourage you. Its a fascinating field, but it is its own field of research for a reason. Start with BERT and see where that gets you. </p>\n\n<p>These ones are also a nice small watch: </p>\n\n<p><a href=\"https://www.youtube.com/watch?v=gQddtTdmG_8\">https://www.youtube.com/watch?v=gQddtTdmG_8</a></p>\n\n<p><a href=\"https://www.youtube.com/watch?v=rURRYI66E54\">https://www.youtube.com/watch?v=rURRYI66E54</a></p>\n</div>",
      "created_utc": 1678993190.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jcguoiy/",
      "parent_id": "t1_jcgshk7",
      "depth": 3,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-16T11:59:50"
    },
    {
      "id": "jcitswg",
      "author": "LeN3rd",
      "body": "The problem with your VAE idea is, that you cannot apply the usual loss function of having the difference between the input and the output, and thous a lot of nice theoretical constraints go out of the window afaik. \n\n[https://jaan.io/what-is-variational-autoencoder-vae-tutorial/](https://jaan.io/what-is-variational-autoencoder-vae-tutorial/)\n\n&#x200B;\n\nI would start with a cycleGAN: \n\n[https://machinelearningmastery.com/what-is-cyclegan/](https://machinelearningmastery.com/what-is-cyclegan/)\n\nIts a little older, but i personally know it a bit better than diffusion methods. \n\n&#x200B;\n\nWith the free to use StableDiffusion model you could use it to conditionally inpaint on your image, though you would have to describe what is on that image in text. You could also train your own diffusion model, though you need a lot of training time. Not necessarily more than a GAN, but still. \n\nIt works by adding noise to an image, and then denoising it again and again. For inpainting you just do that for the regions you want to inpaint (your R and G channel), and for the regions you wanna stay the same as your original image, you just take the noise that you already know.",
      "body_html": "<div class=\"md\"><p>The problem with your VAE idea is, that you cannot apply the usual loss function of having the difference between the input and the output, and thous a lot of nice theoretical constraints go out of the window afaik. </p>\n\n<p><a href=\"https://jaan.io/what-is-variational-autoencoder-vae-tutorial/\">https://jaan.io/what-is-variational-autoencoder-vae-tutorial/</a></p>\n\n<p>&#x200B;</p>\n\n<p>I would start with a cycleGAN: </p>\n\n<p><a href=\"https://machinelearningmastery.com/what-is-cyclegan/\">https://machinelearningmastery.com/what-is-cyclegan/</a></p>\n\n<p>Its a little older, but i personally know it a bit better than diffusion methods. </p>\n\n<p>&#x200B;</p>\n\n<p>With the free to use StableDiffusion model you could use it to conditionally inpaint on your image, though you would have to describe what is on that image in text. You could also train your own diffusion model, though you need a lot of training time. Not necessarily more than a GAN, but still. </p>\n\n<p>It works by adding noise to an image, and then denoising it again and again. For inpainting you just do that for the regions you want to inpaint (your R and G channel), and for the regions you wanna stay the same as your original image, you just take the noise that you already know.</p>\n</div>",
      "created_utc": 1679023322.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jcitswg/",
      "parent_id": "t1_jci3t9m",
      "depth": 3,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-16T20:22:02"
    },
    {
      "id": "jcgzk3c",
      "author": "LeN3rd",
      "body": "If it is model uncertainty, the bnn should only assume distributions only for the model parameters, no? If you make the samples a distribution, you assume data uncertainty. \nAlso I do not know exactly what you other model gives you, but as long as you get variances, I would just compare those at first. If the models give vastly different means, you should take that into account. There is probably some nice way to add this ensemble uncertainty with the uncertainty of the models. Also this strongly means that one model is biased and does jot give you a correct estimate of the model uncertainty.",
      "body_html": "<div class=\"md\"><p>If it is model uncertainty, the bnn should only assume distributions only for the model parameters, no? If you make the samples a distribution, you assume data uncertainty. \nAlso I do not know exactly what you other model gives you, but as long as you get variances, I would just compare those at first. If the models give vastly different means, you should take that into account. There is probably some nice way to add this ensemble uncertainty with the uncertainty of the models. Also this strongly means that one model is biased and does jot give you a correct estimate of the model uncertainty.</p>\n</div>",
      "created_utc": 1678995045.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jcgzk3c/",
      "parent_id": "t1_jcgy9ya",
      "depth": 3,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-16T12:30:45"
    },
    {
      "id": "jd82eo1",
      "author": "trnka",
      "body": "If you're using some API, it's probably best to look at the API docs.\n\nIf I had to guess, I'd say that top\\_k is about the beam width in beam search. And top\\_p is dynamically adjusting the beam width to cover the amount of the probability distribution you specify.\n\ntop\\_k=1 is probably what we'd call a greedy search. It's going left to right and picking the most probable token. The sequence of tokens selected in this way might not be the most probable sequence though. \n\nAgain, check the API docs to be sure.\n\nAll that said, these are just settings for discovering the most probable sequence in a computationally efficient way. It's still deterministic and still attempting to find the most probable sequence. What I was describing in the previous response was adding some randomness so that it's not deterministic.",
      "body_html": "<div class=\"md\"><p>If you&#39;re using some API, it&#39;s probably best to look at the API docs.</p>\n\n<p>If I had to guess, I&#39;d say that top_k is about the beam width in beam search. And top_p is dynamically adjusting the beam width to cover the amount of the probability distribution you specify.</p>\n\n<p>top_k=1 is probably what we&#39;d call a greedy search. It&#39;s going left to right and picking the most probable token. The sequence of tokens selected in this way might not be the most probable sequence though. </p>\n\n<p>Again, check the API docs to be sure.</p>\n\n<p>All that said, these are just settings for discovering the most probable sequence in a computationally efficient way. It&#39;s still deterministic and still attempting to find the most probable sequence. What I was describing in the previous response was adding some randomness so that it&#39;s not deterministic.</p>\n</div>",
      "created_utc": 1679496224.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jd82eo1/",
      "parent_id": "t1_jd66swu",
      "depth": 3,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-22T07:43:44"
    },
    {
      "id": "jdcakhx",
      "author": "fnordstar",
      "body": "Ohh ok wouldn't have thought someone would put pjxel data in a CSV.",
      "body_html": "<div class=\"md\"><p>Ohh ok wouldn&#39;t have thought someone would put pjxel data in a CSV.</p>\n</div>",
      "created_utc": 1679571034.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jdcakhx/",
      "parent_id": "t1_jdc74v5",
      "depth": 3,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-23T04:30:34"
    },
    {
      "id": "jcrh53z",
      "author": "DreamMidnight",
      "body": "Here are some sources:\n\nhttps://home.csulb.edu/~msaintg/ppa696/696regmx.htm\n\nhttps://developers.google.com/machine-learning/data-prep/construct/collect/data-size-quality (order of magnitude in this case means 10)\n\nhttps://stats.stackexchange.com/questions/163055/clarification-on-the-rule-of-10-for-logistic-regression",
      "body_html": "<div class=\"md\"><p>Here are some sources:</p>\n\n<p><a href=\"https://home.csulb.edu/%7Emsaintg/ppa696/696regmx.htm\">https://home.csulb.edu/~msaintg/ppa696/696regmx.htm</a></p>\n\n<p><a href=\"https://developers.google.com/machine-learning/data-prep/construct/collect/data-size-quality\">https://developers.google.com/machine-learning/data-prep/construct/collect/data-size-quality</a> (order of magnitude in this case means 10)</p>\n\n<p><a href=\"https://stats.stackexchange.com/questions/163055/clarification-on-the-rule-of-10-for-logistic-regression\">https://stats.stackexchange.com/questions/163055/clarification-on-the-rule-of-10-for-logistic-regression</a></p>\n</div>",
      "created_utc": 1679184643.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jcrh53z/",
      "parent_id": "t1_jcislrk",
      "depth": 4,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-18T17:10:43"
    },
    {
      "id": "jdhb3ae",
      "author": "Nyanraltotlapun",
      "body": "No more",
      "body_html": "<div class=\"md\"><p>No more</p>\n</div>",
      "created_utc": 1679659665.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jdhb3ae/",
      "parent_id": "t1_jcgs51v",
      "depth": 4,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-24T05:07:45"
    },
    {
      "id": "jchh2u9",
      "author": "No_Complaint_1304",
      "body": "Damn I hope no one got me wrong I wanted to learn the basics in a week (and finish my side project asap) I didn’t claim I could study such a large and complex field in a week.",
      "body_html": "<div class=\"md\"><p>Damn I hope no one got me wrong I wanted to learn the basics in a week (and finish my side project asap) I didn’t claim I could study such a large and complex field in a week.</p>\n</div>",
      "created_utc": 1679001866.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jchh2u9/",
      "parent_id": "t1_jcguoiy",
      "depth": 4,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-16T14:24:26"
    },
    {
      "id": "jcllc74",
      "author": "Batteredcode",
      "body": "Thank you this is really helpful, I think you're right that the cycle GAN is the way to go!",
      "body_html": "<div class=\"md\"><p>Thank you this is really helpful, I think you&#39;re right that the cycle GAN is the way to go!</p>\n</div>",
      "created_utc": 1679078393.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jcllc74/",
      "parent_id": "t1_jcitswg",
      "depth": 4,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-17T11:39:53"
    },
    {
      "id": "jch3vpu",
      "author": "ilrazziatore",
      "body": "Uhm..... the bnn are built assuming distribution both on th parameters( ie the value assumed by the neurons weights) and on the data (the last layer has 2 outputs : the predicted mean and the predicted variance. Those 2 values are then used to model the loss function which is the  likelihood and is a product of gaussians. I think its both model and data uncertainty. \n\n\nLet's say I compare the variances and the mean values predicted. \n\nDo I have to set the same  calibration and test dataset apart for both models or use the entire dataset? The mcmc model can use the entire dataset without the risk of overfitting but for the bnn it will be like cheating",
      "body_html": "<div class=\"md\"><p>Uhm..... the bnn are built assuming distribution both on th parameters( ie the value assumed by the neurons weights) and on the data (the last layer has 2 outputs : the predicted mean and the predicted variance. Those 2 values are then used to model the loss function which is the  likelihood and is a product of gaussians. I think its both model and data uncertainty. </p>\n\n<p>Let&#39;s say I compare the variances and the mean values predicted. </p>\n\n<p>Do I have to set the same  calibration and test dataset apart for both models or use the entire dataset? The mcmc model can use the entire dataset without the risk of overfitting but for the bnn it will be like cheating</p>\n</div>",
      "created_utc": 1678996704.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jch3vpu/",
      "parent_id": "t1_jcgzk3c",
      "depth": 4,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-16T12:58:24"
    },
    {
      "id": "jd92s7i",
      "author": "disastorm",
      "body": "Thanks I found some articles talking about these variables.",
      "body_html": "<div class=\"md\"><p>Thanks I found some articles talking about these variables.</p>\n</div>",
      "created_utc": 1679509993.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jd92s7i/",
      "parent_id": "t1_jd82eo1",
      "depth": 4,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-22T11:33:13"
    },
    {
      "id": "jdcd6xq",
      "author": "GaryS2000",
      "body": "Yeah the csv file has three columns separated into emotion, pixels, and usage. Emotion corresponds to the labels whereas usage corresponds to training/test/val, and the pixels column is made up of all of the pixel values used to make the image. It seems to produce much quicker training times than using the images, which is my main reason for wanting to use it. Training on .csv takes around 10 seconds per epoch whereas images take 10 minutes or so.  \n\n\nThey both produce the same result, a trained model which can make predictions on facial expressions, however its felt weird throughout the entire process that the model trains so quick, you know? I've been led to believe that machine learning is an extremely time intensive process but for me it hasn't took long at all, so I was wondering if there's some fundamental error with using the .csv data instead of the images. Hopefully it should be fine though, I don't see the issue myself if it produces the same result.",
      "body_html": "<div class=\"md\"><p>Yeah the csv file has three columns separated into emotion, pixels, and usage. Emotion corresponds to the labels whereas usage corresponds to training/test/val, and the pixels column is made up of all of the pixel values used to make the image. It seems to produce much quicker training times than using the images, which is my main reason for wanting to use it. Training on .csv takes around 10 seconds per epoch whereas images take 10 minutes or so.  </p>\n\n<p>They both produce the same result, a trained model which can make predictions on facial expressions, however its felt weird throughout the entire process that the model trains so quick, you know? I&#39;ve been led to believe that machine learning is an extremely time intensive process but for me it hasn&#39;t took long at all, so I was wondering if there&#39;s some fundamental error with using the .csv data instead of the images. Hopefully it should be fine though, I don&#39;t see the issue myself if it produces the same result.</p>\n</div>",
      "created_utc": 1679572598.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jdcd6xq/",
      "parent_id": "t1_jdcakhx",
      "depth": 4,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-23T04:56:38"
    },
    {
      "id": "jct6arv",
      "author": "LeN3rd",
      "body": "Ok, so all of these are linear ( logistics) regression models, for which it makes sense to have more data points, because the weights aren't as constraint as in a convolutional layer I.e. but it is still a rule of thumb, not exactly a proof.",
      "body_html": "<div class=\"md\"><p>Ok, so all of these are linear ( logistics) regression models, for which it makes sense to have more data points, because the weights aren&#39;t as constraint as in a convolutional layer I.e. but it is still a rule of thumb, not exactly a proof.</p>\n</div>",
      "created_utc": 1679224456.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jct6arv/",
      "parent_id": "t1_jcrh53z",
      "depth": 5,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-19T04:14:16"
    },
    {
      "id": "jchkhuv",
      "author": "LeN3rd",
      "body": "What you can try is to start with linear or log Regression and try to learn on Wikipedia. That might be fun and give you decent results.",
      "body_html": "<div class=\"md\"><p>What you can try is to start with linear or log Regression and try to learn on Wikipedia. That might be fun and give you decent results.</p>\n</div>",
      "created_utc": 1679003223.0,
      "score": 2,
      "ups": 2,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jchkhuv/",
      "parent_id": "t1_jchh2u9",
      "depth": 5,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-16T14:47:03"
    },
    {
      "id": "jchht71",
      "author": "LeN3rd",
      "body": "Than I would just use a completely different test dataset. In a paper I would also expect this.",
      "body_html": "<div class=\"md\"><p>Than I would just use a completely different test dataset. In a paper I would also expect this.</p>\n</div>",
      "created_utc": 1679002151.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jchht71/",
      "parent_id": "t1_jch3vpu",
      "depth": 5,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-16T14:29:11"
    },
    {
      "id": "jciyif4",
      "author": "ilrazziatore",
      "body": "Eh data are scarce, I have only this dataset ( it's composed by astrophysical measures, I cannot ask them to produce more data).",
      "body_html": "<div class=\"md\"><p>Eh data are scarce, I have only this dataset ( it&#39;s composed by astrophysical measures, I cannot ask them to produce more data).</p>\n</div>",
      "created_utc": 1679025919.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/jciyif4/",
      "parent_id": "t1_jchht71",
      "depth": 6,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-16T21:05:19"
    }
  ],
  "total_comments": 155,
  "fetched_at": "2025-09-13T20:47:12.413345"
}