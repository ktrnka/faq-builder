{
  "submission": {
    "id": "1jjzybv",
    "title": "Need Help and Feedback On mu Thesis using CNN to classify solar bursts",
    "author": "AimanDhai",
    "selftext": "\nHey r/datascience and r/MachineLearning!\n\nI'm working on my thesis and wanted to get some eyes on my Solar Burst Automation Application design. I've put together what I think is a robust framework, but would love some constructive critisism and suggestions from the community.\n\nğŸš€ Project Overview\n\nI'm developing a Flask-based application to automate solar burst classification and analysis for 2024-2025 solar data. The key goals are:\n- Automated FITS file processing\n- CNN-based solar burst classification\n- Comparative data analysis between 2024 and 2025 datasets\n\n## ğŸ“‚ Folder Structure Breakdown\n\n```\nsolar_burst_app/\nâ”œâ”€â”€ app.py                 # Main Flask application\nâ”œâ”€â”€ requirements.txt       # Python dependencies\nâ”œâ”€â”€ static/                # Static files\nâ”œâ”€â”€ templates/             # HTML templates\nâ”œâ”€â”€ data/                  # FITS file management\nâ”‚   â”œâ”€â”€ raw/\nâ”‚   â”œâ”€â”€ processed/\nâ”‚   â”œâ”€â”€ results/\nâ”‚   â””â”€â”€ uploads/\nâ”œâ”€â”€ models/                # ML models\nâ”œâ”€â”€ utils/                 # Utility functions\nâ””â”€â”€ scripts/               # Setup scripts\n```\n\nğŸ” Key Application Workflow\n1. Fetch solar burst reports\n2. Download FITS files\n3. Preprocess images\n4. Train/Use CNN model\n5. Classify solar bursts\n6. Generate visualizations\n7. Compare 2024 vs. 2025 data\n\nğŸ¤” Looking For:\n- Architectural feedback\n- Potential optimization suggestions\n- Best practices I might have missed\n- Critique of the overall design\n\nSpecific Questions:\n- Is the modular approach solid?\n- Any recommended improvements for FITS file handling?\n- Thoughts on the classification workflow?\n-I came into a hiccup where my pc cant handled the process because of hardware restrictions\n\nWould really appreciate any insights from folks who've done similar projects or have experience with scientific data processing and machine learning pipelines!\n\n",
    "selftext_html": "<!-- SC_OFF --><div class=\"md\"><p>Hey <a href=\"/r/datascience\">r/datascience</a> and <a href=\"/r/MachineLearning\">r/MachineLearning</a>!</p>\n\n<p>I&#39;m working on my thesis and wanted to get some eyes on my Solar Burst Automation Application design. I&#39;ve put together what I think is a robust framework, but would love some constructive critisism and suggestions from the community.</p>\n\n<p>ğŸš€ Project Overview</p>\n\n<p>I&#39;m developing a Flask-based application to automate solar burst classification and analysis for 2024-2025 solar data. The key goals are:\n- Automated FITS file processing\n- CNN-based solar burst classification\n- Comparative data analysis between 2024 and 2025 datasets</p>\n\n<h2>ğŸ“‚ Folder Structure Breakdown</h2>\n\n<p><code>\nsolar_burst_app/\nâ”œâ”€â”€ app.py                 # Main Flask application\nâ”œâ”€â”€ requirements.txt       # Python dependencies\nâ”œâ”€â”€ static/                # Static files\nâ”œâ”€â”€ templates/             # HTML templates\nâ”œâ”€â”€ data/                  # FITS file management\nâ”‚   â”œâ”€â”€ raw/\nâ”‚   â”œâ”€â”€ processed/\nâ”‚   â”œâ”€â”€ results/\nâ”‚   â””â”€â”€ uploads/\nâ”œâ”€â”€ models/                # ML models\nâ”œâ”€â”€ utils/                 # Utility functions\nâ””â”€â”€ scripts/               # Setup scripts\n</code></p>\n\n<p>ğŸ” Key Application Workflow\n1. Fetch solar burst reports\n2. Download FITS files\n3. Preprocess images\n4. Train/Use CNN model\n5. Classify solar bursts\n6. Generate visualizations\n7. Compare 2024 vs. 2025 data</p>\n\n<p>ğŸ¤” Looking For:\n- Architectural feedback\n- Potential optimization suggestions\n- Best practices I might have missed\n- Critique of the overall design</p>\n\n<p>Specific Questions:\n- Is the modular approach solid?\n- Any recommended improvements for FITS file handling?\n- Thoughts on the classification workflow?\n-I came into a hiccup where my pc cant handled the process because of hardware restrictions</p>\n\n<p>Would really appreciate any insights from folks who&#39;ve done similar projects or have experience with scientific data processing and machine learning pipelines!</p>\n</div><!-- SC_ON -->",
    "url": "https://www.reddit.com/r/MLQuestions/comments/1jjzybv/need_help_and_feedback_on_mu_thesis_using_cnn_to/",
    "permalink": "/r/MLQuestions/comments/1jjzybv/need_help_and_feedback_on_mu_thesis_using_cnn_to/",
    "subreddit": "MLQuestions",
    "created_utc": 1742951550.0,
    "score": 1,
    "ups": 1,
    "downs": 0,
    "upvote_ratio": 1.0,
    "num_comments": 2,
    "is_self": true,
    "over_18": false,
    "spoiler": false,
    "stickied": false,
    "locked": false,
    "archived": false,
    "distinguished": null,
    "link_flair_text": "Physics-Informed Neural Networks ğŸš€",
    "timestamp": "2025-03-25T18:12:30"
  },
  "comments": [
    {
      "id": "mjur2po",
      "author": "trnka",
      "body": "Hosting a web app online can be a lot of work. If the source data doesn't change often, I'd suggest making a Github Action or cronjob to download new images once per day and update static html/css pages with any output.\n\nAlso, if you're intending to store the images and model in the repo, that will be too big for git itself. [DVC ](https://dvc.org/)is a good option if you're willing to pay a little for S3 storage or another similar storage provider. Alternatively, git-lfs can work but github's LFS option will periodically run out of space and ask for more money.\n\nPersonally I prefer \\`uv\\` and \\`pyproject.toml\\` over \\`requirements.txt\\` because 1) it reduces the chance of accidentally installing requirements into your base Python and 2) it allows you to specify the required version of Python.",
      "body_html": "<div class=\"md\"><p>Hosting a web app online can be a lot of work. If the source data doesn&#39;t change often, I&#39;d suggest making a Github Action or cronjob to download new images once per day and update static html/css pages with any output.</p>\n\n<p>Also, if you&#39;re intending to store the images and model in the repo, that will be too big for git itself. <a href=\"https://dvc.org/\">DVC </a>is a good option if you&#39;re willing to pay a little for S3 storage or another similar storage provider. Alternatively, git-lfs can work but github&#39;s LFS option will periodically run out of space and ask for more money.</p>\n\n<p>Personally I prefer `uv` and `pyproject.toml` over `requirements.txt` because 1) it reduces the chance of accidentally installing requirements into your base Python and 2) it allows you to specify the required version of Python.</p>\n</div>",
      "created_utc": 1743005312.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MLQuestions/comments/1jjzybv/need_help_and_feedback_on_mu_thesis_using_cnn_to/mjur2po/",
      "parent_id": "t3_1jjzybv",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2025-03-26T09:08:32"
    },
    {
      "id": "mk44dul",
      "author": "AimanDhai",
      "body": "how about i just use one type of observeratory. Since, I think it would take a long time and storage i probably start for one observaratory centre. Thanks For the advice. Any further suggestions?",
      "body_html": "<div class=\"md\"><p>how about i just use one type of observeratory. Since, I think it would take a long time and storage i probably start for one observaratory centre. Thanks For the advice. Any further suggestions?</p>\n</div>",
      "created_utc": 1743126292.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MLQuestions/comments/1jjzybv/need_help_and_feedback_on_mu_thesis_using_cnn_to/mk44dul/",
      "parent_id": "t1_mjur2po",
      "depth": 1,
      "is_submitter": true,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2025-03-27T18:44:52"
    }
  ],
  "total_comments": 2,
  "fetched_at": "2025-09-13T20:47:36.969099"
}