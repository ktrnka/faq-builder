{
  "submission": {
    "id": "10oazg7",
    "title": "[D] Simple Questions Thread",
    "author": "AutoModerator",
    "selftext": "Please post your questions here instead of creating a new thread. Encourage others who create new posts for questions to post here instead!\n\nThread will stay alive until next one so keep posting after the date in the title.\n\nThanks to everyone for answering questions in the previous thread!",
    "selftext_html": "<!-- SC_OFF --><div class=\"md\"><p>Please post your questions here instead of creating a new thread. Encourage others who create new posts for questions to post here instead!</p>\n\n<p>Thread will stay alive until next one so keep posting after the date in the title.</p>\n\n<p>Thanks to everyone for answering questions in the previous thread!</p>\n</div><!-- SC_ON -->",
    "url": "https://www.reddit.com/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/",
    "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/",
    "subreddit": "MachineLearning",
    "created_utc": 1675008007.0,
    "score": 12,
    "ups": 12,
    "downs": 0,
    "upvote_ratio": 0.93,
    "num_comments": 129,
    "is_self": true,
    "over_18": false,
    "spoiler": false,
    "stickied": false,
    "locked": false,
    "archived": false,
    "distinguished": null,
    "link_flair_text": "Discussion",
    "timestamp": "2023-01-29T08:00:07"
  },
  "comments": [
    {
      "id": "j6l062p",
      "author": null,
      "body": "[deleted]",
      "body_html": "<div class=\"md\"><p>[deleted]</p>\n</div>",
      "created_utc": 1675129813.0,
      "score": 3,
      "ups": 3,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j6l062p/",
      "parent_id": "t3_10oazg7",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-01-30T17:50:13"
    },
    {
      "id": "j6i36hx",
      "author": "grenouillefolle",
      "body": "I have a (seemingly) simple question concerning systematic studies for classification problems. Is there any literature (books, papers) describing an approach for systematic studies on classifiers, such as varying the size of the training sample, number of input variables, size of the correlation between input variables and classes on simulated data, type of classifier, configuration of parameters of the algorithm etc.?\n\nThe goal is to prove the robustness and limitations of the method before training on real data.  While I have a good feeling of what can and should be done, I want to point a beginner in the right direction for a project without doing all the hard work myself.",
      "body_html": "<div class=\"md\"><p>I have a (seemingly) simple question concerning systematic studies for classification problems. Is there any literature (books, papers) describing an approach for systematic studies on classifiers, such as varying the size of the training sample, number of input variables, size of the correlation between input variables and classes on simulated data, type of classifier, configuration of parameters of the algorithm etc.?</p>\n\n<p>The goal is to prove the robustness and limitations of the method before training on real data.  While I have a good feeling of what can and should be done, I want to point a beginner in the right direction for a project without doing all the hard work myself.</p>\n</div>",
      "created_utc": 1675088435.0,
      "score": 2,
      "ups": 2,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j6i36hx/",
      "parent_id": "t3_10oazg7",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-01-30T06:20:35"
    },
    {
      "id": "j6wtm96",
      "author": "krazyking",
      "body": "hi everyone, its a great day. I am trying to train a model which uses multiple datasets and to give an example would be most helpful. Lets say I want it to predict Basketball player performance. So I have all the player stats in the data set, but I want to incorporate the strength of the player matchup, so I would need a separate table for the opposing teams metrics vs certain positions. How do I do that? Is this only accomplished via feature engineering?\n\nany help is appreciated, thank you  \n\n\ntl;dr if i have a data table that is a subset of the main data how do I incorporate that?",
      "body_html": "<div class=\"md\"><p>hi everyone, its a great day. I am trying to train a model which uses multiple datasets and to give an example would be most helpful. Lets say I want it to predict Basketball player performance. So I have all the player stats in the data set, but I want to incorporate the strength of the player matchup, so I would need a separate table for the opposing teams metrics vs certain positions. How do I do that? Is this only accomplished via feature engineering?</p>\n\n<p>any help is appreciated, thank you  </p>\n\n<p>tl;dr if i have a data table that is a subset of the main data how do I incorporate that?</p>\n</div>",
      "created_utc": 1675344676.0,
      "score": 2,
      "ups": 2,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j6wtm96/",
      "parent_id": "t3_10oazg7",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-02T05:31:16"
    },
    {
      "id": "j7crqhu",
      "author": "Translate_pro",
      "body": "Newer to DS/ml work and am looking for some direction. \n\n\nI'm trying to estimate the impact of an event upon a customer satisfaction metric, for both the general population and specific segments.  The event is assumed to have heterogeneous effects due to the nature of the customer base (impacted customers in some regions more than others) and was not part of an experimental study.\n\nI've tried:\nUsing Arima time series modeling based upon the metric, fitting on the time period prior to the event, predicting after the event, and comparing the predicted values to the actual ones. However, Arima doesn't appear to be appropriate. After talking to my product team, there appears to be monthly seasonality, as well as seasonality related to the day of the week.\nSince the customer satisfaction metric is an aggregation from scores provided by individuals, I've also tried using individual scores pre-event as training and using individual scores given post-event as test, fitting traditional classification models to the training set and making predictions on the test set. To estimate the difference between the expected versus actual customer metric, I've taken the training scores and predicted test scores and calculated the aggregated metric for those records as the expected aggregate value and separately calculated the aggregated metric over the training scores and actual test values for the actual aggregate value. However, this method gives me a larger than actual estimated impact - regardless of whether or not I balance the classes during training, this modeling approach tends to predict one customer rating more frequently than the others.\n\nI've also done some reading into causality libraries/modeling approaches, like econml DML, but I'm not sure how helpful CATE would be here, since my metric of interest is an aggregation. Any suggestions?",
      "body_html": "<div class=\"md\"><p>Newer to DS/ml work and am looking for some direction. </p>\n\n<p>I&#39;m trying to estimate the impact of an event upon a customer satisfaction metric, for both the general population and specific segments.  The event is assumed to have heterogeneous effects due to the nature of the customer base (impacted customers in some regions more than others) and was not part of an experimental study.</p>\n\n<p>I&#39;ve tried:\nUsing Arima time series modeling based upon the metric, fitting on the time period prior to the event, predicting after the event, and comparing the predicted values to the actual ones. However, Arima doesn&#39;t appear to be appropriate. After talking to my product team, there appears to be monthly seasonality, as well as seasonality related to the day of the week.\nSince the customer satisfaction metric is an aggregation from scores provided by individuals, I&#39;ve also tried using individual scores pre-event as training and using individual scores given post-event as test, fitting traditional classification models to the training set and making predictions on the test set. To estimate the difference between the expected versus actual customer metric, I&#39;ve taken the training scores and predicted test scores and calculated the aggregated metric for those records as the expected aggregate value and separately calculated the aggregated metric over the training scores and actual test values for the actual aggregate value. However, this method gives me a larger than actual estimated impact - regardless of whether or not I balance the classes during training, this modeling approach tends to predict one customer rating more frequently than the others.</p>\n\n<p>I&#39;ve also done some reading into causality libraries/modeling approaches, like econml DML, but I&#39;m not sure how helpful CATE would be here, since my metric of interest is an aggregation. Any suggestions?</p>\n</div>",
      "created_utc": 1675630693.0,
      "score": 2,
      "ups": 2,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j7crqhu/",
      "parent_id": "t3_10oazg7",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": true,
      "distinguished": null,
      "timestamp": "2023-02-05T12:58:13"
    },
    {
      "id": "j7cw91s",
      "author": "kerkerdunger",
      "body": "Hello people! \n\nI am currently a CS student, trying to get some practical ml experience.\n\nI've gotten into a project that concerns image classification (i.e. classifying cells, finding differences between pictures, ...).\n\nThe requirement is to do it in kotlin (Java). Previously, I have read fast.ai would be good for it, including their course to implement it, but it runs with python as far as I have seen.\n\nCan somebody help me get started and nudge me in the right direction?\n\nWould be greatly appreciated! Many thanks in advance.",
      "body_html": "<div class=\"md\"><p>Hello people! </p>\n\n<p>I am currently a CS student, trying to get some practical ml experience.</p>\n\n<p>I&#39;ve gotten into a project that concerns image classification (i.e. classifying cells, finding differences between pictures, ...).</p>\n\n<p>The requirement is to do it in kotlin (Java). Previously, I have read fast.ai would be good for it, including their course to implement it, but it runs with python as far as I have seen.</p>\n\n<p>Can somebody help me get started and nudge me in the right direction?</p>\n\n<p>Would be greatly appreciated! Many thanks in advance.</p>\n</div>",
      "created_utc": 1675632534.0,
      "score": 2,
      "ups": 2,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j7cw91s/",
      "parent_id": "t3_10oazg7",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-05T13:28:54"
    },
    {
      "id": "j7cyarn",
      "author": "Emergency-North-6927",
      "body": "Hi all! I'm an undergraduate student in CS, and I intend on following a career working with AI/ML. In my university, I have the option to choose specific CS â€œtracks\" to follow. I am obviously taking classes for the Machine Intelligence track, but I'm seeking opinions on which second track would be beneficial: Computer Graphics, Systems Software, or Database and Information Systems (or none, if it doesn't really matter). I am curious as to which of these could be beneficial for an Al masters program, or just in general. If there are any people working with ML research here, I'd like to hear your opinions about it. Thank you in advance!",
      "body_html": "<div class=\"md\"><p>Hi all! I&#39;m an undergraduate student in CS, and I intend on following a career working with AI/ML. In my university, I have the option to choose specific CS â€œtracks&quot; to follow. I am obviously taking classes for the Machine Intelligence track, but I&#39;m seeking opinions on which second track would be beneficial: Computer Graphics, Systems Software, or Database and Information Systems (or none, if it doesn&#39;t really matter). I am curious as to which of these could be beneficial for an Al masters program, or just in general. If there are any people working with ML research here, I&#39;d like to hear your opinions about it. Thank you in advance!</p>\n</div>",
      "created_utc": 1675633386.0,
      "score": 2,
      "ups": 2,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j7cyarn/",
      "parent_id": "t3_10oazg7",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-05T13:43:06"
    },
    {
      "id": "j7ks0qo",
      "author": null,
      "body": "[deleted]",
      "body_html": "<div class=\"md\"><p>[deleted]</p>\n</div>",
      "created_utc": 1675781571.0,
      "score": 2,
      "ups": 2,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j7ks0qo/",
      "parent_id": "t3_10oazg7",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-07T06:52:51"
    },
    {
      "id": "j7s2o5f",
      "author": "teduck1",
      "body": "I am trying to configure a workstation. I planned to go for an AMD CPU, but I have been told that libraries such as numpy and Pytorch use MKL backend which makes computation much faster with Intel CPUs.\n\nWill this matter in practice, since model training will be done on the GPU?",
      "body_html": "<div class=\"md\"><p>I am trying to configure a workstation. I planned to go for an AMD CPU, but I have been told that libraries such as numpy and Pytorch use MKL backend which makes computation much faster with Intel CPUs.</p>\n\n<p>Will this matter in practice, since model training will be done on the GPU?</p>\n</div>",
      "created_utc": 1675902127.0,
      "score": 2,
      "ups": 2,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j7s2o5f/",
      "parent_id": "t3_10oazg7",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-08T16:22:07"
    },
    {
      "id": "j7v7sxg",
      "author": "throweralal",
      "body": "If I have thousands of hours of content (which can be transcribed) along with numerous articles. Is there a third-party API/tool that would essentially allow me to ask questions about that content and give me a short and sweet answer along with a list of the sources which might have more information pertaining to the topic?",
      "body_html": "<div class=\"md\"><p>If I have thousands of hours of content (which can be transcribed) along with numerous articles. Is there a third-party API/tool that would essentially allow me to ask questions about that content and give me a short and sweet answer along with a list of the sources which might have more information pertaining to the topic?</p>\n</div>",
      "created_utc": 1675963491.0,
      "score": 2,
      "ups": 2,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j7v7sxg/",
      "parent_id": "t3_10oazg7",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-09T09:24:51"
    },
    {
      "id": "j7wbepy",
      "author": "NoNipsPlease",
      "body": "For the purposes of machine learning, what workstation class cards are recommended? What single GPU configuration would be the most powerful?\n\nIs the nvidia RTX 6000 ADA the current top performer? I am currently using a Titan RTX and the 24 GB memory is limiting for some use cases. \n\nI am definitely interested in the more workstation class of cards. I'm concerned about longevity if I use a consumer card.",
      "body_html": "<div class=\"md\"><p>For the purposes of machine learning, what workstation class cards are recommended? What single GPU configuration would be the most powerful?</p>\n\n<p>Is the nvidia RTX 6000 ADA the current top performer? I am currently using a Titan RTX and the 24 GB memory is limiting for some use cases. </p>\n\n<p>I am definitely interested in the more workstation class of cards. I&#39;m concerned about longevity if I use a consumer card.</p>\n</div>",
      "created_utc": 1675978067.0,
      "score": 2,
      "ups": 2,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j7wbepy/",
      "parent_id": "t3_10oazg7",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-09T13:27:47"
    },
    {
      "id": "j6diy8w",
      "author": "RogerKrowiak",
      "body": "I have a very basic question. If I have two columns of data:  \n\n\n\"Students\": \\[\"John\", \"John\", \"Roger\", \"Eve\", \"John\"\\]  \n\"Sex\": \\[\"M\", \"M\", \"M\", \"F\", \"M\"\\]  \n\n\ncan I use different encoding for each column? E.g. frequency encoding for students and binary for sex?Thank you for your answer. If you have tip for basic readings on this, it would be appreciated.",
      "body_html": "<div class=\"md\"><p>I have a very basic question. If I have two columns of data:  </p>\n\n<p>&quot;Students&quot;: [&quot;John&quot;, &quot;John&quot;, &quot;Roger&quot;, &quot;Eve&quot;, &quot;John&quot;]<br/>\n&quot;Sex&quot;: [&quot;M&quot;, &quot;M&quot;, &quot;M&quot;, &quot;F&quot;, &quot;M&quot;]  </p>\n\n<p>can I use different encoding for each column? E.g. frequency encoding for students and binary for sex?Thank you for your answer. If you have tip for basic readings on this, it would be appreciated.</p>\n</div>",
      "created_utc": 1675008779.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j6diy8w/",
      "parent_id": "t3_10oazg7",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-01-29T08:12:59"
    },
    {
      "id": "j6hj3ic",
      "author": "tectoniteshade",
      "body": "While the amount and sophistication of AI tools has taken a sharp upward turn, there's one particular type of tool I tried to find but failed: one that would change the facial expression in a photograph or other still image. I found some toy-like phone apps with very limited sets. The best more professional tool I was able to find was Photoshop's neural filters. They were introduced already a couple of years ago, so one would think more advanced specialized tools for this purpose would exist already. Are there such tools? Did my google-fu just fail?",
      "body_html": "<div class=\"md\"><p>While the amount and sophistication of AI tools has taken a sharp upward turn, there&#39;s one particular type of tool I tried to find but failed: one that would change the facial expression in a photograph or other still image. I found some toy-like phone apps with very limited sets. The best more professional tool I was able to find was Photoshop&#39;s neural filters. They were introduced already a couple of years ago, so one would think more advanced specialized tools for this purpose would exist already. Are there such tools? Did my google-fu just fail?</p>\n</div>",
      "created_utc": 1675076391.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j6hj3ic/",
      "parent_id": "t3_10oazg7",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-01-30T02:59:51"
    },
    {
      "id": "j6ibwq0",
      "author": null,
      "body": "I am trying to create a GAN with RNNs. Therefore I'm trying to create stacked GRU-Cells which get fed the random input. I implemented it as follows:  \n\n\n    def build_generator():\n        inputs = keras.Input(shape=[LATENT_SHAPE])\n        cell = keras.layers.StackedRNNCells([keras.layers.GRUCell(64, activation = 'tanh') for _ in range(7)])\n        rnn = keras.layers.RNN(cell, return_sequences=True)\n        x = rnn(inputs)\n        return keras.models.Model(inputs, x)\n\nHowever everytime I try to call the method, I do get the following error:\n\n[Error](https://imgur.com/Vwt0T39)\n\nI have found basically the same implementation for StackedRNNCells in the second to newest push from [TimeGAN](https://github.com/jsyoon0823/TimeGAN/blob/master/timegan.py). Yet for me I get the error, I don't know how to fix.",
      "body_html": "<div class=\"md\"><p>I am trying to create a GAN with RNNs. Therefore I&#39;m trying to create stacked GRU-Cells which get fed the random input. I implemented it as follows:  </p>\n\n<pre><code>def build_generator():\n    inputs = keras.Input(shape=[LATENT_SHAPE])\n    cell = keras.layers.StackedRNNCells([keras.layers.GRUCell(64, activation = &#39;tanh&#39;) for _ in range(7)])\n    rnn = keras.layers.RNN(cell, return_sequences=True)\n    x = rnn(inputs)\n    return keras.models.Model(inputs, x)\n</code></pre>\n\n<p>However everytime I try to call the method, I do get the following error:</p>\n\n<p><a href=\"https://imgur.com/Vwt0T39\">Error</a></p>\n\n<p>I have found basically the same implementation for StackedRNNCells in the second to newest push from <a href=\"https://github.com/jsyoon0823/TimeGAN/blob/master/timegan.py\">TimeGAN</a>. Yet for me I get the error, I don&#39;t know how to fix.</p>\n</div>",
      "created_utc": 1675092195.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j6ibwq0/",
      "parent_id": "t3_10oazg7",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-01-30T07:23:15"
    },
    {
      "id": "j6iv8g8",
      "author": "8-Bit_Soul",
      "body": "Ball park conceptual number - how long does training take for AI tasks using medical volumetric data? (for example, something along the lines of training for automated segmentation of an organ using 100 CT studies). Are we talking hours? Days? Weeks? \n\nI'm new to ML and I will need a better GPU (and a PSU and maybe a bigger case), and the amount I would be willing to invest depends on how much of a difference it would make in practice.  I figure I can get a used RTX 3090 installed for about $1000 or a new RTX 4090 for about $2000, and if training correlates with AI benchmarks, then it looks like a task that takes 1 day for an A100 GPU would take 1.1 days with an RTX 4090 and 1.7 days with an RTX 3090. If the extra $1k reduces the time by weeks or days, then it should eventually be worth the cost. If it reduces the time by hours or minutes, then it's probably not worth the cost.\n\nThanks!",
      "body_html": "<div class=\"md\"><p>Ball park conceptual number - how long does training take for AI tasks using medical volumetric data? (for example, something along the lines of training for automated segmentation of an organ using 100 CT studies). Are we talking hours? Days? Weeks? </p>\n\n<p>I&#39;m new to ML and I will need a better GPU (and a PSU and maybe a bigger case), and the amount I would be willing to invest depends on how much of a difference it would make in practice.  I figure I can get a used RTX 3090 installed for about $1000 or a new RTX 4090 for about $2000, and if training correlates with AI benchmarks, then it looks like a task that takes 1 day for an A100 GPU would take 1.1 days with an RTX 4090 and 1.7 days with an RTX 3090. If the extra $1k reduces the time by weeks or days, then it should eventually be worth the cost. If it reduces the time by hours or minutes, then it&#39;s probably not worth the cost.</p>\n\n<p>Thanks!</p>\n</div>",
      "created_utc": 1675099680.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j6iv8g8/",
      "parent_id": "t3_10oazg7",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-01-30T09:28:00"
    },
    {
      "id": "j6jjb43",
      "author": "TheCoconutTree",
      "body": "Discrete features as training data:\n\nSay I am using SQL table rows as training data input for a deep neural net classifier. One of the columns contains a number from 1-5 representing a discrete value, say type of computer connection. It could be wifi, mobile-data, LAN, etc. What would be the best way to represent as input features? Right now I'm thinking split into a five dimensional vector, one for each possible value. Then pass 0 or 1 depending on whether a given feature is selected. I'm worried that including the range of values as a single vector would lead to messed up learning since one discrete value doesn't have any meaningful closeness to it's nearest discrete neighbor.",
      "body_html": "<div class=\"md\"><p>Discrete features as training data:</p>\n\n<p>Say I am using SQL table rows as training data input for a deep neural net classifier. One of the columns contains a number from 1-5 representing a discrete value, say type of computer connection. It could be wifi, mobile-data, LAN, etc. What would be the best way to represent as input features? Right now I&#39;m thinking split into a five dimensional vector, one for each possible value. Then pass 0 or 1 depending on whether a given feature is selected. I&#39;m worried that including the range of values as a single vector would lead to messed up learning since one discrete value doesn&#39;t have any meaningful closeness to it&#39;s nearest discrete neighbor.</p>\n</div>",
      "created_utc": 1675108622.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j6jjb43/",
      "parent_id": "t3_10oazg7",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-01-30T11:57:02"
    },
    {
      "id": "j6lu39i",
      "author": "TheCoconutTree",
      "body": "Formatting lat/lng data for neural net feature input:\n\nI've got latitude/longitude columns in a sql table that I'd like to add as features for a neural net classifier model. In terms of formatting for input, I plan to normalize latitude values to a range between 0-1, with 0 mapping to the largest possible negative lat value, and 1 mapping to the largest possible positive lat value. Then do the same for longitude, and pass them in as separate features.\n\nDoes that seem like a reasonable approach? Any other tricks I should know?",
      "body_html": "<div class=\"md\"><p>Formatting lat/lng data for neural net feature input:</p>\n\n<p>I&#39;ve got latitude/longitude columns in a sql table that I&#39;d like to add as features for a neural net classifier model. In terms of formatting for input, I plan to normalize latitude values to a range between 0-1, with 0 mapping to the largest possible negative lat value, and 1 mapping to the largest possible positive lat value. Then do the same for longitude, and pass them in as separate features.</p>\n\n<p>Does that seem like a reasonable approach? Any other tricks I should know?</p>\n</div>",
      "created_utc": 1675145130.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j6lu39i/",
      "parent_id": "t3_10oazg7",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-01-30T22:05:30"
    },
    {
      "id": "j6o0srj",
      "author": "worriedshuffle",
      "body": "GPTZero claims to measure the perplexity of a sample of text. Am I missing something or is that a complete scam? You canâ€™t measure perplexity without access to the model logits, which arenâ€™t available for GPT-3.\n\nYou could guess what the logits would be by gathering text samples but thereâ€™s no way a pet project could gather enough data to accurately estimate conditional probabilities.",
      "body_html": "<div class=\"md\"><p>GPTZero claims to measure the perplexity of a sample of text. Am I missing something or is that a complete scam? You canâ€™t measure perplexity without access to the model logits, which arenâ€™t available for GPT-3.</p>\n\n<p>You could guess what the logits would be by gathering text samples but thereâ€™s no way a pet project could gather enough data to accurately estimate conditional probabilities.</p>\n</div>",
      "created_utc": 1675188631.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j6o0srj/",
      "parent_id": "t3_10oazg7",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-01-31T10:10:31"
    },
    {
      "id": "j6og5xa",
      "author": "Flogirll",
      "body": "Can you adjust gantry length in a claw machine?\n\nIâ€™m sorry if this is dumb but I canâ€™t seem to find this anywhere. I know absolutely nothing about the parts inside a claw machine other than the names. \nI have a cabinet but I am unable to find a gantry the exact size. Do I need a new cabinet or can something be done?\nThanks!",
      "body_html": "<div class=\"md\"><p>Can you adjust gantry length in a claw machine?</p>\n\n<p>Iâ€™m sorry if this is dumb but I canâ€™t seem to find this anywhere. I know absolutely nothing about the parts inside a claw machine other than the names. \nI have a cabinet but I am unable to find a gantry the exact size. Do I need a new cabinet or can something be done?\nThanks!</p>\n</div>",
      "created_utc": 1675194309.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j6og5xa/",
      "parent_id": "t3_10oazg7",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-01-31T11:45:09"
    },
    {
      "id": "j6onxem",
      "author": "ockham_blade",
      "body": "Hi! I am working on a clustering project on a dataset that has some numerical variables, and one categorical variable with very high cardinality (\\~150 values). I was thinking if it is possible to create an embedding for that feature, after one-hot encoding (ohe) it. I was initially thinking of running an autoencoder on the 150 dummy features that result from the ohe, but then I thought that it may not make sense as they are all uncorrelated (mutually exclusive). What do you think about this?  \nOn the same line, I think that applying PCA is likely wrong. What would you suggest to find a latent representation of that variable? One other idea was: use the 15p dummy ohe columns to train a NN for some classification task, including an embedding layer, and then use that layer as low-dimensional representation... does it make any sense? Thank you in advance!",
      "body_html": "<div class=\"md\"><p>Hi! I am working on a clustering project on a dataset that has some numerical variables, and one categorical variable with very high cardinality (~150 values). I was thinking if it is possible to create an embedding for that feature, after one-hot encoding (ohe) it. I was initially thinking of running an autoencoder on the 150 dummy features that result from the ohe, but then I thought that it may not make sense as they are all uncorrelated (mutually exclusive). What do you think about this?<br/>\nOn the same line, I think that applying PCA is likely wrong. What would you suggest to find a latent representation of that variable? One other idea was: use the 15p dummy ohe columns to train a NN for some classification task, including an embedding layer, and then use that layer as low-dimensional representation... does it make any sense? Thank you in advance!</p>\n</div>",
      "created_utc": 1675197185.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j6onxem/",
      "parent_id": "t3_10oazg7",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-01-31T12:33:05"
    },
    {
      "id": "j6qr0qm",
      "author": null,
      "body": "[deleted]",
      "body_html": "<div class=\"md\"><p>[deleted]</p>\n</div>",
      "created_utc": 1675229747.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j6qr0qm/",
      "parent_id": "t3_10oazg7",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-01-31T21:35:47"
    },
    {
      "id": "j6rnbec",
      "author": "EquivocalDephimist",
      "body": "please suggest a keras/tf2 object detection implementation that I could train on my custom datasets",
      "body_html": "<div class=\"md\"><p>please suggest a keras/tf2 object detection implementation that I could train on my custom datasets</p>\n</div>",
      "created_utc": 1675254223.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j6rnbec/",
      "parent_id": "t3_10oazg7",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-01T04:23:43"
    },
    {
      "id": "j6rr531",
      "author": "Ok_Refrigerator5148",
      "body": "Researching most common issues and bottlenecks when it comes to training data, from inconsistent or biased sets to insufficient volume. What's been your experience so far? What has been the longest time spent doing EDA for a project?",
      "body_html": "<div class=\"md\"><p>Researching most common issues and bottlenecks when it comes to training data, from inconsistent or biased sets to insufficient volume. What&#39;s been your experience so far? What has been the longest time spent doing EDA for a project?</p>\n</div>",
      "created_utc": 1675256441.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j6rr531/",
      "parent_id": "t3_10oazg7",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-01T05:00:41"
    },
    {
      "id": "j6snpe3",
      "author": null,
      "body": "Help me. Do I want to become a machine learning engineer?",
      "body_html": "<div class=\"md\"><p>Help me. Do I want to become a machine learning engineer?</p>\n</div>",
      "created_utc": 1675270092.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j6snpe3/",
      "parent_id": "t3_10oazg7",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-01T08:48:12"
    },
    {
      "id": "j6snyau",
      "author": "Oripy",
      "body": "Hello,  \nI'm working on a card game AI using reinforcement learning.   \nThe input is the game state and I have 2 types of output, one is a sort of evaluation of the opponent's strategy (it is more complex than that but it is in the realm of is it going for the \"loose all trick\" strategy or \"win as much trick as possible\" strategy) (= value network?). The other output is: \"what card should I play next\" (= policy network?).  \nShould I train two different networks (policy/value) or have the same network output both?",
      "body_html": "<div class=\"md\"><p>Hello,<br/>\nI&#39;m working on a card game AI using reinforcement learning.<br/>\nThe input is the game state and I have 2 types of output, one is a sort of evaluation of the opponent&#39;s strategy (it is more complex than that but it is in the realm of is it going for the &quot;loose all trick&quot; strategy or &quot;win as much trick as possible&quot; strategy) (= value network?). The other output is: &quot;what card should I play next&quot; (= policy network?).<br/>\nShould I train two different networks (policy/value) or have the same network output both?</p>\n</div>",
      "created_utc": 1675270184.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j6snyau/",
      "parent_id": "t3_10oazg7",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-01T08:49:44"
    },
    {
      "id": "j6td3yy",
      "author": null,
      "body": "[deleted]",
      "body_html": "<div class=\"md\"><p>[deleted]</p>\n</div>",
      "created_utc": 1675279393.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j6td3yy/",
      "parent_id": "t3_10oazg7",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-01T11:23:13"
    },
    {
      "id": "j6w1eku",
      "author": "CloroxBleach019",
      "body": "Hello guys,\r  \n\r  \nI'm thinking of testing out this machine learning project, and I need to know how feasible it is.\r  \n\r  \nThe goal of the model is to take a source image that contains math calculations in handwriting, and then transfer the handwriting so that it matches a target style. Here is a sample [image](https://imgur.com/evbkM9S), there will be around 50-100 of these for both source and target datasets.\r  \n\r  \nThe math will contain symbols and matrices from linear algebra. Note that the source and target training images are somewhat unpaired, as the solutions for each question may be worked out differently.\r  \n\r  \nFor reference, I have machine learning experience in 2 unsupervised domain adaptation papers, including CNN and GAN experience. I found some previous works on this topic, but they all seem to either be handwriting -> text or text -> handwriting. Perhaps I should combine the two, with a pipeline like this? source handwriting -> latex equations -> target handwriting. Is this too complex? Or can I simply throw the source image into a feature extractor and use GAN to generate the target image?\r  \n\r  \nBefore I commit too much time on this, I need to know how feasible it is. Will it actually work? And how good are the results going to be? If I have to manually fix errors everywhere it might end up being more work.",
      "body_html": "<div class=\"md\"><p>Hello guys,</p>\n\n<p>I&#39;m thinking of testing out this machine learning project, and I need to know how feasible it is.</p>\n\n<p>The goal of the model is to take a source image that contains math calculations in handwriting, and then transfer the handwriting so that it matches a target style. Here is a sample <a href=\"https://imgur.com/evbkM9S\">image</a>, there will be around 50-100 of these for both source and target datasets.</p>\n\n<p>The math will contain symbols and matrices from linear algebra. Note that the source and target training images are somewhat unpaired, as the solutions for each question may be worked out differently.</p>\n\n<p>For reference, I have machine learning experience in 2 unsupervised domain adaptation papers, including CNN and GAN experience. I found some previous works on this topic, but they all seem to either be handwriting -&gt; text or text -&gt; handwriting. Perhaps I should combine the two, with a pipeline like this? source handwriting -&gt; latex equations -&gt; target handwriting. Is this too complex? Or can I simply throw the source image into a feature extractor and use GAN to generate the target image?</p>\n\n<p>Before I commit too much time on this, I need to know how feasible it is. Will it actually work? And how good are the results going to be? If I have to manually fix errors everywhere it might end up being more work.</p>\n</div>",
      "created_utc": 1675323785.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j6w1eku/",
      "parent_id": "t3_10oazg7",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-01T23:43:05"
    },
    {
      "id": "j6wf66h",
      "author": "imperator_rex_za",
      "body": "Hello everyone,\n\nQuick question - I have a trained image classifier I built from years back in PyTorch for a simple specific task, but I now want to use that classifier in some sort of Object Detection model.\n\nIâ€™ve looked at R-CNN, SSD, etc but Iâ€™m not sure which to choose and if itâ€™s even possible to plug my classifier in as backbone to those. Ideally I donâ€™t want to build an enitre one from scratch.\n\nThanks",
      "body_html": "<div class=\"md\"><p>Hello everyone,</p>\n\n<p>Quick question - I have a trained image classifier I built from years back in PyTorch for a simple specific task, but I now want to use that classifier in some sort of Object Detection model.</p>\n\n<p>Iâ€™ve looked at R-CNN, SSD, etc but Iâ€™m not sure which to choose and if itâ€™s even possible to plug my classifier in as backbone to those. Ideally I donâ€™t want to build an enitre one from scratch.</p>\n\n<p>Thanks</p>\n</div>",
      "created_utc": 1675335484.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j6wf66h/",
      "parent_id": "t3_10oazg7",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-02T02:58:04"
    },
    {
      "id": "j6wikpz",
      "author": "Oripy",
      "body": "I have a question related to the Actor Critic method described in the keras example here: [https://keras.io/examples/rl/actor\\_critic\\_cartpole/](https://keras.io/examples/rl/actor_critic_cartpole/)\n\nI looked at the code for the Train part, and I think I understand what all lines are supposed to do and why they are there. However, I don't think I understand what role the critic plays in the improvement of the agent. To me this critic is just a value that predicts the future reward, but I don't see this being fed back into the system for the agent to make a better action to improve its reward.\n\nDo I have a good understanding? Is the critic just a \"bonus\" output? Are the two unrelated and the exact same performance could be achieved by removing the Critic output altogether? Or is the critic output used in any way to improve learning rate in a way I fail to see?\n\n&#x200B;\n\nThank you.",
      "body_html": "<div class=\"md\"><p>I have a question related to the Actor Critic method described in the keras example here: <a href=\"https://keras.io/examples/rl/actor_critic_cartpole/\">https://keras.io/examples/rl/actor_critic_cartpole/</a></p>\n\n<p>I looked at the code for the Train part, and I think I understand what all lines are supposed to do and why they are there. However, I don&#39;t think I understand what role the critic plays in the improvement of the agent. To me this critic is just a value that predicts the future reward, but I don&#39;t see this being fed back into the system for the agent to make a better action to improve its reward.</p>\n\n<p>Do I have a good understanding? Is the critic just a &quot;bonus&quot; output? Are the two unrelated and the exact same performance could be achieved by removing the Critic output altogether? Or is the critic output used in any way to improve learning rate in a way I fail to see?</p>\n\n<p>&#x200B;</p>\n\n<p>Thank you.</p>\n</div>",
      "created_utc": 1675338048.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j6wikpz/",
      "parent_id": "t3_10oazg7",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-02T03:40:48"
    },
    {
      "id": "j6xb6z0",
      "author": "amousss",
      "body": "thank you",
      "body_html": "<div class=\"md\"><p>thank you</p>\n</div>",
      "created_utc": 1675352304.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j6xb6z0/",
      "parent_id": "t3_10oazg7",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-02T07:38:24"
    },
    {
      "id": "j6ya5pq",
      "author": "tosleepinacroissant",
      "body": "Hi! basically my results are too good to be true and my supervisors think I must be making a mistake :( so I would need some help please! Im very new to machine learning so I hope this question will make sense ðŸ˜­  \nIm using the SciKit Learn ridge regression function (im using the lasso and elastic net functions too for comparison but ridge performs best) in python. I am using it to propagate satellite orbits with past TLE (two-line element) data.  \nI have a satellite with 7750 days worth of data which is split into df\\_train (pd DataFrame contains data for a chosen number of days) and df\\_test (contains the rest of the data). These are my variables:  \nX\\_train = df\\_train\\[feature\\_cols\\]  \ny\\_train = df\\_train\\[\\[target\\_col\\]\\].values.ravel()  \nX\\_test = df\\_test\\[feature\\_cols\\]  \ny\\_test = df\\_test\\[\\[target\\_col\\]\\].values.ravel()  \nThis is how I implement the ridge function:  \nrf\\_ridge1 = Ridge(alpha=0.00000000000000001)  \nrf\\_ridge1.fit(X\\_train, y\\_train)  \ny\\_pred\\_ridge1 = rf\\_ridge1.predict(X\\_test)  \nThe problem I'm having is that I cant understand whether the data from X\\_test is being used as feedback to train the algorithm or it is purely used to see performance?  \nThe results are letting me predict 20 years worth of data with 7 days of training with EVS = 0.99999 which is insane. My supervisors don't believe that this is possible and im doubting it now too. It would make more sense that the 20 years of test data is sending feedback to the algorithm to improve it?  \nIm doing this for my masters in mechanical engineering so my supervisors are well versed in the orbital propagation part but are unfamiliar with the machine learning component.  \nSorry for the long message! Ive been trying to find a concrete answer online but cant find what I need :(  \nIf you made it here thank you :) Please let me know if you need more info!! again I apologize if this is poorly explained im still very new at this (its even my first python project ðŸ˜‚)!!",
      "body_html": "<div class=\"md\"><p>Hi! basically my results are too good to be true and my supervisors think I must be making a mistake :( so I would need some help please! Im very new to machine learning so I hope this question will make sense ðŸ˜­<br/>\nIm using the SciKit Learn ridge regression function (im using the lasso and elastic net functions too for comparison but ridge performs best) in python. I am using it to propagate satellite orbits with past TLE (two-line element) data.<br/>\nI have a satellite with 7750 days worth of data which is split into df_train (pd DataFrame contains data for a chosen number of days) and df_test (contains the rest of the data). These are my variables:<br/>\nX_train = df_train[feature_cols]<br/>\ny_train = df_train[[target_col]].values.ravel()<br/>\nX_test = df_test[feature_cols]<br/>\ny_test = df_test[[target_col]].values.ravel()<br/>\nThis is how I implement the ridge function:<br/>\nrf_ridge1 = Ridge(alpha=0.00000000000000001)<br/>\nrf_ridge1.fit(X_train, y_train)<br/>\ny_pred_ridge1 = rf_ridge1.predict(X_test)<br/>\nThe problem I&#39;m having is that I cant understand whether the data from X_test is being used as feedback to train the algorithm or it is purely used to see performance?<br/>\nThe results are letting me predict 20 years worth of data with 7 days of training with EVS = 0.99999 which is insane. My supervisors don&#39;t believe that this is possible and im doubting it now too. It would make more sense that the 20 years of test data is sending feedback to the algorithm to improve it?<br/>\nIm doing this for my masters in mechanical engineering so my supervisors are well versed in the orbital propagation part but are unfamiliar with the machine learning component.<br/>\nSorry for the long message! Ive been trying to find a concrete answer online but cant find what I need :(<br/>\nIf you made it here thank you :) Please let me know if you need more info!! again I apologize if this is poorly explained im still very new at this (its even my first python project ðŸ˜‚)!!</p>\n</div>",
      "created_utc": 1675365377.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j6ya5pq/",
      "parent_id": "t3_10oazg7",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-02T11:16:17"
    },
    {
      "id": "j6yocpt",
      "author": "dcanna2006",
      "body": "Hi Everyone, looking for direction as a beginner in the field. I am investigating what would be the best low cost NLP model to use for my medical report written project and recommendations on methods for preprocessing data. \n\nThe project involves preprocessing patient medical referrals which are in pdf non FHIR format written to a specialist, and the associated specialists medical report again not in FHIR format. I need a way to preprocess this data and Then pick a suitable model to be trained or fine tuned on this data. The model could then be promoted to provide suggested responses for future reports based on a prompt with a referral.",
      "body_html": "<div class=\"md\"><p>Hi Everyone, looking for direction as a beginner in the field. I am investigating what would be the best low cost NLP model to use for my medical report written project and recommendations on methods for preprocessing data. </p>\n\n<p>The project involves preprocessing patient medical referrals which are in pdf non FHIR format written to a specialist, and the associated specialists medical report again not in FHIR format. I need a way to preprocess this data and Then pick a suitable model to be trained or fine tuned on this data. The model could then be promoted to provide suggested responses for future reports based on a prompt with a referral.</p>\n</div>",
      "created_utc": 1675370706.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j6yocpt/",
      "parent_id": "t3_10oazg7",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-02T12:45:06"
    },
    {
      "id": "j6zo5h5",
      "author": "Wild_Basil_2396",
      "body": "Hello everyone,\n I have a question about the Google Colab and the amount of mobile data(internet) used to run it.\n\nMy question,\nWould it possible to run a Google Colab in my mobile browser? If yes, On an average, how much data could it consume if I run it for an hour?\n\nThank you.",
      "body_html": "<div class=\"md\"><p>Hello everyone,\n I have a question about the Google Colab and the amount of mobile data(internet) used to run it.</p>\n\n<p>My question,\nWould it possible to run a Google Colab in my mobile browser? If yes, On an average, how much data could it consume if I run it for an hour?</p>\n\n<p>Thank you.</p>\n</div>",
      "created_utc": 1675385038.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j6zo5h5/",
      "parent_id": "t3_10oazg7",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-02T16:43:58"
    },
    {
      "id": "j7052j5",
      "author": "Bubbly_Classic8362",
      "body": "Hey everyone, I want to start a new project for emotion detection. I have used sklearn in the past but I have also seen a lot of stuff about tensor flow. In your opinion, which is better for this task?",
      "body_html": "<div class=\"md\"><p>Hey everyone, I want to start a new project for emotion detection. I have used sklearn in the past but I have also seen a lot of stuff about tensor flow. In your opinion, which is better for this task?</p>\n</div>",
      "created_utc": 1675392741.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j7052j5/",
      "parent_id": "t3_10oazg7",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-02T18:52:21"
    },
    {
      "id": "j71cswp",
      "author": "SkylerSlytherin",
      "body": "How does running multiple processes (e.g 2 different .py file written with pytorch) on a single GPU affect training time and productivity? Our lab is short on GPU and a colleague of mine keeps throwing his codes on GPUs that Iâ€™ve been already using. Since GPU doesnâ€™t support manually adjusting priorities (like renice), is there anything I can do to speed up my process? Thanks in advance.",
      "body_html": "<div class=\"md\"><p>How does running multiple processes (e.g 2 different .py file written with pytorch) on a single GPU affect training time and productivity? Our lab is short on GPU and a colleague of mine keeps throwing his codes on GPUs that Iâ€™ve been already using. Since GPU doesnâ€™t support manually adjusting priorities (like renice), is there anything I can do to speed up my process? Thanks in advance.</p>\n</div>",
      "created_utc": 1675421999.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j71cswp/",
      "parent_id": "t3_10oazg7",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-03T02:59:59"
    },
    {
      "id": "j72prrx",
      "author": "TheCoconutTree",
      "body": "How much training data do I need:\n\nI'm building a neural net classifier, and my population is roughly 10 million rows of SQL data. What's a reasonable number of rows to randomly sample in order to make classification predictions, all else being equal? Is it impacted by the dimensionality of inputs? If so, is there an equation or rule of thumb that relates input dimensionality, population size, and necessary random sample size for accuracy? The classifier is a binary yes/no classifier if that matters.",
      "body_html": "<div class=\"md\"><p>How much training data do I need:</p>\n\n<p>I&#39;m building a neural net classifier, and my population is roughly 10 million rows of SQL data. What&#39;s a reasonable number of rows to randomly sample in order to make classification predictions, all else being equal? Is it impacted by the dimensionality of inputs? If so, is there an equation or rule of thumb that relates input dimensionality, population size, and necessary random sample size for accuracy? The classifier is a binary yes/no classifier if that matters.</p>\n</div>",
      "created_utc": 1675445077.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j72prrx/",
      "parent_id": "t3_10oazg7",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-03T09:24:37"
    },
    {
      "id": "j74t9of",
      "author": "Trex090",
      "body": "Hello, my goal is to create embeddings for a set of small graphs I have. I need a method that takes into account that the nodes in my graphs have four continuous attributes and a label associated with them. Does anyone know of some python libraries or papers that address this task? I have looked into methods like graph2vec and graphsage but those do not consider the node attributes of the graph.\n\nAlso, it would be a bonus if the model was inductive so that I can create embeddings for graphs that are not part of the training data down the line.\n\nThank you!",
      "body_html": "<div class=\"md\"><p>Hello, my goal is to create embeddings for a set of small graphs I have. I need a method that takes into account that the nodes in my graphs have four continuous attributes and a label associated with them. Does anyone know of some python libraries or papers that address this task? I have looked into methods like graph2vec and graphsage but those do not consider the node attributes of the graph.</p>\n\n<p>Also, it would be a bonus if the model was inductive so that I can create embeddings for graphs that are not part of the training data down the line.</p>\n\n<p>Thank you!</p>\n</div>",
      "created_utc": 1675475678.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j74t9of/",
      "parent_id": "t3_10oazg7",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": true,
      "distinguished": null,
      "timestamp": "2023-02-03T17:54:38"
    },
    {
      "id": "j77tcea",
      "author": "Jack7heRapper",
      "body": "I'm reading a [paper](https://openaccess.thecvf.com/content/CVPR2022/html/Wang_DeepFake_Disrupter_The_Detector_of_DeepFake_Is_My_Friend_CVPR_2022_paper.html) that adds learnable perturbations to source images so that a DeepFake Generator that manipulates the perturbed image will generate a distorted image that cannot spoof a DeepFake Detector.  \n\nThe authors optimize their perturbation generator (called DeepFake Disruptor) using a multi-objective loss function that they designed themselves. The problem is that to minimize the objective function, 3 out of 4 terms need to be minimized to 0 but there is no lower bound on the first term. So, the theoretical minimum of the loss function is negative infinity. \n\nI'm confused as to how the authors were able to optimize this loss function. They mentioned that they used GradNorm to weigh the other 3 terms but I just couldn't optimize it when I coded it myself (the author's code is not available). Can someone help me with understanding how I could minimize their loss function?",
      "body_html": "<div class=\"md\"><p>I&#39;m reading a <a href=\"https://openaccess.thecvf.com/content/CVPR2022/html/Wang_DeepFake_Disrupter_The_Detector_of_DeepFake_Is_My_Friend_CVPR_2022_paper.html\">paper</a> that adds learnable perturbations to source images so that a DeepFake Generator that manipulates the perturbed image will generate a distorted image that cannot spoof a DeepFake Detector.  </p>\n\n<p>The authors optimize their perturbation generator (called DeepFake Disruptor) using a multi-objective loss function that they designed themselves. The problem is that to minimize the objective function, 3 out of 4 terms need to be minimized to 0 but there is no lower bound on the first term. So, the theoretical minimum of the loss function is negative infinity. </p>\n\n<p>I&#39;m confused as to how the authors were able to optimize this loss function. They mentioned that they used GradNorm to weigh the other 3 terms but I just couldn&#39;t optimize it when I coded it myself (the author&#39;s code is not available). Can someone help me with understanding how I could minimize their loss function?</p>\n</div>",
      "created_utc": 1675537464.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j77tcea/",
      "parent_id": "t3_10oazg7",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-04T11:04:24"
    },
    {
      "id": "j781e3n",
      "author": "raikone51",
      "body": "Hey Guys, I am a noob with machine learning, but I really excited to be honest.\n\nMy question is: I have built a dataset related to DDoS attacks, in my topology I have two pcs, pc1 and pc2. Pc1 sends legitimate traffic , pc2 sends a DDoS attack. \n\nNow I have my dataset and I started with the basics,I was cleaning.\n\nIn this case, I could remove all columns with  \"0\" values ? \n\nBecause I think, that  if the collum has only  0 values, this collum should not be useful for my analyses, because there is nothing that differentiates the traffic between this two pcs, makes sense ?\n\nAnd what other things should I do before I apply a machine learning algorithm? I dont see any missing values in my dataset. \n\nAnd any recommendations about algorithms? My dataset is label and I was think about decision three or random forest regression.",
      "body_html": "<div class=\"md\"><p>Hey Guys, I am a noob with machine learning, but I really excited to be honest.</p>\n\n<p>My question is: I have built a dataset related to DDoS attacks, in my topology I have two pcs, pc1 and pc2. Pc1 sends legitimate traffic , pc2 sends a DDoS attack. </p>\n\n<p>Now I have my dataset and I started with the basics,I was cleaning.</p>\n\n<p>In this case, I could remove all columns with  &quot;0&quot; values ? </p>\n\n<p>Because I think, that  if the collum has only  0 values, this collum should not be useful for my analyses, because there is nothing that differentiates the traffic between this two pcs, makes sense ?</p>\n\n<p>And what other things should I do before I apply a machine learning algorithm? I dont see any missing values in my dataset. </p>\n\n<p>And any recommendations about algorithms? My dataset is label and I was think about decision three or random forest regression.</p>\n</div>",
      "created_utc": 1675540850.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j781e3n/",
      "parent_id": "t3_10oazg7",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-04T12:00:50"
    },
    {
      "id": "j79s6s8",
      "author": "CoronaRadiata576",
      "body": "A question from a student - why in regression problems are the loss function and performance metric the same thing? For example, in classification tasks, the loss function may be MSE and the metric - accuracy, which is understandably interpreted. But how do I interpret the efficiency of a regression model by looking at it loss function?",
      "body_html": "<div class=\"md\"><p>A question from a student - why in regression problems are the loss function and performance metric the same thing? For example, in classification tasks, the loss function may be MSE and the metric - accuracy, which is understandably interpreted. But how do I interpret the efficiency of a regression model by looking at it loss function?</p>\n</div>",
      "created_utc": 1675570457.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j79s6s8/",
      "parent_id": "t3_10oazg7",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-04T20:14:17"
    },
    {
      "id": "j79yd10",
      "author": "its420SnoopDogg",
      "body": "is there a free version as high quality as elevenlabs? Now they have paywalled it?",
      "body_html": "<div class=\"md\"><p>is there a free version as high quality as elevenlabs? Now they have paywalled it?</p>\n</div>",
      "created_utc": 1675574160.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j79yd10/",
      "parent_id": "t3_10oazg7",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-04T21:16:00"
    },
    {
      "id": "j7aq10d",
      "author": "fitz-simmons-0",
      "body": "I am trying to build an open book question answer model at work. The model would take input in the form of documents. I should be able to ask a question and the model/chatbot retrieves the answer and shows that.\nI am familiar with the original transformers model and I have built one for language translation. However, I am still learning NLP.\n\nQuestion - there are many articles on open domain question answering and many models but it is confusing to understand what would be best suited for my purpose. Any suggestions on best and easiest to run/understand model that I can tweak for my data and use it?",
      "body_html": "<div class=\"md\"><p>I am trying to build an open book question answer model at work. The model would take input in the form of documents. I should be able to ask a question and the model/chatbot retrieves the answer and shows that.\nI am familiar with the original transformers model and I have built one for language translation. However, I am still learning NLP.</p>\n\n<p>Question - there are many articles on open domain question answering and many models but it is confusing to understand what would be best suited for my purpose. Any suggestions on best and easiest to run/understand model that I can tweak for my data and use it?</p>\n</div>",
      "created_utc": 1675595987.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j7aq10d/",
      "parent_id": "t3_10oazg7",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-05T03:19:47"
    },
    {
      "id": "j7atef6",
      "author": "Basic-Energy-955",
      "body": "New to ML, looking some direction. I have a large timeseries dataset of GPS coordinates of vehicle trips. Each GPS data point has a timestamp, speed, orientation and vehicle ID. \n\nI'm wanting to use ML trained on the historic data to predict a live vehicles next GPS data point.\n\nThanks",
      "body_html": "<div class=\"md\"><p>New to ML, looking some direction. I have a large timeseries dataset of GPS coordinates of vehicle trips. Each GPS data point has a timestamp, speed, orientation and vehicle ID. </p>\n\n<p>I&#39;m wanting to use ML trained on the historic data to predict a live vehicles next GPS data point.</p>\n\n<p>Thanks</p>\n</div>",
      "created_utc": 1675598731.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j7atef6/",
      "parent_id": "t3_10oazg7",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-05T04:05:31"
    },
    {
      "id": "j7dhabf",
      "author": "Stabile_Feldmaus",
      "body": "On which kind of tasks whas ChatGPT specifically/directly trained and which did it learn surprisingly along the way? \n\nI know this is a vague question, but I'm not an expert so I hope this is OK. \n\nAs I understand it, ChatGPTs training involved phases where humans would directly rank the NNs output. Was this organized into specific tasks? \n\nLike N iterations for prompts of the form \"Write a text in the style of this Person\", M iterations of \" summarize this text and answer questions about it\" etc.?\n\nIf this is somewhat correct, I would be interested in the skills it learned that were not intended.",
      "body_html": "<div class=\"md\"><p>On which kind of tasks whas ChatGPT specifically/directly trained and which did it learn surprisingly along the way? </p>\n\n<p>I know this is a vague question, but I&#39;m not an expert so I hope this is OK. </p>\n\n<p>As I understand it, ChatGPTs training involved phases where humans would directly rank the NNs output. Was this organized into specific tasks? </p>\n\n<p>Like N iterations for prompts of the form &quot;Write a text in the style of this Person&quot;, M iterations of &quot; summarize this text and answer questions about it&quot; etc.?</p>\n\n<p>If this is somewhat correct, I would be interested in the skills it learned that were not intended.</p>\n</div>",
      "created_utc": 1675641652.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j7dhabf/",
      "parent_id": "t3_10oazg7",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-05T16:00:52"
    },
    {
      "id": "j7f5pd6",
      "author": null,
      "body": "[deleted]",
      "body_html": "<div class=\"md\"><p>[deleted]</p>\n</div>",
      "created_utc": 1675677834.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j7f5pd6/",
      "parent_id": "t3_10oazg7",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-06T02:03:54"
    },
    {
      "id": "j7gglax",
      "author": "sanskar_negi",
      "body": "after restarting pc, would a machine learning model recognize old test cases ?",
      "body_html": "<div class=\"md\"><p>after restarting pc, would a machine learning model recognize old test cases ?</p>\n</div>",
      "created_utc": 1675702840.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j7gglax/",
      "parent_id": "t3_10oazg7",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-06T09:00:40"
    },
    {
      "id": "j7i4ahy",
      "author": "aveterotto",
      "body": "consider a a probabilistic mlp  whose last layer is a distributional lambda layer that sample from a gaussian distribution. the mlp has been trained  with MC-dropout  by minimizing the negative log likelihood. The samples are considered I.I.d and normally distributed around the true values.  WHAT the f should i use to report the uncertainty, the quantile or the variance?. Does the activation of dropout makes so that the samples are not gaussian distributed anymore?",
      "body_html": "<div class=\"md\"><p>consider a a probabilistic mlp  whose last layer is a distributional lambda layer that sample from a gaussian distribution. the mlp has been trained  with MC-dropout  by minimizing the negative log likelihood. The samples are considered I.I.d and normally distributed around the true values.  WHAT the f should i use to report the uncertainty, the quantile or the variance?. Does the activation of dropout makes so that the samples are not gaussian distributed anymore?</p>\n</div>",
      "created_utc": 1675725699.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j7i4ahy/",
      "parent_id": "t3_10oazg7",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-06T15:21:39"
    },
    {
      "id": "j7kkra6",
      "author": "Zestyclose-Check-751",
      "body": "I want to publish my paper related to the image retrieval problem, and I guess that the \"short paper\" format is the best for it. Do you know of any coming conferences with a corresponding section? BMVC and ICCV are the most relevant, but there is no call for short papers there.",
      "body_html": "<div class=\"md\"><p>I want to publish my paper related to the image retrieval problem, and I guess that the &quot;short paper&quot; format is the best for it. Do you know of any coming conferences with a corresponding section? BMVC and ICCV are the most relevant, but there is no call for short papers there.</p>\n</div>",
      "created_utc": 1675778278.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j7kkra6/",
      "parent_id": "t3_10oazg7",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-07T05:57:58"
    },
    {
      "id": "j7krenk",
      "author": "Shot-Builder-2374",
      "body": "I'm looking for a solution to change the background of some of my wedding photos, Is there an easy to use AI tool for that available?",
      "body_html": "<div class=\"md\"><p>I&#39;m looking for a solution to change the background of some of my wedding photos, Is there an easy to use AI tool for that available?</p>\n</div>",
      "created_utc": 1675781303.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j7krenk/",
      "parent_id": "t3_10oazg7",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-07T06:48:23"
    },
    {
      "id": "j7kwngd",
      "author": null,
      "body": "New to ML so excuse the ignorance.  If I build an ML program to play snake (or whatever) can I export that code to a typical python (or binary) executable?  How portable are the results?  How efficient?",
      "body_html": "<div class=\"md\"><p>New to ML so excuse the ignorance.  If I build an ML program to play snake (or whatever) can I export that code to a typical python (or binary) executable?  How portable are the results?  How efficient?</p>\n</div>",
      "created_utc": 1675783531.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j7kwngd/",
      "parent_id": "t3_10oazg7",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-07T07:25:31"
    },
    {
      "id": "j7mmdi0",
      "author": "-justapersononreddit",
      "body": "For a project I have to compare two algorithms. My research question is concerned with making inference, so my choices are limited to models that can be easily interpreted. My response variable is continuous and I have a lot features to consider as possible predictors. Does it make sense to use stepwise regression and LASSO regression? From what I have read it seems that itâ€™s almost certain that LASSO would perform better in terms of accuracy, but  maybe comparing the two models would still be interesting to check if they both point to the same predictors? Does that make sense? TIA",
      "body_html": "<div class=\"md\"><p>For a project I have to compare two algorithms. My research question is concerned with making inference, so my choices are limited to models that can be easily interpreted. My response variable is continuous and I have a lot features to consider as possible predictors. Does it make sense to use stepwise regression and LASSO regression? From what I have read it seems that itâ€™s almost certain that LASSO would perform better in terms of accuracy, but  maybe comparing the two models would still be interesting to check if they both point to the same predictors? Does that make sense? TIA</p>\n</div>",
      "created_utc": 1675807498.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j7mmdi0/",
      "parent_id": "t3_10oazg7",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-07T14:04:58"
    },
    {
      "id": "j7mslqh",
      "author": "C_l3b",
      "body": "Hi easy question, I want to start studying RL (non-deep and deep)\n\nWhat are the papers/books that I must read to have strong foundation?",
      "body_html": "<div class=\"md\"><p>Hi easy question, I want to start studying RL (non-deep and deep)</p>\n\n<p>What are the papers/books that I must read to have strong foundation?</p>\n</div>",
      "created_utc": 1675810018.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j7mslqh/",
      "parent_id": "t3_10oazg7",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-07T14:46:58"
    },
    {
      "id": "j7n4z38",
      "author": "-Django",
      "body": "Are there rules of thumb for the max size of the output space for multi-label classification tasks? I assume it depends on the dataset's information content and the model's complexity.  E.g. I've heard that if each class has \\~10 labels on average, then you shouldn't predict more than 10 classes. Does anyone know of research in this area?",
      "body_html": "<div class=\"md\"><p>Are there rules of thumb for the max size of the output space for multi-label classification tasks? I assume it depends on the dataset&#39;s information content and the model&#39;s complexity.  E.g. I&#39;ve heard that if each class has ~10 labels on average, then you shouldn&#39;t predict more than 10 classes. Does anyone know of research in this area?</p>\n</div>",
      "created_utc": 1675815262.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j7n4z38/",
      "parent_id": "t3_10oazg7",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-07T16:14:22"
    },
    {
      "id": "j7qgt0x",
      "author": "Accomplished_Nail_11",
      "body": "Hello everyone, Im trying train a text-img diffusion model. Im fairly new to ML and have a project to do with diffusion models. I need some pointers on where to get started a what to look into when training this models, I do know about forward process and reverse process but doesnt have any hands on experience for training a model. thankyou for helping a noob. ðŸ‘",
      "body_html": "<div class=\"md\"><p>Hello everyone, Im trying train a text-img diffusion model. Im fairly new to ML and have a project to do with diffusion models. I need some pointers on where to get started a what to look into when training this models, I do know about forward process and reverse process but doesnt have any hands on experience for training a model. thankyou for helping a noob. ðŸ‘</p>\n</div>",
      "created_utc": 1675879779.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j7qgt0x/",
      "parent_id": "t3_10oazg7",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-08T10:09:39"
    },
    {
      "id": "j7qrvk6",
      "author": "martinisi",
      "body": "Iâ€™m quite new to ML and need some advise on where to start. \n\nIâ€™m building an application and need to group supermarket products by type. By bread and dairy, but also like semi-skimmed milk and skimmed milk.",
      "body_html": "<div class=\"md\"><p>Iâ€™m quite new to ML and need some advise on where to start. </p>\n\n<p>Iâ€™m building an application and need to group supermarket products by type. By bread and dairy, but also like semi-skimmed milk and skimmed milk.</p>\n</div>",
      "created_utc": 1675884008.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j7qrvk6/",
      "parent_id": "t3_10oazg7",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-08T11:20:08"
    },
    {
      "id": "j7ril3k",
      "author": "Kastell24",
      "body": "I am new to reinforcement learning and I would like to get a book to understand the field in depth.\n\nDo you have any good book recommendations?\n\nThank you in advanced.",
      "body_html": "<div class=\"md\"><p>I am new to reinforcement learning and I would like to get a book to understand the field in depth.</p>\n\n<p>Do you have any good book recommendations?</p>\n\n<p>Thank you in advanced.</p>\n</div>",
      "created_utc": 1675893958.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j7ril3k/",
      "parent_id": "t3_10oazg7",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-08T14:05:58"
    },
    {
      "id": "j7sshua",
      "author": "CogPsych441",
      "body": "I have a problem where I need to train a multi-class classifier, and I want to use active learning to achieve high accuracy with as few training examples as possible. Some classes are highly separable and require relatively few training instances to learn, whereas others are harder to learn and need more training instances. I don't necessarily know which classes are easy or hard a priori, though, and I have to construct the training set on the fly. I can always sample a new example of a given class but I can't make any guarantees about what that example will look like other than its label.\n\nAre there any active learning algorithms that could tell me which class(es) I should sample from to maximize overall model accuracy?",
      "body_html": "<div class=\"md\"><p>I have a problem where I need to train a multi-class classifier, and I want to use active learning to achieve high accuracy with as few training examples as possible. Some classes are highly separable and require relatively few training instances to learn, whereas others are harder to learn and need more training instances. I don&#39;t necessarily know which classes are easy or hard a priori, though, and I have to construct the training set on the fly. I can always sample a new example of a given class but I can&#39;t make any guarantees about what that example will look like other than its label.</p>\n\n<p>Are there any active learning algorithms that could tell me which class(es) I should sample from to maximize overall model accuracy?</p>\n</div>",
      "created_utc": 1675913649.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j7sshua/",
      "parent_id": "t3_10oazg7",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-08T19:34:09"
    },
    {
      "id": "j7th3qg",
      "author": "Maditek",
      "body": "I want to start a project using python,opencv and tensorflow to create a car recognition app that will detect other cars from a video camera that's placed in your own car. My question is first, do you guys know any good car datasets? second, do I need to look for a dataset that has pictures/videos/labels/any feature that is filmed from a car perspective or is it enough to find many images of cars from any angle.\r  \n\r  \nI tried looking for many datasets but I couldn't find many that are filmed from a car perspective and many of them were hard to fit in my tensorflow model.\r  \n\r  \nI am new to tensorflow so I don't know if these are the types of questions you ask here but I am trying my best to describe my problem since I am yet to understand much about machine learning and all. thanks for any helpers!",
      "body_html": "<div class=\"md\"><p>I want to start a project using python,opencv and tensorflow to create a car recognition app that will detect other cars from a video camera that&#39;s placed in your own car. My question is first, do you guys know any good car datasets? second, do I need to look for a dataset that has pictures/videos/labels/any feature that is filmed from a car perspective or is it enough to find many images of cars from any angle.</p>\n\n<p>I tried looking for many datasets but I couldn&#39;t find many that are filmed from a car perspective and many of them were hard to fit in my tensorflow model.</p>\n\n<p>I am new to tensorflow so I don&#39;t know if these are the types of questions you ask here but I am trying my best to describe my problem since I am yet to understand much about machine learning and all. thanks for any helpers!</p>\n</div>",
      "created_utc": 1675928347.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j7th3qg/",
      "parent_id": "t3_10oazg7",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-08T23:39:07"
    },
    {
      "id": "j7tyxjl",
      "author": "dmzkrsk",
      "body": "What is a good book to dive into ml/statistic for an experienced programmer? A more practical book focused on problem solving: picking right tools, setup/train. Not about internal stuff. \n\nMore specific: I want to build some sort of classification/recommendation systems based on text, images and metadata",
      "body_html": "<div class=\"md\"><p>What is a good book to dive into ml/statistic for an experienced programmer? A more practical book focused on problem solving: picking right tools, setup/train. Not about internal stuff. </p>\n\n<p>More specific: I want to build some sort of classification/recommendation systems based on text, images and metadata</p>\n</div>",
      "created_utc": 1675942968.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j7tyxjl/",
      "parent_id": "t3_10oazg7",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-09T03:42:48"
    },
    {
      "id": "j7vbxbw",
      "author": "UrMomHusband",
      "body": "Do you know where I can find a large amount of audio dataset from one person in particular?",
      "body_html": "<div class=\"md\"><p>Do you know where I can find a large amount of audio dataset from one person in particular?</p>\n</div>",
      "created_utc": 1675965014.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j7vbxbw/",
      "parent_id": "t3_10oazg7",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-09T09:50:14"
    },
    {
      "id": "j7vismo",
      "author": "priyangshu_hzy",
      "body": "Help in increasing the accuracy of lightGbm(Regression) model  for a Kaggle competition organized by my school. Would be grateful if you guys would help me before the deadline of my project.\n\nDrive link for the data: [Dataset link](https://drive.google.com/drive/folders/1ronho26m9uX9_ooBTh0M81ox1a43ika8?usp=sharing)  \nBut I can't increase the accuracy anymore now. I tried tuning some parameters too but it didn't increase the accuracy of it.   \nWould be really helpful if you guys could give me some tips how to increase the score.\n\n>  \nimport numpy as np  \nimport pandas as pd  \ntrain = pd.read\\_csv('train.csv')  \ntest = pd.read\\_csv('test.csv')  \nsample\\_submission = pd.read\\_csv('sample\\_submission.csv')  \ntrain.head()  \nimport lightgbm as lgb  \nreg = lgb.LGBMRegressor(learning\\_rate=0.09,max\\_depth=-5,random\\_state=42,min\\_data\\_in\\_leaf=35)  \nreg.fit(train\\[\\[f'F\\_{i}' for i in range(40)\\]\\],train\\['target'\\])  \npreds = reg.predict(test\\[\\[f'F\\_{i}' for i in range(40)\\]\\])  \nsample\\_submission\\['target'\\] = preds  \nsample\\_submission.to\\_csv(\"submission.csv\", index = False)  \nsample\\_submission.head()  \n\n\nI researched that TabNet can get better accuracy but I don't really have an idea how to implement it. So guys further help would be appreciated.",
      "body_html": "<div class=\"md\"><p>Help in increasing the accuracy of lightGbm(Regression) model  for a Kaggle competition organized by my school. Would be grateful if you guys would help me before the deadline of my project.</p>\n\n<p>Drive link for the data: <a href=\"https://drive.google.com/drive/folders/1ronho26m9uX9_ooBTh0M81ox1a43ika8?usp=sharing\">Dataset link</a><br/>\nBut I can&#39;t increase the accuracy anymore now. I tried tuning some parameters too but it didn&#39;t increase the accuracy of it.<br/>\nWould be really helpful if you guys could give me some tips how to increase the score.</p>\n\n<blockquote>\n<p>import numpy as np<br/>\nimport pandas as pd<br/>\ntrain = pd.read_csv(&#39;train.csv&#39;)<br/>\ntest = pd.read_csv(&#39;test.csv&#39;)<br/>\nsample_submission = pd.read_csv(&#39;sample_submission.csv&#39;)<br/>\ntrain.head()<br/>\nimport lightgbm as lgb<br/>\nreg = lgb.LGBMRegressor(learning_rate=0.09,max_depth=-5,random_state=42,min_data_in_leaf=35)<br/>\nreg.fit(train[[f&#39;F_{i}&#39; for i in range(40)]],train[&#39;target&#39;])<br/>\npreds = reg.predict(test[[f&#39;F_{i}&#39; for i in range(40)]])<br/>\nsample_submission[&#39;target&#39;] = preds<br/>\nsample_submission.to_csv(&quot;submission.csv&quot;, index = False)<br/>\nsample_submission.head()  </p>\n</blockquote>\n\n<p>I researched that TabNet can get better accuracy but I don&#39;t really have an idea how to implement it. So guys further help would be appreciated.</p>\n</div>",
      "created_utc": 1675967580.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j7vismo/",
      "parent_id": "t3_10oazg7",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-09T10:33:00"
    },
    {
      "id": "j7xyc9c",
      "author": "throwaway2676",
      "body": "Does facebook have any developments in the LLM space to compete with google and chatgpt?  Are there any rumors?  It seems like they've invested a lot into DL, but I guess most of it was metaverse related.",
      "body_html": "<div class=\"md\"><p>Does facebook have any developments in the LLM space to compete with google and chatgpt?  Are there any rumors?  It seems like they&#39;ve invested a lot into DL, but I guess most of it was metaverse related.</p>\n</div>",
      "created_utc": 1676004350.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j7xyc9c/",
      "parent_id": "t3_10oazg7",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-09T20:45:50"
    },
    {
      "id": "j7zsg1z",
      "author": "parawaa",
      "body": "Do models like the one 11Labs presented that can clone the voice of a human need a big dataset of dialogues in order to achieve that or it can be done with what a normal person has on the internet (Some videos, audios but not as much as a celebrity or actor has)?",
      "body_html": "<div class=\"md\"><p>Do models like the one 11Labs presented that can clone the voice of a human need a big dataset of dialogues in order to achieve that or it can be done with what a normal person has on the internet (Some videos, audios but not as much as a celebrity or actor has)?</p>\n</div>",
      "created_utc": 1676045168.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j7zsg1z/",
      "parent_id": "t3_10oazg7",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-10T08:06:08"
    },
    {
      "id": "j7ztpd7",
      "author": "EducationalCreme9044",
      "body": "In Google Colab, how do I actually force Keras to use GPU (not the provided one... but I also can't get that to work). I have QUADRO so it should work... Googling around only returns results on how to use Google's GPU's (which also don't work for me for some reason, or Google's GPU's coincidentally are exactly as fast as my 6 year old CPU).",
      "body_html": "<div class=\"md\"><p>In Google Colab, how do I actually force Keras to use GPU (not the provided one... but I also can&#39;t get that to work). I have QUADRO so it should work... Googling around only returns results on how to use Google&#39;s GPU&#39;s (which also don&#39;t work for me for some reason, or Google&#39;s GPU&#39;s coincidentally are exactly as fast as my 6 year old CPU).</p>\n</div>",
      "created_utc": 1676045669.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j7ztpd7/",
      "parent_id": "t3_10oazg7",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-10T08:14:29"
    },
    {
      "id": "j80wxxt",
      "author": "throwaway2676",
      "body": "Was anyone here around the ML/DL space back when IBM released Watson?  What kind of impact did it have on the field, and why didn't we see a greater degree of progress from that point?",
      "body_html": "<div class=\"md\"><p>Was anyone here around the ML/DL space back when IBM released Watson?  What kind of impact did it have on the field, and why didn&#39;t we see a greater degree of progress from that point?</p>\n</div>",
      "created_utc": 1676060938.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j80wxxt/",
      "parent_id": "t3_10oazg7",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-10T12:28:58"
    },
    {
      "id": "j83hzso",
      "author": "jjok13",
      "body": "What cloud services would you use nowadays for ML training/testing? I have a binary classification medical dataset (20gb), but my computer isn't the best and testing anything just takes very long. I've heard of Colab and Kaggle, but would very much like to hear your recommendations/experiences with these and other services.  \n\n\nWhat options are out there? Specifically for a student that doesn't need an expensive infrastructure but something better than my pc?",
      "body_html": "<div class=\"md\"><p>What cloud services would you use nowadays for ML training/testing? I have a binary classification medical dataset (20gb), but my computer isn&#39;t the best and testing anything just takes very long. I&#39;ve heard of Colab and Kaggle, but would very much like to hear your recommendations/experiences with these and other services.  </p>\n\n<p>What options are out there? Specifically for a student that doesn&#39;t need an expensive infrastructure but something better than my pc?</p>\n</div>",
      "created_utc": 1676111579.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j83hzso/",
      "parent_id": "t3_10oazg7",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-11T02:32:59"
    },
    {
      "id": "j84xnj1",
      "author": "vwxyzabcdef",
      "body": "Are TPUs or GPUs better suited for 1) training and 2) running inference off of LLMs? Iâ€™m reading a lot about how TPUs are cheaper and faster to run, but all the hype seems to be around GPUsâ€¦?",
      "body_html": "<div class=\"md\"><p>Are TPUs or GPUs better suited for 1) training and 2) running inference off of LLMs? Iâ€™m reading a lot about how TPUs are cheaper and faster to run, but all the hype seems to be around GPUsâ€¦?</p>\n</div>",
      "created_utc": 1676137024.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j84xnj1/",
      "parent_id": "t3_10oazg7",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-11T09:37:04"
    },
    {
      "id": "j84y2dg",
      "author": "Severe_Sweet_862",
      "body": "Can anyone let me know how I would go about making a movie genre classifier? I just want to define a few genres like comedy, action, horror, romance etc and then teach a neural network to read a movie name, search for it on the internet and predict which genre it is most likely to be. Any help?",
      "body_html": "<div class=\"md\"><p>Can anyone let me know how I would go about making a movie genre classifier? I just want to define a few genres like comedy, action, horror, romance etc and then teach a neural network to read a movie name, search for it on the internet and predict which genre it is most likely to be. Any help?</p>\n</div>",
      "created_utc": 1676137193.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j84y2dg/",
      "parent_id": "t3_10oazg7",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-11T09:39:53"
    },
    {
      "id": "j85f6ra",
      "author": "unobservant_bot",
      "body": "Can anyone recommend some good, relatively basic review papers for the field? I have a strong background in statistics, but I am trying to make the jump to machine learning.",
      "body_html": "<div class=\"md\"><p>Can anyone recommend some good, relatively basic review papers for the field? I have a strong background in statistics, but I am trying to make the jump to machine learning.</p>\n</div>",
      "created_utc": 1676144232.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j85f6ra/",
      "parent_id": "t3_10oazg7",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-11T11:37:12"
    },
    {
      "id": "j884uj6",
      "author": "IcySnowy",
      "body": "How can I make a side by side notebook interactively like in [nn.labml.ai](https://nn.labml.ai), I want to implement some project in that format since I want to understand machine learning papers better/",
      "body_html": "<div class=\"md\"><p>How can I make a side by side notebook interactively like in <a href=\"https://nn.labml.ai\">nn.labml.ai</a>, I want to implement some project in that format since I want to understand machine learning papers better/</p>\n</div>",
      "created_utc": 1676196989.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j884uj6/",
      "parent_id": "t3_10oazg7",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-12T02:16:29"
    },
    {
      "id": "j7twhyt",
      "author": "badabummbadabing",
      "body": "I worked as a researcher in ML for medical imaging. I am sorry to say, but what you are looking for isn't out there. There is no model that can 'just medically analyze' some scans. Don't be confused by overly simplistic headlines that claim that 'an AI' can now pass a doctor's exam.\n\nML models for medical imaging are highly specialized and trained (at most) to distinguish a set of well-defined conditions from one another (or from healthy tissue). That means that there is most likely a model that can (*on average* decently well) distinguish 'eye condition A' from 'doesn't have eye condition A', and another one for 'eye condition B', but there is no ML model that knows many different eye conditions and can just look at your scan and say: \"This person has eye condition X.\", or tell you anything beyond that.\n\nEven if that existed, it would most likely not work with your scans. Typically, these medical imaging ML systems require the data (i.e. the scans) to be standardized in some way (e.g. come from a specific scanner).\n\nYour best shot is still to show this to a trained doctor. *They* are trained to know many different conditions, and to relate the scans to your medical history etc.",
      "body_html": "<div class=\"md\"><p>I worked as a researcher in ML for medical imaging. I am sorry to say, but what you are looking for isn&#39;t out there. There is no model that can &#39;just medically analyze&#39; some scans. Don&#39;t be confused by overly simplistic headlines that claim that &#39;an AI&#39; can now pass a doctor&#39;s exam.</p>\n\n<p>ML models for medical imaging are highly specialized and trained (at most) to distinguish a set of well-defined conditions from one another (or from healthy tissue). That means that there is most likely a model that can (<em>on average</em> decently well) distinguish &#39;eye condition A&#39; from &#39;doesn&#39;t have eye condition A&#39;, and another one for &#39;eye condition B&#39;, but there is no ML model that knows many different eye conditions and can just look at your scan and say: &quot;This person has eye condition X.&quot;, or tell you anything beyond that.</p>\n\n<p>Even if that existed, it would most likely not work with your scans. Typically, these medical imaging ML systems require the data (i.e. the scans) to be standardized in some way (e.g. come from a specific scanner).</p>\n\n<p>Your best shot is still to show this to a trained doctor. <em>They</em> are trained to know many different conditions, and to relate the scans to your medical history etc.</p>\n</div>",
      "created_utc": 1675941149.0,
      "score": 2,
      "ups": 2,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j7twhyt/",
      "parent_id": "t1_j6l062p",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": true,
      "distinguished": null,
      "timestamp": "2023-02-09T03:12:29"
    },
    {
      "id": "j6iqvql",
      "author": "qalis",
      "body": "Somewhat more limited than your question, but I know two such papers: \"Tunability: Importance of Hyperparameters of Machine Learning Algorithms\" P. Probst et al., and \"Hyperparameters and tuning strategies for random forest\" P. Probst et al.\n\nBoth are on Arxiv. First one concerns tunability of multiple ML algorithms, i.e. how sensitive are they in general to hyperparameter choice. Second one delves deeper into the same area, but specifically for random forests, gathering results from many other works. Using those ideas, I was able to dramatically decrease the computational resources for tuning by better designing hyperparameter grids.",
      "body_html": "<div class=\"md\"><p>Somewhat more limited than your question, but I know two such papers: &quot;Tunability: Importance of Hyperparameters of Machine Learning Algorithms&quot; P. Probst et al., and &quot;Hyperparameters and tuning strategies for random forest&quot; P. Probst et al.</p>\n\n<p>Both are on Arxiv. First one concerns tunability of multiple ML algorithms, i.e. how sensitive are they in general to hyperparameter choice. Second one delves deeper into the same area, but specifically for random forests, gathering results from many other works. Using those ideas, I was able to dramatically decrease the computational resources for tuning by better designing hyperparameter grids.</p>\n</div>",
      "created_utc": 1675098047.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j6iqvql/",
      "parent_id": "t1_j6i36hx",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-01-30T09:00:47"
    },
    {
      "id": "j6ymh8j",
      "author": "trnka",
      "body": "I've seen that handled with feature engineering in the past. If each row is one player's performance in one game, you could have one-hot columns for their teammates and opponents.\n\nI'm not the most experienced in that area so take it with a grain of salt.",
      "body_html": "<div class=\"md\"><p>I&#39;ve seen that handled with feature engineering in the past. If each row is one player&#39;s performance in one game, you could have one-hot columns for their teammates and opponents.</p>\n\n<p>I&#39;m not the most experienced in that area so take it with a grain of salt.</p>\n</div>",
      "created_utc": 1675370004.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j6ymh8j/",
      "parent_id": "t1_j6wtm96",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-02T12:33:24"
    },
    {
      "id": "j7f2cgp",
      "author": "trnka",
      "body": "I've used Prophet which handles those seasonalities fine. In the past year I've seen more criticism of Prophet and pointers to more classical methods that can handle those kinds of seasonalities, so I'm sure there's an extension of ARIMA that could work for you. For instance see [this post](https://www.reddit.com/r/MachineLearning/comments/wqrw8x/d_fool_me_once_shame_on_you_fool_me_twice_shame/).\n\nI've done some similar work in healthcare with mixed success -- I tried predicting patient satisfaction scores from features of their visit, like which doctor treated them, their diagnosis, whether they had a video call, whether a prescription was ordered, whether it was before or after a key feature launch, etc. I found it wasn't a very sensitive test though, because there's just so much variance in satisfaction scores and many patients just didn't fill out the survey. It was able to detect some major effects though, like patients are more satisfied when they get a prescription, or with certain doctors.\n\nI had much more success explaining visit efficiency metrics rather than satisfaction scores though.\n\nYou might also try propensity scores to make matched groups to use traditional statistical testing. I know some people that prefer that approach.\n\nSorry I don't have deep expertise in this area but hopefully it gives you some ideas or pointers",
      "body_html": "<div class=\"md\"><p>I&#39;ve used Prophet which handles those seasonalities fine. In the past year I&#39;ve seen more criticism of Prophet and pointers to more classical methods that can handle those kinds of seasonalities, so I&#39;m sure there&#39;s an extension of ARIMA that could work for you. For instance see <a href=\"https://www.reddit.com/r/MachineLearning/comments/wqrw8x/d_fool_me_once_shame_on_you_fool_me_twice_shame/\">this post</a>.</p>\n\n<p>I&#39;ve done some similar work in healthcare with mixed success -- I tried predicting patient satisfaction scores from features of their visit, like which doctor treated them, their diagnosis, whether they had a video call, whether a prescription was ordered, whether it was before or after a key feature launch, etc. I found it wasn&#39;t a very sensitive test though, because there&#39;s just so much variance in satisfaction scores and many patients just didn&#39;t fill out the survey. It was able to detect some major effects though, like patients are more satisfied when they get a prescription, or with certain doctors.</p>\n\n<p>I had much more success explaining visit efficiency metrics rather than satisfaction scores though.</p>\n\n<p>You might also try propensity scores to make matched groups to use traditional statistical testing. I know some people that prefer that approach.</p>\n\n<p>Sorry I don&#39;t have deep expertise in this area but hopefully it gives you some ideas or pointers</p>\n</div>",
      "created_utc": 1675674861.0,
      "score": 3,
      "ups": 3,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j7f2cgp/",
      "parent_id": "t1_j7crqhu",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-06T01:14:21"
    },
    {
      "id": "j7fzf0h",
      "author": "amrit_za",
      "body": "Databases would definitely help. Learning about the various ways data is stored, accessed, and the tradeoffs between them all is definitely a plus.",
      "body_html": "<div class=\"md\"><p>Databases would definitely help. Learning about the various ways data is stored, accessed, and the tradeoffs between them all is definitely a plus.</p>\n</div>",
      "created_utc": 1675695874.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j7fzf0h/",
      "parent_id": "t1_j7cyarn",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-06T07:04:34"
    },
    {
      "id": "j7mfxm3",
      "author": "trnka",
      "body": "That approach would work -- are you asking if there's a more efficient way? You could do something like train 48 x 2 times, then retain the best 24, train those another 2 times, retain the best 12, and so on. That way you're focusing your computational budget on the most promising models.\n\nThat said, if F1 is really close maybe the subtle differences aren't that significant. You could consider other factors, like if one model is smaller or uses inputs that are easier to get.",
      "body_html": "<div class=\"md\"><p>That approach would work -- are you asking if there&#39;s a more efficient way? You could do something like train 48 x 2 times, then retain the best 24, train those another 2 times, retain the best 12, and so on. That way you&#39;re focusing your computational budget on the most promising models.</p>\n\n<p>That said, if F1 is really close maybe the subtle differences aren&#39;t that significant. You could consider other factors, like if one model is smaller or uses inputs that are easier to get.</p>\n</div>",
      "created_utc": 1675805009.0,
      "score": 0,
      "ups": 0,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j7mfxm3/",
      "parent_id": "t1_j7ks0qo",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-07T13:23:29"
    },
    {
      "id": "j7ziarz",
      "author": null,
      "body": "OMG I saw a start-up doing pretty much **exactly** this recently but I just spent 15 minutes looking and I can't find it.. I remember they were talking about being able to input youtube playlists of content, then I think it would speech-to-text all the vids and you could query it via embeddings + GPT3",
      "body_html": "<div class=\"md\"><p>OMG I saw a start-up doing pretty much <strong>exactly</strong> this recently but I just spent 15 minutes looking and I can&#39;t find it.. I remember they were talking about being able to input youtube playlists of content, then I think it would speech-to-text all the vids and you could query it via embeddings + GPT3</p>\n</div>",
      "created_utc": 1676041071.0,
      "score": 2,
      "ups": 2,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j7ziarz/",
      "parent_id": "t1_j7v7sxg",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-10T06:57:51"
    },
    {
      "id": "j7xp0no",
      "author": "throwaway2676",
      "body": "I second this question and add on, how difficult is it to configure an external GPU to work with an M1 macbook?",
      "body_html": "<div class=\"md\"><p>I second this question and add on, how difficult is it to configure an external GPU to work with an M1 macbook?</p>\n</div>",
      "created_utc": 1675999481.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j7xp0no/",
      "parent_id": "t1_j7wbepy",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-09T19:24:41"
    },
    {
      "id": "j6fx4hp",
      "author": "Maleficent-Rate6479",
      "body": "If your response variable is sex then you meed to make it binary, otherwise I do not see a problem I think.",
      "body_html": "<div class=\"md\"><p>If your response variable is sex then you meed to make it binary, otherwise I do not see a problem I think.</p>\n</div>",
      "created_utc": 1675041664.0,
      "score": 2,
      "ups": 2,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j6fx4hp/",
      "parent_id": "t1_j6diy8w",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-01-29T17:21:04"
    },
    {
      "id": "j6ir4fh",
      "author": "qalis",
      "body": "Yes, you can. Variables in tabular learning are (in general) independent in terms of preprocessing. In fact, in most cases you will perform such different preprocessings, e.g. one-hot + SVD for high cardinality categorical variables, binary encoding for simple binary choices, integer encoding for ordinal variables.",
      "body_html": "<div class=\"md\"><p>Yes, you can. Variables in tabular learning are (in general) independent in terms of preprocessing. In fact, in most cases you will perform such different preprocessings, e.g. one-hot + SVD for high cardinality categorical variables, binary encoding for simple binary choices, integer encoding for ordinal variables.</p>\n</div>",
      "created_utc": 1675098141.0,
      "score": 2,
      "ups": 2,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j6ir4fh/",
      "parent_id": "t1_j6diy8w",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-01-30T09:02:21"
    },
    {
      "id": "j6iksqy",
      "author": null,
      "body": "Welp, it seemed like the problem was, that the inputs need to be defined as 2-dimensional with the sequence length as the first parameter. I thought one would give the RNN only 1 dimension of latent noise and get the sequence through reiterating it trough the RNN.",
      "body_html": "<div class=\"md\"><p>Welp, it seemed like the problem was, that the inputs need to be defined as 2-dimensional with the sequence length as the first parameter. I thought one would give the RNN only 1 dimension of latent noise and get the sequence through reiterating it trough the RNN.</p>\n</div>",
      "created_utc": 1675095712.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j6iksqy/",
      "parent_id": "t1_j6ibwq0",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-01-30T08:21:52"
    },
    {
      "id": "j6l3lzv",
      "author": "pronunciaai",
      "body": "Your suggested approach is the correct one and is called \"one-hot encoding\". Your thinking about why an embedding (single learned value) is inappropriate is also accurate.",
      "body_html": "<div class=\"md\"><p>Your suggested approach is the correct one and is called &quot;one-hot encoding&quot;. Your thinking about why an embedding (single learned value) is inappropriate is also accurate.</p>\n</div>",
      "created_utc": 1675131341.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j6l3lzv/",
      "parent_id": "t1_j6jjb43",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-01-30T18:15:41"
    },
    {
      "id": "j6olw50",
      "author": "SawtoothData",
      "body": "I don't know your application but, if lat/lon don't work very well, you could also try something like geohashing.\n\nSomething that's weird about longitude is that it loops. you might have weird things at the boundary. It's also odd that the distance between two points is also a function of latitude.",
      "body_html": "<div class=\"md\"><p>I don&#39;t know your application but, if lat/lon don&#39;t work very well, you could also try something like geohashing.</p>\n\n<p>Something that&#39;s weird about longitude is that it loops. you might have weird things at the boundary. It&#39;s also odd that the distance between two points is also a function of latitude.</p>\n</div>",
      "created_utc": 1675196426.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j6olw50/",
      "parent_id": "t1_j6lu39i",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-01-31T12:20:26"
    },
    {
      "id": "j7rasoq",
      "author": "theLanguageSprite",
      "body": "I think you may be confused about this subreddit.  Itâ€™s not for learning about machines, it about teaching machines to learn, like ai and robots and stuff",
      "body_html": "<div class=\"md\"><p>I think you may be confused about this subreddit.  Itâ€™s not for learning about machines, it about teaching machines to learn, like ai and robots and stuff</p>\n</div>",
      "created_utc": 1675891067.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j7rasoq/",
      "parent_id": "t1_j6og5xa",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-08T13:17:47"
    },
    {
      "id": "j6r92h1",
      "author": "trnka",
      "body": "I think it's more common to find a latent representation of the entire input space rather than a latent representation of a single input, so PCA or an autoencoder over all inputs might work. Or as you said, try to predict something from it and then use that latent representation for clustering.\n\nThat said, what problem are you trying to address? 150 values doesn't sound like a lot.",
      "body_html": "<div class=\"md\"><p>I think it&#39;s more common to find a latent representation of the entire input space rather than a latent representation of a single input, so PCA or an autoencoder over all inputs might work. Or as you said, try to predict something from it and then use that latent representation for clustering.</p>\n\n<p>That said, what problem are you trying to address? 150 values doesn&#39;t sound like a lot.</p>\n</div>",
      "created_utc": 1675243322.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j6r92h1/",
      "parent_id": "t1_j6onxem",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-01T01:22:02"
    },
    {
      "id": "j6r8rp2",
      "author": "trnka",
      "body": "Oh I'm in the midst of a job search myself -- job descriptions often seek PyTorch or TensorFlow experience, though I've seen slightly more that only mention PyTorch and not Tensorflow. Some mention Keras but not a lot. Many don't mention any frameworks at all.\n\nMy experience in industry was that things were slowly shifting from Tensorflow to PyTorch but almost nobody has the time to rewrite a codebase so legacy codebases are often stuck in the language and framework they started in.",
      "body_html": "<div class=\"md\"><p>Oh I&#39;m in the midst of a job search myself -- job descriptions often seek PyTorch or TensorFlow experience, though I&#39;ve seen slightly more that only mention PyTorch and not Tensorflow. Some mention Keras but not a lot. Many don&#39;t mention any frameworks at all.</p>\n\n<p>My experience in industry was that things were slowly shifting from Tensorflow to PyTorch but almost nobody has the time to rewrite a codebase so legacy codebases are often stuck in the language and framework they started in.</p>\n</div>",
      "created_utc": 1675243066.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j6r8rp2/",
      "parent_id": "t1_j6qr0qm",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-01T01:17:46"
    },
    {
      "id": "j6toelb",
      "author": "trnka",
      "body": "What's usually longest is when we need to create training data. In successful projects I think the slower ones took a month or two to get to the point of having enough high-quality data to build something useful. Though we often keep working to get more data and improve annotator agreement for a while, depending on the importance of the project.\n\nIn situations where the data already exists, I think the slower efforts took a couple weeks.\n\nFor unsuccessful projects, it's more about how much time we're willing to put into it. And sometimes I just need to set a project down for a bit before getting an idea, so I'm not sure how to count those projects. \n\nThe EDA part itself is usually fairly quick (days at worst).\n\nHope this helps!",
      "body_html": "<div class=\"md\"><p>What&#39;s usually longest is when we need to create training data. In successful projects I think the slower ones took a month or two to get to the point of having enough high-quality data to build something useful. Though we often keep working to get more data and improve annotator agreement for a while, depending on the importance of the project.</p>\n\n<p>In situations where the data already exists, I think the slower efforts took a couple weeks.</p>\n\n<p>For unsuccessful projects, it&#39;s more about how much time we&#39;re willing to put into it. And sometimes I just need to set a project down for a bit before getting an idea, so I&#39;m not sure how to count those projects. </p>\n\n<p>The EDA part itself is usually fairly quick (days at worst).</p>\n\n<p>Hope this helps!</p>\n</div>",
      "created_utc": 1675283545.0,
      "score": 2,
      "ups": 2,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j6toelb/",
      "parent_id": "t1_j6rr531",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-01T12:32:25"
    },
    {
      "id": "j6yrwle",
      "author": "MrOfficialCandy",
      "body": "Only if you enjoy it and want to be successful.  Otherwise, no.",
      "body_html": "<div class=\"md\"><p>Only if you enjoy it and want to be successful.  Otherwise, no.</p>\n</div>",
      "created_utc": 1675372015.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j6yrwle/",
      "parent_id": "t1_j6snpe3",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-02T13:06:55"
    },
    {
      "id": "j6veij8",
      "author": null,
      "body": "Iâ€™m not sure entirely what you mean when you describe your system but by the sounds of it you might be able to get away with just minimax or Monte Carlo tree search.\n\nIf youâ€™re determined to use a neutral network though, generally a single bigger model is going to give you better results than two separate models.",
      "body_html": "<div class=\"md\"><p>Iâ€™m not sure entirely what you mean when you describe your system but by the sounds of it you might be able to get away with just minimax or Monte Carlo tree search.</p>\n\n<p>If youâ€™re determined to use a neutral network though, generally a single bigger model is going to give you better results than two separate models.</p>\n</div>",
      "created_utc": 1675309488.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j6veij8/",
      "parent_id": "t1_j6snyau",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-01T19:44:48"
    },
    {
      "id": "j72r6kk",
      "author": null,
      "body": "Seems like you have a lot of covered ground, chances are you might already be good to go. Some notes:\n\n\\- I missed basic SQL knowledge in your experience. There are many MLE roles that don't need it, especially the more DL-oriented ones, but if you really want breadth you'd need to have more experience with it.  \n\\- Many openings will ask for the loathed leetcode/hackerank tests. If you have some spare time, consider grinding those a bit so you don't get caught off guard;  \n\\- If you're unsure about your overall skills in MLE, you could try self-assessing those in tests such as [this one](https://skills.workera.ai/for-individuals), which also points to relevant learning material if you want to fill in any gaps.  \n\\- Keep your resume sharp - some varnish in personal github projects and updated specs are always welcome if you want to passively check new opportunities.",
      "body_html": "<div class=\"md\"><p>Seems like you have a lot of covered ground, chances are you might already be good to go. Some notes:</p>\n\n<p>- I missed basic SQL knowledge in your experience. There are many MLE roles that don&#39;t need it, especially the more DL-oriented ones, but if you really want breadth you&#39;d need to have more experience with it.<br/>\n- Many openings will ask for the loathed leetcode/hackerank tests. If you have some spare time, consider grinding those a bit so you don&#39;t get caught off guard;<br/>\n- If you&#39;re unsure about your overall skills in MLE, you could try self-assessing those in tests such as <a href=\"https://skills.workera.ai/for-individuals\">this one</a>, which also points to relevant learning material if you want to fill in any gaps.<br/>\n- Keep your resume sharp - some varnish in personal github projects and updated specs are always welcome if you want to passively check new opportunities.</p>\n</div>",
      "created_utc": 1675445605.0,
      "score": 2,
      "ups": 2,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j72r6kk/",
      "parent_id": "t1_j6td3yy",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": true,
      "distinguished": null,
      "timestamp": "2023-02-03T09:33:25"
    },
    {
      "id": "j6yllxg",
      "author": "trnka",
      "body": "I don't see any problem in the code. Calling `.predict` doesn't re-train the model or anything. If the results are \"too good\", maybe it's an issue with how `df_train` and `df_test` were formed? Maybe there's significant overlap between them?\n\nAnother thing you can do to debug is to print out the model weights `y_pred_ridge1.coef_` and calculate the predictions by hand to understand what it's doing.\n\nAlso, I'm not sure what EVS is, but just to be sure -- you've tested that the EVS calculation is correct right?",
      "body_html": "<div class=\"md\"><p>I don&#39;t see any problem in the code. Calling <code>.predict</code> doesn&#39;t re-train the model or anything. If the results are &quot;too good&quot;, maybe it&#39;s an issue with how <code>df_train</code> and <code>df_test</code> were formed? Maybe there&#39;s significant overlap between them?</p>\n\n<p>Another thing you can do to debug is to print out the model weights <code>y_pred_ridge1.coef_</code> and calculate the predictions by hand to understand what it&#39;s doing.</p>\n\n<p>Also, I&#39;m not sure what EVS is, but just to be sure -- you&#39;ve tested that the EVS calculation is correct right?</p>\n</div>",
      "created_utc": 1675369675.0,
      "score": 2,
      "ups": 2,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j6yllxg/",
      "parent_id": "t1_j6ya5pq",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-02T12:27:55"
    },
    {
      "id": "j714m60",
      "author": "trnka",
      "body": "I'd say start with sklearn and then you'll have a solid baseline to compare against while you're building a model in Tensorflow or PyTroch. If you jump right into Tensorflow/PyTorch you might not have a good sense of whether your model is fitting reasonably or not.",
      "body_html": "<div class=\"md\"><p>I&#39;d say start with sklearn and then you&#39;ll have a solid baseline to compare against while you&#39;re building a model in Tensorflow or PyTroch. If you jump right into Tensorflow/PyTorch you might not have a good sense of whether your model is fitting reasonably or not.</p>\n</div>",
      "created_utc": 1675415065.0,
      "score": 2,
      "ups": 2,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j714m60/",
      "parent_id": "t1_j7052j5",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-03T01:04:25"
    },
    {
      "id": "j72pdnt",
      "author": null,
      "body": "Best case scenario you have slowdowns proportional to each experiment's load. Worst (and quite often), you'll crash either experiment (or both) since most will optimize for the largest VRAM usage (by e.g. increasing batch sizes and optimizing data throughput), and the 2nd issued experiment will eventually trigger OOM errors.\n\nSolutions vary from serving your IS over an MLOps platform (kubeflow, wandb, ray) to having basic lab etiquette and not being an ass when you know you could mess up other people's work and sync stuff via slack channels or whatever.",
      "body_html": "<div class=\"md\"><p>Best case scenario you have slowdowns proportional to each experiment&#39;s load. Worst (and quite often), you&#39;ll crash either experiment (or both) since most will optimize for the largest VRAM usage (by e.g. increasing batch sizes and optimizing data throughput), and the 2nd issued experiment will eventually trigger OOM errors.</p>\n\n<p>Solutions vary from serving your IS over an MLOps platform (kubeflow, wandb, ray) to having basic lab etiquette and not being an ass when you know you could mess up other people&#39;s work and sync stuff via slack channels or whatever.</p>\n</div>",
      "created_utc": 1675444930.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j72pdnt/",
      "parent_id": "t1_j71cswp",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-03T09:22:10"
    },
    {
      "id": "j73gljq",
      "author": "trnka",
      "body": "One rule of thumb is about 100 examples per class to see if there's potential to learn a model that's better than predicting the majority class. Another rule of thumb is that model performance grows about logarithmically with the amount of data, so every time you double your training data, you get X increase in performance.\n\nIf you're asking if you can get a model that's as good as training on 10 million rows, using just a subset, I can't give a direct answer. It depends on how complex the input space is (text, image, tabular, mixture) and how complex the true relationship between the inputs and output is. Once you've explored your data, I'd recommend training powers of 10 and plotting, like 100 examples, 1000, 10000, 100000, and so on. You should be able to fit a curve to tell you if it's worthwhile to train on the full set of 10 mil.\n\nHope this helps, and if anyone else has good rules of thumb let me know!",
      "body_html": "<div class=\"md\"><p>One rule of thumb is about 100 examples per class to see if there&#39;s potential to learn a model that&#39;s better than predicting the majority class. Another rule of thumb is that model performance grows about logarithmically with the amount of data, so every time you double your training data, you get X increase in performance.</p>\n\n<p>If you&#39;re asking if you can get a model that&#39;s as good as training on 10 million rows, using just a subset, I can&#39;t give a direct answer. It depends on how complex the input space is (text, image, tabular, mixture) and how complex the true relationship between the inputs and output is. Once you&#39;ve explored your data, I&#39;d recommend training powers of 10 and plotting, like 100 examples, 1000, 10000, 100000, and so on. You should be able to fit a curve to tell you if it&#39;s worthwhile to train on the full set of 10 mil.</p>\n\n<p>Hope this helps, and if anyone else has good rules of thumb let me know!</p>\n</div>",
      "created_utc": 1675455242.0,
      "score": 3,
      "ups": 3,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j73gljq/",
      "parent_id": "t1_j72prrx",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-03T12:14:02"
    },
    {
      "id": "j7bnj8r",
      "author": "trnka",
      "body": "Yes that's right - if a column has all the same values then it's not useful for the models and it's a good idea to drop those columns because they're slowing down training a little.\n\nIt sounds like a classification problem to me (DDoS or not). Usually I start with a random forest, because the default hyperparameters (aka settings) are usually reasonable for random forests. In my experience decision trees are more sensitive to hyperparameter tuning.",
      "body_html": "<div class=\"md\"><p>Yes that&#39;s right - if a column has all the same values then it&#39;s not useful for the models and it&#39;s a good idea to drop those columns because they&#39;re slowing down training a little.</p>\n\n<p>It sounds like a classification problem to me (DDoS or not). Usually I start with a random forest, because the default hyperparameters (aka settings) are usually reasonable for random forests. In my experience decision trees are more sensitive to hyperparameter tuning.</p>\n</div>",
      "created_utc": 1675614525.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j7bnj8r/",
      "parent_id": "t1_j781e3n",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-05T08:28:45"
    },
    {
      "id": "j7bmsb6",
      "author": "trnka",
      "body": "They aren't always the same in regression. Depending on your project, the performance metric could be mean absolute error, mean average percent error, weighted versions of those, or something more like explained variance.\n\nBut to your question, if someone wants to use MSE as their metric then they're really fortunate because MSE is differentiable and smooth so it can be used as the loss function. Most metrics can't be used as the loss function, so we're forced to use a proxy that is suitable as a loss function.",
      "body_html": "<div class=\"md\"><p>They aren&#39;t always the same in regression. Depending on your project, the performance metric could be mean absolute error, mean average percent error, weighted versions of those, or something more like explained variance.</p>\n\n<p>But to your question, if someone wants to use MSE as their metric then they&#39;re really fortunate because MSE is differentiable and smooth so it can be used as the loss function. Most metrics can&#39;t be used as the loss function, so we&#39;re forced to use a proxy that is suitable as a loss function.</p>\n</div>",
      "created_utc": 1675614212.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j7bmsb6/",
      "parent_id": "t1_j79s6s8",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-05T08:23:32"
    },
    {
      "id": "j7iipvm",
      "author": "theLanguageSprite",
      "body": "This sounds like a job for a Recurrent Neural Network (RNN).  If the pixels on screen as a human writes are measured at each time step, you can train the rnn on this data and it will output predictions for which pixels will need to be drawn in future time steps.  Sounds like a cool project, let me know if you want help with it",
      "body_html": "<div class=\"md\"><p>This sounds like a job for a Recurrent Neural Network (RNN).  If the pixels on screen as a human writes are measured at each time step, you can train the rnn on this data and it will output predictions for which pixels will need to be drawn in future time steps.  Sounds like a cool project, let me know if you want help with it</p>\n</div>",
      "created_utc": 1675731953.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j7iipvm/",
      "parent_id": "t1_j7f5pd6",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-06T17:05:53"
    },
    {
      "id": "j7iialj",
      "author": "theLanguageSprite",
      "body": "If I understand your question correctly, the answer depends on whether youâ€™ve saved the model weights.  If you have, you can restart the computer and load the model exactly where it left off",
      "body_html": "<div class=\"md\"><p>If I understand your question correctly, the answer depends on whether youâ€™ve saved the model weights.  If you have, you can restart the computer and load the model exactly where it left off</p>\n</div>",
      "created_utc": 1675731758.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j7iialj/",
      "parent_id": "t1_j7gglax",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-06T17:02:38"
    },
    {
      "id": "j7mf43r",
      "author": "trnka",
      "body": "By default, assume that the models can only be loaded in the language they were trained in.\n\nIf you're using machine learning framework that supports saving as [ONNX](https://onnx.ai/) that's more portable across languages. Likewise, Tensorflow has a format that's portable across a few platforms. Other frameworks may have similar support but it's not guaranteed.\n\nEfficiency depends on how complicated of a model you use. You could probably have a snake model that's <1kb that can run a prediction in <1ns. It's possible that such a model might be too simple to be good at snake though. In general, we rarely know ahead of time how complex the model will need to be to solve the problem.\n\nIf you're asking about efficiency of the ML libraries though, those are highly optimized.",
      "body_html": "<div class=\"md\"><p>By default, assume that the models can only be loaded in the language they were trained in.</p>\n\n<p>If you&#39;re using machine learning framework that supports saving as <a href=\"https://onnx.ai/\">ONNX</a> that&#39;s more portable across languages. Likewise, Tensorflow has a format that&#39;s portable across a few platforms. Other frameworks may have similar support but it&#39;s not guaranteed.</p>\n\n<p>Efficiency depends on how complicated of a model you use. You could probably have a snake model that&#39;s &lt;1kb that can run a prediction in &lt;1ns. It&#39;s possible that such a model might be too simple to be good at snake though. In general, we rarely know ahead of time how complex the model will need to be to solve the problem.</p>\n\n<p>If you&#39;re asking about efficiency of the ML libraries though, those are highly optimized.</p>\n</div>",
      "created_utc": 1675804700.0,
      "score": 0,
      "ups": 0,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j7mf43r/",
      "parent_id": "t1_j7kwngd",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-07T13:18:20"
    },
    {
      "id": "j7r9wy3",
      "author": "theLanguageSprite",
      "body": "Yeah, python scripts can be compiled into executables, and Iâ€™m pretty sure the weights file can be bundled in so itâ€™s all a single exe.  Iâ€™m not sure what you mean by portable or efficient, but how fast it runs is a feature of the computer you run it on.  Fortunately models are always faster to deploy than to train, so if you just want to send someone your snake ai they shouldnâ€™t need a fancy computer or graphics card to run it",
      "body_html": "<div class=\"md\"><p>Yeah, python scripts can be compiled into executables, and Iâ€™m pretty sure the weights file can be bundled in so itâ€™s all a single exe.  Iâ€™m not sure what you mean by portable or efficient, but how fast it runs is a feature of the computer you run it on.  Fortunately models are always faster to deploy than to train, so if you just want to send someone your snake ai they shouldnâ€™t need a fancy computer or graphics card to run it</p>\n</div>",
      "created_utc": 1675890744.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j7r9wy3/",
      "parent_id": "t1_j7kwngd",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-08T13:12:24"
    },
    {
      "id": "j7osnjb",
      "author": "trnka",
      "body": "It's a good idea to try out a few different models, especially to catch anything unusual like poorly configured hyperparameters, or models that are generally better or worse at certain kinds of problems.\n\nFrom an interpretability perspective, combining multiple models may filter out noisy features a little better but it also makes the explanation more complex though.",
      "body_html": "<div class=\"md\"><p>It&#39;s a good idea to try out a few different models, especially to catch anything unusual like poorly configured hyperparameters, or models that are generally better or worse at certain kinds of problems.</p>\n\n<p>From an interpretability perspective, combining multiple models may filter out noisy features a little better but it also makes the explanation more complex though.</p>\n</div>",
      "created_utc": 1675849466.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j7osnjb/",
      "parent_id": "t1_j7mmdi0",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-08T01:44:26"
    },
    {
      "id": "j7pmdwu",
      "author": "zbqv",
      "body": "David Silverâ€™s course",
      "body_html": "<div class=\"md\"><p>David Silverâ€™s course</p>\n</div>",
      "created_utc": 1675867784.0,
      "score": 5,
      "ups": 5,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j7pmdwu/",
      "parent_id": "t1_j7mslqh",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-08T06:49:44"
    },
    {
      "id": "j7ot8pc",
      "author": "trnka",
      "body": "I haven't experienced limits on the output space. Secondhand I've seen problems in language modeling with large vocabularies but only because it's slow.\n\nI've done classifiers of \\~150 binary outputs, and if we'd needed to do 300 that would've been fine. When looking at the amount of data needed it was fine to think about it like 150 separate classifiers. Like say if one output only had 10 positive examples that often wasn't enough to learn much useful. Maybe if we had tens of thousands of outputs it could've been a computational bottleneck.\n\nMulti-task learning did help form a useful latent representation though, so we needed fewer labeled examples when adding new outputs (compared to a model trained only for that one output). It also tended to denoise our labels a bit too.\n\nThe one challenge we had with multi-task was that we needed to scale up the number of params in the network to be able to support that many outputs. If we didn't, they'd \"compete\" for influence in the hidden representation, which led to underfitting and also led to the model retraining differently each time.\n\nHope this helps -- I haven't heard of any limits like the kind you're describing.",
      "body_html": "<div class=\"md\"><p>I haven&#39;t experienced limits on the output space. Secondhand I&#39;ve seen problems in language modeling with large vocabularies but only because it&#39;s slow.</p>\n\n<p>I&#39;ve done classifiers of ~150 binary outputs, and if we&#39;d needed to do 300 that would&#39;ve been fine. When looking at the amount of data needed it was fine to think about it like 150 separate classifiers. Like say if one output only had 10 positive examples that often wasn&#39;t enough to learn much useful. Maybe if we had tens of thousands of outputs it could&#39;ve been a computational bottleneck.</p>\n\n<p>Multi-task learning did help form a useful latent representation though, so we needed fewer labeled examples when adding new outputs (compared to a model trained only for that one output). It also tended to denoise our labels a bit too.</p>\n\n<p>The one challenge we had with multi-task was that we needed to scale up the number of params in the network to be able to support that many outputs. If we didn&#39;t, they&#39;d &quot;compete&quot; for influence in the hidden representation, which led to underfitting and also led to the model retraining differently each time.</p>\n\n<p>Hope this helps -- I haven&#39;t heard of any limits like the kind you&#39;re describing.</p>\n</div>",
      "created_utc": 1675849978.0,
      "score": 2,
      "ups": 2,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j7ot8pc/",
      "parent_id": "t1_j7n4z38",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-08T01:52:58"
    },
    {
      "id": "j83cull",
      "author": "trnka",
      "body": "Yeah I was. If I remember their publications were interesting, and Jeopardy made me realize that you can get pretty far by searching against a database like Wikipedia.\n\nMy interpretation of Watson is that maybe it started as one technology, but quickly became an umbrella term for a certain kind of IBM consulting not any particular piece of software. It seemed that the term \"Watson\" was coopted as a marketing term to drive consulting contracts, and those contracts didn't have a good track record from the people I talked to.\n\nI wasn't in IBM so I don't know what actually happened, that's just what I saw in the news, blogs, and from talking to people that had run-ins with Watson projects.",
      "body_html": "<div class=\"md\"><p>Yeah I was. If I remember their publications were interesting, and Jeopardy made me realize that you can get pretty far by searching against a database like Wikipedia.</p>\n\n<p>My interpretation of Watson is that maybe it started as one technology, but quickly became an umbrella term for a certain kind of IBM consulting not any particular piece of software. It seemed that the term &quot;Watson&quot; was coopted as a marketing term to drive consulting contracts, and those contracts didn&#39;t have a good track record from the people I talked to.</p>\n\n<p>I wasn&#39;t in IBM so I don&#39;t know what actually happened, that&#39;s just what I saw in the news, blogs, and from talking to people that had run-ins with Watson projects.</p>\n</div>",
      "created_utc": 1676107069.0,
      "score": 2,
      "ups": 2,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j83cull/",
      "parent_id": "t1_j80wxxt",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-11T01:17:49"
    },
    {
      "id": "j892g0u",
      "author": "redditneight",
      "body": "I read an article about the demise of Watson, which kind of answers your second half of your question. \n\nWhat Ever Happened to IBMâ€™s Watson? https://nyti.ms/36EFq0K\n\nTldr; they spent all their money acquiring patient medical data, and then they weren't able to turn that into something that really helped doctors.",
      "body_html": "<div class=\"md\"><p>I read an article about the demise of Watson, which kind of answers your second half of your question. </p>\n\n<p>What Ever Happened to IBMâ€™s Watson? <a href=\"https://nyti.ms/36EFq0K\">https://nyti.ms/36EFq0K</a></p>\n\n<p>Tldr; they spent all their money acquiring patient medical data, and then they weren&#39;t able to turn that into something that really helped doctors.</p>\n</div>",
      "created_utc": 1676217236.0,
      "score": 2,
      "ups": 2,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j892g0u/",
      "parent_id": "t1_j80wxxt",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-12T07:53:56"
    },
    {
      "id": "j85ac5u",
      "author": "trnka",
      "body": "For the machine learning part, I'd recommend starting with a tutorial on a standard, small data set like 20 newsgroups. Here's [one such guide](https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html) for scikit-learn in Python.\n\nFor the other parts, I haven't worked in those areas in quite a while, but Google has an API you can use for searching if I remember right. I'm not sure if that API has the \"card\" info that Google shows for movies though. If not, you could search in IMDB and take the first page or two.\n\nExtracting the content from IMDB might be a pain. I'm a bit outdated there but generally I'd use a library like beautifulsoup with an xpath selector to extract the part of the webpage I wanted. You can figure out the xpath selector you need in Chrome by right clicking the part of the page you want and inspecting the element -- there's a helper in the dev tools\n\nSorry I haven't done web scraping in a couple years so I don't know what's best these days",
      "body_html": "<div class=\"md\"><p>For the machine learning part, I&#39;d recommend starting with a tutorial on a standard, small data set like 20 newsgroups. Here&#39;s <a href=\"https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html\">one such guide</a> for scikit-learn in Python.</p>\n\n<p>For the other parts, I haven&#39;t worked in those areas in quite a while, but Google has an API you can use for searching if I remember right. I&#39;m not sure if that API has the &quot;card&quot; info that Google shows for movies though. If not, you could search in IMDB and take the first page or two.</p>\n\n<p>Extracting the content from IMDB might be a pain. I&#39;m a bit outdated there but generally I&#39;d use a library like beautifulsoup with an xpath selector to extract the part of the webpage I wanted. You can figure out the xpath selector you need in Chrome by right clicking the part of the page you want and inspecting the element -- there&#39;s a helper in the dev tools</p>\n\n<p>Sorry I haven&#39;t done web scraping in a couple years so I don&#39;t know what&#39;s best these days</p>\n</div>",
      "created_utc": 1676142236.0,
      "score": 2,
      "ups": 2,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j85ac5u/",
      "parent_id": "t1_j84y2dg",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-11T11:03:56"
    },
    {
      "id": "j7cv7zo",
      "author": "krazyking",
      "body": "I appreciate you responding, thank you",
      "body_html": "<div class=\"md\"><p>I appreciate you responding, thank you</p>\n</div>",
      "created_utc": 1675632106.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j7cv7zo/",
      "parent_id": "t1_j6ymh8j",
      "depth": 2,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-05T13:21:46"
    },
    {
      "id": "j7iing7",
      "author": "Translate_pro",
      "body": "Thank you!",
      "body_html": "<div class=\"md\"><p>Thank you!</p>\n</div>",
      "created_utc": 1675731922.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j7iing7/",
      "parent_id": "t1_j7f2cgp",
      "depth": 2,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-06T17:05:22"
    },
    {
      "id": "j81jnhc",
      "author": "throweralal",
      "body": "Interesting, I'll look more into it as well then, thanks!",
      "body_html": "<div class=\"md\"><p>Interesting, I&#39;ll look more into it as well then, thanks!</p>\n</div>",
      "created_utc": 1676070141.0,
      "score": 2,
      "ups": 2,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j81jnhc/",
      "parent_id": "t1_j7ziarz",
      "depth": 2,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-10T15:02:21"
    },
    {
      "id": "j7z0c43",
      "author": "Zei33",
      "body": "Just a thought, but why don't you just SSH into a dedicated computer connected to the GPU from your Macbook?",
      "body_html": "<div class=\"md\"><p>Just a thought, but why don&#39;t you just SSH into a dedicated computer connected to the GPU from your Macbook?</p>\n</div>",
      "created_utc": 1676032331.0,
      "score": 3,
      "ups": 3,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j7z0c43/",
      "parent_id": "t1_j7xp0no",
      "depth": 2,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-10T04:32:11"
    },
    {
      "id": "j6otii7",
      "author": "TheCoconutTree",
      "body": "That's a good point about longitude looping. I hadn't thought about that. I'm designing a classifier, and would like to include geographic location as one of the input variables.",
      "body_html": "<div class=\"md\"><p>That&#39;s a good point about longitude looping. I hadn&#39;t thought about that. I&#39;m designing a classifier, and would like to include geographic location as one of the input variables.</p>\n</div>",
      "created_utc": 1675199241.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j6otii7/",
      "parent_id": "t1_j6olw50",
      "depth": 2,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-01-31T13:07:21"
    },
    {
      "id": "j6tua0p",
      "author": "ockham_blade",
      "body": "thank you. I know what you mean, however I would prefer to leave the other variables unchanged, and only embed the one-hot encoded ones (that all come from the same single feature).\n\ndo you have any recommendations? thanks!",
      "body_html": "<div class=\"md\"><p>thank you. I know what you mean, however I would prefer to leave the other variables unchanged, and only embed the one-hot encoded ones (that all come from the same single feature).</p>\n\n<p>do you have any recommendations? thanks!</p>\n</div>",
      "created_utc": 1675285698.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j6tua0p/",
      "parent_id": "t1_j6r92h1",
      "depth": 2,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-01T13:08:18"
    },
    {
      "id": "j6vfssy",
      "author": "Oripy",
      "body": "Thank you for the reply!\nI already have a working AI using MCTS, I just want to try the NN route to learn and see if the result would be better.\nThank you for the advice, I will use only one network.",
      "body_html": "<div class=\"md\"><p>Thank you for the reply!\nI already have a working AI using MCTS, I just want to try the NN route to learn and see if the result would be better.\nThank you for the advice, I will use only one network.</p>\n</div>",
      "created_utc": 1675310100.0,
      "score": 2,
      "ups": 2,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j6vfssy/",
      "parent_id": "t1_j6veij8",
      "depth": 2,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-01T19:55:00"
    },
    {
      "id": "j6yp934",
      "author": "tosleepinacroissant",
      "body": "thank you!! I will try that ... I think it is and overlap in the target columns and feature columns :( EVS is the explained variance score and I took it from sklearn.metrics (I trust them lol)!",
      "body_html": "<div class=\"md\"><p>thank you!! I will try that ... I think it is and overlap in the target columns and feature columns :( EVS is the explained variance score and I took it from sklearn.metrics (I trust them lol)!</p>\n</div>",
      "created_utc": 1675371037.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j6yp934/",
      "parent_id": "t1_j6yllxg",
      "depth": 2,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-02T12:50:37"
    },
    {
      "id": "j73tc6h",
      "author": "TheCoconutTree",
      "body": "Very helpful, thanks. My particular use case is tabular data with some converted location and one-hot encodings. I've gotten some useful suggestions from the forum for dealing with the latter two.",
      "body_html": "<div class=\"md\"><p>Very helpful, thanks. My particular use case is tabular data with some converted location and one-hot encodings. I&#39;ve gotten some useful suggestions from the forum for dealing with the latter two.</p>\n</div>",
      "created_utc": 1675460134.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j73tc6h/",
      "parent_id": "t1_j73gljq",
      "depth": 2,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-03T13:35:34"
    },
    {
      "id": "j7bt3eb",
      "author": "raikone51",
      "body": "thank you so much for the kind reply, \n\n&#x200B;\n\nWhat I should look more in my dataset before the training? I don't have missing values, and I will drop the 0 columns.\n\ntks a lot",
      "body_html": "<div class=\"md\"><p>thank you so much for the kind reply, </p>\n\n<p>&#x200B;</p>\n\n<p>What I should look more in my dataset before the training? I don&#39;t have missing values, and I will drop the 0 columns.</p>\n\n<p>tks a lot</p>\n</div>",
      "created_utc": 1675616794.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j7bt3eb/",
      "parent_id": "t1_j7bnj8r",
      "depth": 2,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-05T09:06:34"
    },
    {
      "id": "j7k3v8g",
      "author": "MercyFive",
      "body": "Thanks for your response and offer. I will look into RNN. I will dm you for collaboration.",
      "body_html": "<div class=\"md\"><p>Thanks for your response and offer. I will look into RNN. I will dm you for collaboration.</p>\n</div>",
      "created_utc": 1675767924.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j7k3v8g/",
      "parent_id": "t1_j7iipvm",
      "depth": 2,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-07T03:05:24"
    },
    {
      "id": "j7kyuff",
      "author": "sanskar_negi",
      "body": "I am asking, like we can't use same data to evaluate our model on different parameters, so can we use same data after restarting IDE(notebook) or pc..?",
      "body_html": "<div class=\"md\"><p>I am asking, like we can&#39;t use same data to evaluate our model on different parameters, so can we use same data after restarting IDE(notebook) or pc..?</p>\n</div>",
      "created_utc": 1675784435.0,
      "score": 0,
      "ups": 0,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j7kyuff/",
      "parent_id": "t1_j7iialj",
      "depth": 2,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-07T07:40:35"
    },
    {
      "id": "j85bc8h",
      "author": "Severe_Sweet_862",
      "body": "I have an xls file with all the movie names and at first I had the thought of automating the process of googling for each entry and then pick up the specific part of the page that lists the genre, scraping it and boom we're done. The problem is, Google doesn't provide definitive answers if you ask the genre of a movie. It's only as smart as the source it's feeding off of and if the movie I'm searching for is really obscure, it won't give me a straight answer.\n\nI'm hoping to train a model to 'learn' all the genres and predict which categories the movie I want to search for belongs in, instead of searching for them one by one on google.\n\nI think using the IMDB api would be useful in my case but it's owned by amazon and I think their API is paid.",
      "body_html": "<div class=\"md\"><p>I have an xls file with all the movie names and at first I had the thought of automating the process of googling for each entry and then pick up the specific part of the page that lists the genre, scraping it and boom we&#39;re done. The problem is, Google doesn&#39;t provide definitive answers if you ask the genre of a movie. It&#39;s only as smart as the source it&#39;s feeding off of and if the movie I&#39;m searching for is really obscure, it won&#39;t give me a straight answer.</p>\n\n<p>I&#39;m hoping to train a model to &#39;learn&#39; all the genres and predict which categories the movie I want to search for belongs in, instead of searching for them one by one on google.</p>\n\n<p>I think using the IMDB api would be useful in my case but it&#39;s owned by amazon and I think their API is paid.</p>\n</div>",
      "created_utc": 1676142658.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j85bc8h/",
      "parent_id": "t1_j85ac5u",
      "depth": 2,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-11T11:10:58"
    },
    {
      "id": "j8ph920",
      "author": null,
      "body": "This wasn't it, but I found a load of startups this morning that do \"ask your documents anything\" type interfaces\n\nThis one appears to support audio [https://mixpeek.com/](https://mixpeek.com/)\n\nA bunch more:\n\nhttps://www.heypal.chat/\nhttps://www.notably.ai/\nhttps://www.filechat.io/\nhttps://www.chatbase.co/\nhttps://slite.com/ask",
      "body_html": "<div class=\"md\"><p>This wasn&#39;t it, but I found a load of startups this morning that do &quot;ask your documents anything&quot; type interfaces</p>\n\n<p>This one appears to support audio <a href=\"https://mixpeek.com/\">https://mixpeek.com/</a></p>\n\n<p>A bunch more:</p>\n\n<p><a href=\"https://www.heypal.chat/\">https://www.heypal.chat/</a>\n<a href=\"https://www.notably.ai/\">https://www.notably.ai/</a>\n<a href=\"https://www.filechat.io/\">https://www.filechat.io/</a>\n<a href=\"https://www.chatbase.co/\">https://www.chatbase.co/</a>\n<a href=\"https://slite.com/ask\">https://slite.com/ask</a></p>\n</div>",
      "created_utc": 1676507623.0,
      "score": 2,
      "ups": 2,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j8ph920/",
      "parent_id": "t1_j81jnhc",
      "depth": 3,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-15T16:33:43"
    },
    {
      "id": "j82xxgr",
      "author": "itsyourboiirow",
      "body": "This is what I do with VSCode remote and it's the best.",
      "body_html": "<div class=\"md\"><p>This is what I do with VSCode remote and it&#39;s the best.</p>\n</div>",
      "created_utc": 1676095465.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j82xxgr/",
      "parent_id": "t1_j7z0c43",
      "depth": 3,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-10T22:04:25"
    },
    {
      "id": "j87becc",
      "author": "throwaway2676",
      "body": "Well, would that be as cheap as the external GPU by itself?  I only have the Macbook at the moment.",
      "body_html": "<div class=\"md\"><p>Well, would that be as cheap as the external GPU by itself?  I only have the Macbook at the moment.</p>\n</div>",
      "created_utc": 1676175812.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j87becc/",
      "parent_id": "t1_j7z0c43",
      "depth": 3,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-11T20:23:32"
    },
    {
      "id": "j6w6hwv",
      "author": "trnka",
      "body": "If the reason you want an embedding is because it's too slow with 150 features, hashing before one-hot encoding can be effective.\n\nIf the reason is that you want a more \"smooth\" way of measuring similarity or distance for clustering, maybe there's other information about the 150 values? If they're strings like \"acute upper respiratory infection\", you could try a unigram or bigram tfidf representation rather than one-hot, which would allow for partial similarity with \"severe respiratory infection\". Alternatively, if there's other information about those values stored elsewhere like a description you could use with ngrams or a sentence/document embedding of those to get smoother representations.\n\nKinda depends on the problem you're having though.",
      "body_html": "<div class=\"md\"><p>If the reason you want an embedding is because it&#39;s too slow with 150 features, hashing before one-hot encoding can be effective.</p>\n\n<p>If the reason is that you want a more &quot;smooth&quot; way of measuring similarity or distance for clustering, maybe there&#39;s other information about the 150 values? If they&#39;re strings like &quot;acute upper respiratory infection&quot;, you could try a unigram or bigram tfidf representation rather than one-hot, which would allow for partial similarity with &quot;severe respiratory infection&quot;. Alternatively, if there&#39;s other information about those values stored elsewhere like a description you could use with ngrams or a sentence/document embedding of those to get smoother representations.</p>\n\n<p>Kinda depends on the problem you&#39;re having though.</p>\n</div>",
      "created_utc": 1675328002.0,
      "score": 2,
      "ups": 2,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j6w6hwv/",
      "parent_id": "t1_j6tua0p",
      "depth": 3,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-02T00:53:22"
    },
    {
      "id": "j7c3u42",
      "author": "raikone51",
      "body": "just adding I don't have duplicate values, missing values, or corrupted data",
      "body_html": "<div class=\"md\"><p>just adding I don&#39;t have duplicate values, missing values, or corrupted data</p>\n</div>",
      "created_utc": 1675621072.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j7c3u42/",
      "parent_id": "t1_j7bt3eb",
      "depth": 3,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-05T10:17:52"
    },
    {
      "id": "j852oko",
      "author": "Zei33",
      "body": "That's pretty much how I've done it forever. VS code with SFTP (remote) extension is what I use on windows along with ubuntu subsystem for SSH. Then on my Macbook I use Nova SFTP and iterm2 to SSH. Basically, I can access all of my servers (EC2 instances and databases) from either computer.",
      "body_html": "<div class=\"md\"><p>That&#39;s pretty much how I&#39;ve done it forever. VS code with SFTP (remote) extension is what I use on windows along with ubuntu subsystem for SSH. Then on my Macbook I use Nova SFTP and iterm2 to SSH. Basically, I can access all of my servers (EC2 instances and databases) from either computer.</p>\n</div>",
      "created_utc": 1676139051.0,
      "score": 2,
      "ups": 2,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j852oko/",
      "parent_id": "t1_j82xxgr",
      "depth": 4,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-11T10:10:51"
    },
    {
      "id": "j87bvhq",
      "author": "Zei33",
      "body": "You'd basically have a computer with a GPU in it that actually runs the code. You're just remotely accessing it and editing it from the Macbook. Get iterm2 and learn how to use SSH and get a code editor that can do SFTP. I'm assuming you know how to setup and use Ubuntu to run your program on the main computer with the GPU? Ubuntu works perfectly with basically everything but C#, but you can use MonoDevelop to get around that if it's your preferred language.\n\nIf you need to build a computer to connect the GPU to, you should be able to do it on the cheap. You don't need a particularly expensive motherboard, and the CPU doesn't need to be blazing fast for what you want to do. You will probably want a certain amount of RAM and SSD space for the training materials. Basically, you just need a shell of a computer that can run Ubuntu and hold the GPU. Also, I recommend only installing command line Ubuntu, not the full desktop version. Since you'll be doing everything from your Macbook, you really don't need the Ubuntu user interface. In this setup, the macbook acts as the interface through SSH and SFTP.",
      "body_html": "<div class=\"md\"><p>You&#39;d basically have a computer with a GPU in it that actually runs the code. You&#39;re just remotely accessing it and editing it from the Macbook. Get iterm2 and learn how to use SSH and get a code editor that can do SFTP. I&#39;m assuming you know how to setup and use Ubuntu to run your program on the main computer with the GPU? Ubuntu works perfectly with basically everything but C#, but you can use MonoDevelop to get around that if it&#39;s your preferred language.</p>\n\n<p>If you need to build a computer to connect the GPU to, you should be able to do it on the cheap. You don&#39;t need a particularly expensive motherboard, and the CPU doesn&#39;t need to be blazing fast for what you want to do. You will probably want a certain amount of RAM and SSD space for the training materials. Basically, you just need a shell of a computer that can run Ubuntu and hold the GPU. Also, I recommend only installing command line Ubuntu, not the full desktop version. Since you&#39;ll be doing everything from your Macbook, you really don&#39;t need the Ubuntu user interface. In this setup, the macbook acts as the interface through SSH and SFTP.</p>\n</div>",
      "created_utc": 1676176077.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j87bvhq/",
      "parent_id": "t1_j87becc",
      "depth": 4,
      "is_submitter": false,
      "stickied": false,
      "edited": true,
      "distinguished": null,
      "timestamp": "2023-02-11T20:27:57"
    },
    {
      "id": "j7ciwxq",
      "author": "trnka",
      "body": "If you're comfortable with pandas, I'd recommend running DataFrame.corr to see which features correlate with the output and which feature correlate with one another.\n\nBeyond that, I think the random forest in scikit-learn support numeric inputs as well as categorical inputs. With other models you'd need to one-hot encode the categorical inputs. \n\nSo you're pretty much ready to train a model. I'd recommend using DummyClassifier or DummyRegressor as a baseline to compare against, so that you know whether your random forest is actually learning something interesting.",
      "body_html": "<div class=\"md\"><p>If you&#39;re comfortable with pandas, I&#39;d recommend running DataFrame.corr to see which features correlate with the output and which feature correlate with one another.</p>\n\n<p>Beyond that, I think the random forest in scikit-learn support numeric inputs as well as categorical inputs. With other models you&#39;d need to one-hot encode the categorical inputs. </p>\n\n<p>So you&#39;re pretty much ready to train a model. I&#39;d recommend using DummyClassifier or DummyRegressor as a baseline to compare against, so that you know whether your random forest is actually learning something interesting.</p>\n</div>",
      "created_utc": 1675627158.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j7ciwxq/",
      "parent_id": "t1_j7c3u42",
      "depth": 4,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-05T11:59:18"
    },
    {
      "id": "j7clxtp",
      "author": "raikone51",
      "body": ">models you'd need to one-hot encode the categorical inpu\n\nTHank you promise, my last question, \n\nI was reading and found that I should add a target column in my dataset that represents an attack or not. (1 or 0), this is correct ?\n\nThank you promise, my last question, aset ? all lines ? Because this should be a problem, for my legit traffic I have a fixed ip, for my attacks I have random Ips..",
      "body_html": "<div class=\"md\"><blockquote>\n<p>models you&#39;d need to one-hot encode the categorical inpu</p>\n</blockquote>\n\n<p>THank you promise, my last question, </p>\n\n<p>I was reading and found that I should add a target column in my dataset that represents an attack or not. (1 or 0), this is correct ?</p>\n\n<p>Thank you promise, my last question, aset ? all lines ? Because this should be a problem, for my legit traffic I have a fixed ip, for my attacks I have random Ips..</p>\n</div>",
      "created_utc": 1675628368.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j7clxtp/",
      "parent_id": "t1_j7ciwxq",
      "depth": 5,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-05T12:19:28"
    },
    {
      "id": "j7crmg0",
      "author": "trnka",
      "body": "Yep you'll need that column. \n\nIf the ip address would give it away I'd suggest not including ip to your model.",
      "body_html": "<div class=\"md\"><p>Yep you&#39;ll need that column. </p>\n\n<p>If the ip address would give it away I&#39;d suggest not including ip to your model.</p>\n</div>",
      "created_utc": 1675630649.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/j7crmg0/",
      "parent_id": "t1_j7clxtp",
      "depth": 6,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-05T12:57:29"
    },
    {
      "id": "jbpkc9s",
      "author": "raikone51",
      "body": "Hey I hope you are doing fine, and sorry to bother you.\n\nJust one question I did some things in pandas and got  a correlation for my features, I was think about eliminate feature that has a correlation 0.95 negative or positive. would make sense?\n\nAnd for example if I have feature A x B both have   a correlation with each other 0.95 which one should I remove ? the one that has a weaker correlation with my target variable?\n\naditionaly, would you recomend any matirial about this topic ?",
      "body_html": "<div class=\"md\"><p>Hey I hope you are doing fine, and sorry to bother you.</p>\n\n<p>Just one question I did some things in pandas and got  a correlation for my features, I was think about eliminate feature that has a correlation 0.95 negative or positive. would make sense?</p>\n\n<p>And for example if I have feature A x B both have   a correlation with each other 0.95 which one should I remove ? the one that has a weaker correlation with my target variable?</p>\n\n<p>aditionaly, would you recomend any matirial about this topic ?</p>\n</div>",
      "created_utc": 1678475074.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/jbpkc9s/",
      "parent_id": "t1_j7crmg0",
      "depth": 7,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-10T11:04:34"
    },
    {
      "id": "jbpr4b7",
      "author": "trnka",
      "body": "It's no trouble. If you have features with over 0.95 correlation with the output, it's worth thinking about whether that feature is unintentionally leaking information about the output. Otherwise, be happy that you've found a strong predictor!\n\nFor features that are correlated with each other, it's usually fine to include both of them. Most machine learning models will handle that just fine. The main reason I'd remove a near-duplicate feature would be to speed up training. If they're only 95% correlated, then there may be a small benefit to including both also.",
      "body_html": "<div class=\"md\"><p>It&#39;s no trouble. If you have features with over 0.95 correlation with the output, it&#39;s worth thinking about whether that feature is unintentionally leaking information about the output. Otherwise, be happy that you&#39;ve found a strong predictor!</p>\n\n<p>For features that are correlated with each other, it&#39;s usually fine to include both of them. Most machine learning models will handle that just fine. The main reason I&#39;d remove a near-duplicate feature would be to speed up training. If they&#39;re only 95% correlated, then there may be a small benefit to including both also.</p>\n</div>",
      "created_utc": 1678477722.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/jbpr4b7/",
      "parent_id": "t1_jbpkc9s",
      "depth": 8,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-10T11:48:42"
    },
    {
      "id": "jbu1lqf",
      "author": "raikone51",
      "body": "Thank you again for the kind reply,\n\nIf I understood you correctly , I dont need to remove because this wont affect my model (possible a decision tree).\n\nBut for example this features, they have a strong correlation:\n\n    subflow_fwd_byts x totlen_fwd_pkts 1.0\nsubflow_fwd_byts x fwd_pkt_len_std 0.9626\nsubflow_fwd_byts x bwd_pkt_len_max 0.9812\nsubflow_fwd_byts x pkt_len_max 0.9815\n\n\nAnd this is the correlation with the target variable:\n\n    subflow_fwd_byts     0.158648\n    totlen_fwd_pkts      0.158648\n    fwd_pkt_len_std      0.167938\n    bwd_pkt_len_max      0.225195\n    pkt_len_max          0.231735\n\nCan I remove subflow\\_fwd\\_byts  or totlen\\_fwd\\_pkts or fwd\\_pkt\\_len\\_std , because they have a weaker correlation with the target variable ?\n\nI just trying to reduce my dataset in total now I have 67 features :)\n\nTks again",
      "body_html": "<div class=\"md\"><p>Thank you again for the kind reply,</p>\n\n<p>If I understood you correctly , I dont need to remove because this wont affect my model (possible a decision tree).</p>\n\n<p>But for example this features, they have a strong correlation:</p>\n\n<pre><code>subflow_fwd_byts x totlen_fwd_pkts 1.0\n</code></pre>\n\n<p>subflow_fwd_byts x fwd_pkt_len_std 0.9626\nsubflow_fwd_byts x bwd_pkt_len_max 0.9812\nsubflow_fwd_byts x pkt_len_max 0.9815</p>\n\n<p>And this is the correlation with the target variable:</p>\n\n<pre><code>subflow_fwd_byts     0.158648\ntotlen_fwd_pkts      0.158648\nfwd_pkt_len_std      0.167938\nbwd_pkt_len_max      0.225195\npkt_len_max          0.231735\n</code></pre>\n\n<p>Can I remove subflow_fwd_byts  or totlen_fwd_pkts or fwd_pkt_len_std , because they have a weaker correlation with the target variable ?</p>\n\n<p>I just trying to reduce my dataset in total now I have 67 features :)</p>\n\n<p>Tks again</p>\n</div>",
      "created_utc": 1678559842.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/jbu1lqf/",
      "parent_id": "t1_jbpr4b7",
      "depth": 9,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-11T10:37:22"
    },
    {
      "id": "jbzt9p3",
      "author": "trnka",
      "body": "If your goal is to speed up training, then yeah reducing the least correlated features makes sense to me.\n\nIf your goal is to improve the quality of the model, usually I find that a well-tuned model doesn't benefit from dropping features.",
      "body_html": "<div class=\"md\"><p>If your goal is to speed up training, then yeah reducing the least correlated features makes sense to me.</p>\n\n<p>If your goal is to improve the quality of the model, usually I find that a well-tuned model doesn&#39;t benefit from dropping features.</p>\n</div>",
      "created_utc": 1678666070.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/jbzt9p3/",
      "parent_id": "t1_jbu1lqf",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-12T17:07:50"
    }
  ],
  "total_comments": 132,
  "fetched_at": "2025-09-13T20:47:36.733427"
}