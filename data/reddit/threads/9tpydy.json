{
  "submission": {
    "id": "9tpydy",
    "title": "Do I re-train my model on the entire training set after selecting the best model following the validation stage ?",
    "author": "Cowboy_Yankee",
    "selftext": "Suppose I have a training set and testing set for a classification problem.\n\nAnd set aside 20% of the training set for parameter tuning and model selection. \n\nOnce I know the best performing model, do I re-train this model against the entire training set before I use it for predictions on the test set. \n\n&#x200B;\n\nThank you for your answers.  ",
    "selftext_html": "<!-- SC_OFF --><div class=\"md\"><p>Suppose I have a training set and testing set for a classification problem.</p>\n\n<p>And set aside 20% of the training set for parameter tuning and model selection. </p>\n\n<p>Once I know the best performing model, do I re-train this model against the entire training set before I use it for predictions on the test set. </p>\n\n<p>&#x200B;</p>\n\n<p>Thank you for your answers.  </p>\n</div><!-- SC_ON -->",
    "url": "https://www.reddit.com/r/MLQuestions/comments/9tpydy/do_i_retrain_my_model_on_the_entire_training_set/",
    "permalink": "/r/MLQuestions/comments/9tpydy/do_i_retrain_my_model_on_the_entire_training_set/",
    "subreddit": "MLQuestions",
    "created_utc": 1541206681.0,
    "score": 11,
    "ups": 11,
    "downs": 0,
    "upvote_ratio": 0.92,
    "num_comments": 16,
    "is_self": true,
    "over_18": false,
    "spoiler": false,
    "stickied": false,
    "locked": false,
    "archived": false,
    "distinguished": null,
    "link_flair_text": null,
    "timestamp": "2018-11-02T17:58:01"
  },
  "comments": [
    {
      "id": "e8y8y01",
      "author": null,
      "body": "Yes, you should re-train your model on the entire training set. This takes advantage of all of the train data to build an ultimately better model. ",
      "body_html": "<div class=\"md\"><p>Yes, you should re-train your model on the entire training set. This takes advantage of all of the train data to build an ultimately better model. </p>\n</div>",
      "created_utc": 1541207610.0,
      "score": 10,
      "ups": 10,
      "downs": 0,
      "permalink": "/r/MLQuestions/comments/9tpydy/do_i_retrain_my_model_on_the_entire_training_set/e8y8y01/",
      "parent_id": "t3_9tpydy",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2018-11-02T18:13:30"
    },
    {
      "id": "e8yp9pw",
      "author": "FragLegs",
      "body": "A few considerations:\n\n1) If your validation set has told you which model or set of hyperparameters is best, then yes I think you should retrain on the full dataset with that new knowledge. \n\n2) You may want to try a different 80/20 split to make sure the “best” model/hyperparameters are stable and not an artifact of the validation set. This is the motivation behind k-fold cross validation. \n\n3) If, instead of picking hyperparameters, you are using the validation set to detect an early stopping criteria (in stochastic gradient descent, for instance), then you might not be able to retrain. It’s possible that the number of epochs before stopping could act like a hyperparameter you’ve chosen, but be aware that changing the size of the dataset is essentially changing the meaning of “an epoch” (assuming you’re defining an epoch as one full pass through your data). \n\n4) If you are planning on using this model in production, you can retrain the entire thing with both the training and test set before deploying to production. Consider whether you want to do a validation split again in this instance to make sure the optimal hyperparameters didn’t change with the introduction of the new data from the test set. ",
      "body_html": "<div class=\"md\"><p>A few considerations:</p>\n\n<p>1) If your validation set has told you which model or set of hyperparameters is best, then yes I think you should retrain on the full dataset with that new knowledge. </p>\n\n<p>2) You may want to try a different 80/20 split to make sure the “best” model/hyperparameters are stable and not an artifact of the validation set. This is the motivation behind k-fold cross validation. </p>\n\n<p>3) If, instead of picking hyperparameters, you are using the validation set to detect an early stopping criteria (in stochastic gradient descent, for instance), then you might not be able to retrain. It’s possible that the number of epochs before stopping could act like a hyperparameter you’ve chosen, but be aware that changing the size of the dataset is essentially changing the meaning of “an epoch” (assuming you’re defining an epoch as one full pass through your data). </p>\n\n<p>4) If you are planning on using this model in production, you can retrain the entire thing with both the training and test set before deploying to production. Consider whether you want to do a validation split again in this instance to make sure the optimal hyperparameters didn’t change with the introduction of the new data from the test set. </p>\n</div>",
      "created_utc": 1541228079.0,
      "score": 6,
      "ups": 6,
      "downs": 0,
      "permalink": "/r/MLQuestions/comments/9tpydy/do_i_retrain_my_model_on_the_entire_training_set/e8yp9pw/",
      "parent_id": "t3_9tpydy",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2018-11-02T23:54:39"
    },
    {
      "id": "e8zaj29",
      "author": "trnka",
      "body": "Industry response:\n\nIf you have a small amount of data, use k-fold CV instead for tuning then retrain on 100%.\n\nIf you have a large amount of data, reduce to say 5% held-out and then don't retrain. This isn't about accuracy but about saving yourself from long training times, maintaining more code, etc.",
      "body_html": "<div class=\"md\"><p>Industry response:</p>\n\n<p>If you have a small amount of data, use k-fold CV instead for tuning then retrain on 100%.</p>\n\n<p>If you have a large amount of data, reduce to say 5% held-out and then don&#39;t retrain. This isn&#39;t about accuracy but about saving yourself from long training times, maintaining more code, etc.</p>\n</div>",
      "created_utc": 1541260012.0,
      "score": 3,
      "ups": 3,
      "downs": 0,
      "permalink": "/r/MLQuestions/comments/9tpydy/do_i_retrain_my_model_on_the_entire_training_set/e8zaj29/",
      "parent_id": "t3_9tpydy",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2018-11-03T08:46:52"
    },
    {
      "id": "e8yn7dg",
      "author": "shaggorama",
      "body": "Yes.",
      "body_html": "<div class=\"md\"><p>Yes.</p>\n</div>",
      "created_utc": 1541224444.0,
      "score": 0,
      "ups": 0,
      "downs": 0,
      "permalink": "/r/MLQuestions/comments/9tpydy/do_i_retrain_my_model_on_the_entire_training_set/e8yn7dg/",
      "parent_id": "t3_9tpydy",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2018-11-02T22:54:04"
    },
    {
      "id": "e8yl6m7",
      "author": "Silver5005",
      "body": "You train in on the remaining 80% you have left.  That was your whole reason for doing the initial split.  You know your parameters will perform unusually well on the first 20% because that's what you tested for, so adding that back into training doesn't seem too genuine.",
      "body_html": "<div class=\"md\"><p>You train in on the remaining 80% you have left.  That was your whole reason for doing the initial split.  You know your parameters will perform unusually well on the first 20% because that&#39;s what you tested for, so adding that back into training doesn&#39;t seem too genuine.</p>\n</div>",
      "created_utc": 1541221253.0,
      "score": -1,
      "ups": -1,
      "downs": 0,
      "permalink": "/r/MLQuestions/comments/9tpydy/do_i_retrain_my_model_on_the_entire_training_set/e8yl6m7/",
      "parent_id": "t3_9tpydy",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2018-11-02T22:00:53"
    },
    {
      "id": "e8z7o0o",
      "author": "koolaidman123",
      "body": "no, because then you're running the risk of destroying all the weights of the best performing model and overfitting. in practice you never retrain the model on the whole data",
      "body_html": "<div class=\"md\"><p>no, because then you&#39;re running the risk of destroying all the weights of the best performing model and overfitting. in practice you never retrain the model on the whole data</p>\n</div>",
      "created_utc": 1541257168.0,
      "score": 3,
      "ups": 3,
      "downs": 0,
      "permalink": "/r/MLQuestions/comments/9tpydy/do_i_retrain_my_model_on_the_entire_training_set/e8z7o0o/",
      "parent_id": "t1_e8y8y01",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2018-11-03T07:59:28"
    },
    {
      "id": "e8yt62y",
      "author": "thntk",
      "body": "This practice would introduce another problem: how do you tune the re-trained model (early stop/learning rate/regularizer...)?",
      "body_html": "<div class=\"md\"><p>This practice would introduce another problem: how do you tune the re-trained model (early stop/learning rate/regularizer...)?</p>\n</div>",
      "created_utc": 1541236227.0,
      "score": 2,
      "ups": 2,
      "downs": 0,
      "permalink": "/r/MLQuestions/comments/9tpydy/do_i_retrain_my_model_on_the_entire_training_set/e8yt62y/",
      "parent_id": "t1_e8y8y01",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2018-11-03T02:10:27"
    },
    {
      "id": "e8yqngx",
      "author": null,
      "body": "[deleted]",
      "body_html": "<div class=\"md\"><p>[deleted]</p>\n</div>",
      "created_utc": 1541230841.0,
      "score": 3,
      "ups": 3,
      "downs": 0,
      "permalink": "/r/MLQuestions/comments/9tpydy/do_i_retrain_my_model_on_the_entire_training_set/e8yqngx/",
      "parent_id": "t1_e8yp9pw",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2018-11-03T00:40:41"
    },
    {
      "id": "e8ypfyl",
      "author": "Cowboy_Yankee",
      "body": "Thanks this was quite comprehensive and insightful. So far my project falls under category 1 fortunately. I was concerned that I was essentially wasting 20% of my data by not re-training. ",
      "body_html": "<div class=\"md\"><p>Thanks this was quite comprehensive and insightful. So far my project falls under category 1 fortunately. I was concerned that I was essentially wasting 20% of my data by not re-training. </p>\n</div>",
      "created_utc": 1541228407.0,
      "score": 2,
      "ups": 2,
      "downs": 0,
      "permalink": "/r/MLQuestions/comments/9tpydy/do_i_retrain_my_model_on_the_entire_training_set/e8ypfyl/",
      "parent_id": "t1_e8yp9pw",
      "depth": 1,
      "is_submitter": true,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2018-11-03T00:00:07"
    },
    {
      "id": "e90dpax",
      "author": "Cowboy_Yankee",
      "body": "So for the small data scenario doesn't re-training the tuned model on 100% of the training data change the weights of the tuned model ?",
      "body_html": "<div class=\"md\"><p>So for the small data scenario doesn&#39;t re-training the tuned model on 100% of the training data change the weights of the tuned model ?</p>\n</div>",
      "created_utc": 1541297239.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MLQuestions/comments/9tpydy/do_i_retrain_my_model_on_the_entire_training_set/e90dpax/",
      "parent_id": "t1_e8zaj29",
      "depth": 1,
      "is_submitter": true,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2018-11-03T19:07:19"
    },
    {
      "id": "m6p18a7",
      "author": "a-loafing-cat",
      "body": "Let's say that I use scikit-learn's \\`gridSearch()\\` function where I have 10-fold cross-validation as an argument for the \\`cv\\` parameter.\n\nI can extract the best model by calling \\`best\\_estimator\\_\\` (the details might be slightly wrong). I'm going to assume that that model is the best model trained on the entire training set with the optimal hyperparameters, but are you suggesting to take those optimal hyperparameters that the \\`gridSearch()\\` routine returned and then train the same model with those hyperparameters hardcoded?\n\nOn the other hand, I'm now thinking that the \\`best\\_estimator\\_\\` is trained on k-1 folds, so there's one fold left out for the model weights. It now sounds like it would better to train on the entire dataset after \\`gridSearch()\\`.",
      "body_html": "<div class=\"md\"><p>Let&#39;s say that I use scikit-learn&#39;s `gridSearch()` function where I have 10-fold cross-validation as an argument for the `cv` parameter.</p>\n\n<p>I can extract the best model by calling `best_estimator_` (the details might be slightly wrong). I&#39;m going to assume that that model is the best model trained on the entire training set with the optimal hyperparameters, but are you suggesting to take those optimal hyperparameters that the `gridSearch()` routine returned and then train the same model with those hyperparameters hardcoded?</p>\n\n<p>On the other hand, I&#39;m now thinking that the `best_estimator_` is trained on k-1 folds, so there&#39;s one fold left out for the model weights. It now sounds like it would better to train on the entire dataset after `gridSearch()`.</p>\n</div>",
      "created_utc": 1736655601.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MLQuestions/comments/9tpydy/do_i_retrain_my_model_on_the_entire_training_set/m6p18a7/",
      "parent_id": "t1_e8zaj29",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": true,
      "distinguished": null,
      "timestamp": "2025-01-11T20:20:01"
    },
    {
      "id": "e8ypb7z",
      "author": "Cowboy_Yankee",
      "body": "I am not sure if I was able to understand you. So I start out by training on 80% of the training data and then I tune my model on the remaining 20% of the training data which is the validation data set.  So my question was after I have the tuned model, do I retrain the tuned model on 100% of the training data ?",
      "body_html": "<div class=\"md\"><p>I am not sure if I was able to understand you. So I start out by training on 80% of the training data and then I tune my model on the remaining 20% of the training data which is the validation data set.  So my question was after I have the tuned model, do I retrain the tuned model on 100% of the training data ?</p>\n</div>",
      "created_utc": 1541228159.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MLQuestions/comments/9tpydy/do_i_retrain_my_model_on_the_entire_training_set/e8ypb7z/",
      "parent_id": "t1_e8yl6m7",
      "depth": 1,
      "is_submitter": true,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2018-11-02T23:55:59"
    },
    {
      "id": "e90dbkb",
      "author": "Cowboy_Yankee",
      "body": "Ya, I was thinking of this issue as well, so this is a problem for smaller datasets.",
      "body_html": "<div class=\"md\"><p>Ya, I was thinking of this issue as well, so this is a problem for smaller datasets.</p>\n</div>",
      "created_utc": 1541296856.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MLQuestions/comments/9tpydy/do_i_retrain_my_model_on_the_entire_training_set/e90dbkb/",
      "parent_id": "t1_e8z7o0o",
      "depth": 2,
      "is_submitter": true,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2018-11-03T19:00:56"
    },
    {
      "id": "e8yvs5r",
      "author": "FragLegs",
      "body": "Yep, that’s a good call out. My comment was explicitly talking about cross validation _within the training set_, but I might not have made that clear enough. Thanks for clarifying. ",
      "body_html": "<div class=\"md\"><p>Yep, that’s a good call out. My comment was explicitly talking about cross validation <em>within the training set</em>, but I might not have made that clear enough. Thanks for clarifying. </p>\n</div>",
      "created_utc": 1541241297.0,
      "score": 2,
      "ups": 2,
      "downs": 0,
      "permalink": "/r/MLQuestions/comments/9tpydy/do_i_retrain_my_model_on_the_entire_training_set/e8yvs5r/",
      "parent_id": "t1_e8yqngx",
      "depth": 2,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2018-11-03T03:34:57"
    },
    {
      "id": "e91hod4",
      "author": "trnka",
      "body": "Yep. Tuning is just about finding the right hyper parameters and usually an extra 10% data doesn't change the best hps much. If your model is very sensitive to the random seed though it could be risky but also everything else is risky too. \n\nAnother option is to test your HPs with CV say 3 fold. Then average the prediction of the three models, each trained on 67%. That way the full data will contribute",
      "body_html": "<div class=\"md\"><p>Yep. Tuning is just about finding the right hyper parameters and usually an extra 10% data doesn&#39;t change the best hps much. If your model is very sensitive to the random seed though it could be risky but also everything else is risky too. </p>\n\n<p>Another option is to test your HPs with CV say 3 fold. Then average the prediction of the three models, each trained on 67%. That way the full data will contribute</p>\n</div>",
      "created_utc": 1541351118.0,
      "score": 2,
      "ups": 2,
      "downs": 0,
      "permalink": "/r/MLQuestions/comments/9tpydy/do_i_retrain_my_model_on_the_entire_training_set/e91hod4/",
      "parent_id": "t1_e90dpax",
      "depth": 2,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2018-11-04T09:05:18"
    },
    {
      "id": "m6ro9w7",
      "author": "trnka",
      "body": "In sklearn's [GridSearchCV](https://scikit-learn.org/1.5/modules/generated/sklearn.model_selection.GridSearchCV.html), `best_estimator_` takes the best params and retrains a model on the whole dataset, so long as `refit=True`. That's enabled by default. So if you're using that, you don't necessarily need to do much else.\n\nSometimes in industry I'm getting new data often and should retrain, but full hyperparameter tuning can be too slow. For example, retraining a model with new data might take 15 min and hyperparam tuning might take 8 hours. In that situation, I'd only run the hyperparmeter tuning once every few months, save the best hyperparams, and then load those hyperparams in a weekly retraining process.",
      "body_html": "<div class=\"md\"><p>In sklearn&#39;s <a href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.model_selection.GridSearchCV.html\">GridSearchCV</a>, <code>best_estimator_</code> takes the best params and retrains a model on the whole dataset, so long as <code>refit=True</code>. That&#39;s enabled by default. So if you&#39;re using that, you don&#39;t necessarily need to do much else.</p>\n\n<p>Sometimes in industry I&#39;m getting new data often and should retrain, but full hyperparameter tuning can be too slow. For example, retraining a model with new data might take 15 min and hyperparam tuning might take 8 hours. In that situation, I&#39;d only run the hyperparmeter tuning once every few months, save the best hyperparams, and then load those hyperparams in a weekly retraining process.</p>\n</div>",
      "created_utc": 1736700842.0,
      "score": 2,
      "ups": 2,
      "downs": 0,
      "permalink": "/r/MLQuestions/comments/9tpydy/do_i_retrain_my_model_on_the_entire_training_set/m6ro9w7/",
      "parent_id": "t1_m6p18a7",
      "depth": 2,
      "is_submitter": false,
      "stickied": false,
      "edited": true,
      "distinguished": null,
      "timestamp": "2025-01-12T08:54:02"
    },
    {
      "id": "m70nvzf",
      "author": "a-loafing-cat",
      "body": "Thanks. I appreciate your answer.\n\n  \nI don't have a lot of industry experience when it comes to machine learning/predictive analytics, and I'm the only one on my analytics team with mathematics/statistics background. \n\nWe're very much an analytics/reporting data team, but I want to start doing a little bit of statistics/predictive modelling since I've taken some courses in statistical learning. Very much a \"pull yourself up by the bootstraps\" situation, which is good and bad.",
      "body_html": "<div class=\"md\"><p>Thanks. I appreciate your answer.</p>\n\n<p>I don&#39;t have a lot of industry experience when it comes to machine learning/predictive analytics, and I&#39;m the only one on my analytics team with mathematics/statistics background. </p>\n\n<p>We&#39;re very much an analytics/reporting data team, but I want to start doing a little bit of statistics/predictive modelling since I&#39;ve taken some courses in statistical learning. Very much a &quot;pull yourself up by the bootstraps&quot; situation, which is good and bad.</p>\n</div>",
      "created_utc": 1736815738.0,
      "score": 2,
      "ups": 2,
      "downs": 0,
      "permalink": "/r/MLQuestions/comments/9tpydy/do_i_retrain_my_model_on_the_entire_training_set/m70nvzf/",
      "parent_id": "t1_m6ro9w7",
      "depth": 3,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2025-01-13T16:48:58"
    }
  ],
  "total_comments": 17,
  "fetched_at": "2025-09-13T20:47:09.238046"
}