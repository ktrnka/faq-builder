{
  "submission": {
    "id": "1i8vk7h",
    "title": "Future of small-scale AI research?",
    "author": "SammathNaur",
    "selftext": "Hello. I hope this post finds you all well. I've been thinking a lot lately about the phd journey i've embarked on and the such types of research in the near future. I imagine many experts with varied backgrounds lurk around here, so I'll add some context to this situation. People with backgrounds in academia might find much of this familiar, so you can skip that part.\n\n  \nContext: By small-scale AI research I am not referring to small businesses that might find their budgets stretched by needing to invest more and more to offer a solution that is at least partly comparable to the big players. I am referring to people working by themselves, with little to no budget to allocate for improving the tools needed for their research, nor capable of employing additional experts to guide them (which would also be a conflict with regards to the nature of a phd). We, unlike businesses that provide services to private customers whom they can satisfy by fulfilling their needs, have to justify our work by comparing it with the latest and greatest in the field. That's perfectly reasonable and greatly needed to prevent unruly actors from reaping fruits they do not deserve. The specific problem we face is the ever-increasing gap between results that can be obtained at home, using only a computer and small amounts of data. Gathering large amounts of data can be tricky, costly and take a lot of time. We also have to have a rather constant output of articles to meet university rules, so spending 6+ months working on something might not be feasible.\n\n  \nNow, my question is: how can we keep working and obtain results in a field that is dominated by companies with very large pockets that make use of them and output models that break new records every couple of months?\n\n  \nTake an image segmentation task as an example. Gathering the data, preparing it, training and fine-tuning a model might produce results significantly worse than meta's Segment Anything can achieve. That model can be tested for free and downloaded at no cost. Sure, some more specialized fields might take longer to be affected, but many already are. General purpose image processing, language models, generative models, voice generation, etc already cannot compete with already existent solutions.\n\n\n\nHow should we go from here? How do we continue and improve our work to still produce meaningful results?\n\n\n\nThank you to whoever spent the time to read this and decides to share their thoughts and experiences. ",
    "selftext_html": "<!-- SC_OFF --><div class=\"md\"><p>Hello. I hope this post finds you all well. I&#39;ve been thinking a lot lately about the phd journey i&#39;ve embarked on and the such types of research in the near future. I imagine many experts with varied backgrounds lurk around here, so I&#39;ll add some context to this situation. People with backgrounds in academia might find much of this familiar, so you can skip that part.</p>\n\n<p>Context: By small-scale AI research I am not referring to small businesses that might find their budgets stretched by needing to invest more and more to offer a solution that is at least partly comparable to the big players. I am referring to people working by themselves, with little to no budget to allocate for improving the tools needed for their research, nor capable of employing additional experts to guide them (which would also be a conflict with regards to the nature of a phd). We, unlike businesses that provide services to private customers whom they can satisfy by fulfilling their needs, have to justify our work by comparing it with the latest and greatest in the field. That&#39;s perfectly reasonable and greatly needed to prevent unruly actors from reaping fruits they do not deserve. The specific problem we face is the ever-increasing gap between results that can be obtained at home, using only a computer and small amounts of data. Gathering large amounts of data can be tricky, costly and take a lot of time. We also have to have a rather constant output of articles to meet university rules, so spending 6+ months working on something might not be feasible.</p>\n\n<p>Now, my question is: how can we keep working and obtain results in a field that is dominated by companies with very large pockets that make use of them and output models that break new records every couple of months?</p>\n\n<p>Take an image segmentation task as an example. Gathering the data, preparing it, training and fine-tuning a model might produce results significantly worse than meta&#39;s Segment Anything can achieve. That model can be tested for free and downloaded at no cost. Sure, some more specialized fields might take longer to be affected, but many already are. General purpose image processing, language models, generative models, voice generation, etc already cannot compete with already existent solutions.</p>\n\n<p>How should we go from here? How do we continue and improve our work to still produce meaningful results?</p>\n\n<p>Thank you to whoever spent the time to read this and decides to share their thoughts and experiences. </p>\n</div><!-- SC_ON -->",
    "url": "https://www.reddit.com/r/MLQuestions/comments/1i8vk7h/future_of_smallscale_ai_research/",
    "permalink": "/r/MLQuestions/comments/1i8vk7h/future_of_smallscale_ai_research/",
    "subreddit": "MLQuestions",
    "created_utc": 1737725875.0,
    "score": 1,
    "ups": 1,
    "downs": 0,
    "upvote_ratio": 1.0,
    "num_comments": 4,
    "is_self": true,
    "over_18": false,
    "spoiler": false,
    "stickied": false,
    "locked": false,
    "archived": false,
    "distinguished": null,
    "link_flair_text": "Educational content ðŸ“–",
    "timestamp": "2025-01-24T05:37:55"
  },
  "comments": [
    {
      "id": "m8ws6yw",
      "author": "jeandebleau",
      "body": "Foundation models are not well adapted for industrial applications or AI on the edge. The models are often way too big, need too much memory and compute resources. There is a huge demand for small efficient and specialized models. Real use cases for image segmentation looks more like 30 to 60 fps 4k images where small objects need to be precisely detected. Good luck using \"sota\" segmentation models trained on 224x224 tiny images.",
      "body_html": "<div class=\"md\"><p>Foundation models are not well adapted for industrial applications or AI on the edge. The models are often way too big, need too much memory and compute resources. There is a huge demand for small efficient and specialized models. Real use cases for image segmentation looks more like 30 to 60 fps 4k images where small objects need to be precisely detected. Good luck using &quot;sota&quot; segmentation models trained on 224x224 tiny images.</p>\n</div>",
      "created_utc": 1737727070.0,
      "score": 2,
      "ups": 2,
      "downs": 0,
      "permalink": "/r/MLQuestions/comments/1i8vk7h/future_of_smallscale_ai_research/m8ws6yw/",
      "parent_id": "t3_1i8vk7h",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2025-01-24T05:57:50"
    },
    {
      "id": "m8wuwc0",
      "author": "mocny-chlapik",
      "body": "You need to be able to pick your battles. There are tons of problems that are not being addressed by big tech at all, eg anything that is not monetizable in a short term. Those are the kinds of problems that academia should focus on. There is no point in trying to outspend commercial businesses in their core features.",
      "body_html": "<div class=\"md\"><p>You need to be able to pick your battles. There are tons of problems that are not being addressed by big tech at all, eg anything that is not monetizable in a short term. Those are the kinds of problems that academia should focus on. There is no point in trying to outspend commercial businesses in their core features.</p>\n</div>",
      "created_utc": 1737727986.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MLQuestions/comments/1i8vk7h/future_of_smallscale_ai_research/m8wuwc0/",
      "parent_id": "t3_1i8vk7h",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2025-01-24T06:13:06"
    },
    {
      "id": "m8xfb9r",
      "author": "DigThatData",
      "body": "Independent researchers are often interested in different questions than industry labs. Curiosity and passion are human qualities that aren't going anywhere. Industry researchers have to justify their research agenda within the business/customer context. Academics and independent researchers don't have this limitation.\n\n> We also have to have a rather constant output of articles to meet university rules\n\nUniversities often partner with industry, and/or have their own resources. The trump administration is working rapidly to attack the US's education and research infrastructure though, which a lot of researchers previously relied upon.\n\nI'd be less concerned about \"how do we compete with industry generally\" than \"how are we going to find funding for academic research with the ecosystem being actively dismantled\".",
      "body_html": "<div class=\"md\"><p>Independent researchers are often interested in different questions than industry labs. Curiosity and passion are human qualities that aren&#39;t going anywhere. Industry researchers have to justify their research agenda within the business/customer context. Academics and independent researchers don&#39;t have this limitation.</p>\n\n<blockquote>\n<p>We also have to have a rather constant output of articles to meet university rules</p>\n</blockquote>\n\n<p>Universities often partner with industry, and/or have their own resources. The trump administration is working rapidly to attack the US&#39;s education and research infrastructure though, which a lot of researchers previously relied upon.</p>\n\n<p>I&#39;d be less concerned about &quot;how do we compete with industry generally&quot; than &quot;how are we going to find funding for academic research with the ecosystem being actively dismantled&quot;.</p>\n</div>",
      "created_utc": 1737734129.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MLQuestions/comments/1i8vk7h/future_of_smallscale_ai_research/m8xfb9r/",
      "parent_id": "t3_1i8vk7h",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2025-01-24T07:55:29"
    },
    {
      "id": "m902d4g",
      "author": "trnka",
      "body": "I hear you. There are still plenty of research areas that don't require tons of compute. Some examples:\n\n- Applications issues, like situations where the model needs to be loaded in 1 sec (AWS lambda) or it needs to be small (typing on mobile phones, running ML inside the web browser)\n- ML-UX, like how to make machine translation user interfaces more trustworthy, or how to make RAG/LLM citations more trustworthy\n- Domain-specific models, where the general-purpose models don't work well yet (or they're too expensive)\n- Forecasting",
      "body_html": "<div class=\"md\"><p>I hear you. There are still plenty of research areas that don&#39;t require tons of compute. Some examples:</p>\n\n<ul>\n<li>Applications issues, like situations where the model needs to be loaded in 1 sec (AWS lambda) or it needs to be small (typing on mobile phones, running ML inside the web browser)</li>\n<li>ML-UX, like how to make machine translation user interfaces more trustworthy, or how to make RAG/LLM citations more trustworthy</li>\n<li>Domain-specific models, where the general-purpose models don&#39;t work well yet (or they&#39;re too expensive)</li>\n<li>Forecasting</li>\n</ul>\n</div>",
      "created_utc": 1737761166.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/MLQuestions/comments/1i8vk7h/future_of_smallscale_ai_research/m902d4g/",
      "parent_id": "t3_1i8vk7h",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2025-01-24T15:26:06"
    }
  ],
  "total_comments": 4,
  "fetched_at": "2025-09-13T20:47:05.697908"
}