{
  "submission": {
    "id": "1ff8kqm",
    "title": "Manually labeling text dataset",
    "author": "mabl00",
    "selftext": "Me, along with my group is tasked with curating a labeled dataset of tweets that talk about STEM, which will then be used to fine-tune a model like BERT and make predictions. We have access to about 300 unlabeled datasets of university tweets (in individual csv files). We don't need to use all of the universities.\n\nWe'd like to stick to a manual approach for an initial dataset for about 2000 tweets. So we don't wanna use similarity search or any pretrained models and would rather like a manual approach. We created some small groups of universities each of us will work on. How to go about labeling them manually but efficiently? \n\n1. Sampling data from each university in a group and manually finding out STEM tweets\n\n2. Doing a keyword-search on the whole group and then manually checking whether they are about STEM or not\n\nOR, Any other approach you guys have in mind? ",
    "selftext_html": "<!-- SC_OFF --><div class=\"md\"><p>Me, along with my group is tasked with curating a labeled dataset of tweets that talk about STEM, which will then be used to fine-tune a model like BERT and make predictions. We have access to about 300 unlabeled datasets of university tweets (in individual csv files). We don&#39;t need to use all of the universities.</p>\n\n<p>We&#39;d like to stick to a manual approach for an initial dataset for about 2000 tweets. So we don&#39;t wanna use similarity search or any pretrained models and would rather like a manual approach. We created some small groups of universities each of us will work on. How to go about labeling them manually but efficiently? </p>\n\n<ol>\n<li><p>Sampling data from each university in a group and manually finding out STEM tweets</p></li>\n<li><p>Doing a keyword-search on the whole group and then manually checking whether they are about STEM or not</p></li>\n</ol>\n\n<p>OR, Any other approach you guys have in mind? </p>\n</div><!-- SC_ON -->",
    "url": "https://www.reddit.com/r/LanguageTechnology/comments/1ff8kqm/manually_labeling_text_dataset/",
    "permalink": "/r/LanguageTechnology/comments/1ff8kqm/manually_labeling_text_dataset/",
    "subreddit": "LanguageTechnology",
    "created_utc": 1726162990.0,
    "score": 2,
    "ups": 2,
    "downs": 0,
    "upvote_ratio": 1.0,
    "num_comments": 8,
    "is_self": true,
    "over_18": false,
    "spoiler": false,
    "stickied": false,
    "locked": false,
    "archived": false,
    "distinguished": null,
    "link_flair_text": null,
    "timestamp": "2024-09-12T10:43:10"
  },
  "comments": [
    {
      "id": "lmstk39",
      "author": null,
      "body": "[removed]",
      "body_html": "<div class=\"md\"><p>[removed]</p>\n</div>",
      "created_utc": 1726163601.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/LanguageTechnology/comments/1ff8kqm/manually_labeling_text_dataset/lmstk39/",
      "parent_id": "t3_1ff8kqm",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2024-09-12T10:53:21"
    },
    {
      "id": "lmtxh68",
      "author": "trnka",
      "body": "This is a relatively small amount of data so I'd just use google sheets. If possible, get your annotators in a room doing the annotation and stop to discuss any challenging examples, then create/refine your annotation manual as you go. If possible, annotate at least a subset of the data by multiple annotators and measure agreement to evaluate the quality of your instructions.\n\nIf you're going to do much more annotation though, it'll save time to use annotation software, active leaning, and/or LLMs. You could also start with manual annotation until you've reconciled enough challenging examples, which will be useful for making the LLM prompt.",
      "body_html": "<div class=\"md\"><p>This is a relatively small amount of data so I&#39;d just use google sheets. If possible, get your annotators in a room doing the annotation and stop to discuss any challenging examples, then create/refine your annotation manual as you go. If possible, annotate at least a subset of the data by multiple annotators and measure agreement to evaluate the quality of your instructions.</p>\n\n<p>If you&#39;re going to do much more annotation though, it&#39;ll save time to use annotation software, active leaning, and/or LLMs. You could also start with manual annotation until you&#39;ve reconciled enough challenging examples, which will be useful for making the LLM prompt.</p>\n</div>",
      "created_utc": 1726176389.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/LanguageTechnology/comments/1ff8kqm/manually_labeling_text_dataset/lmtxh68/",
      "parent_id": "t3_1ff8kqm",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2024-09-12T14:26:29"
    },
    {
      "id": "lmvj3nm",
      "author": "XablauSilva",
      "body": "Use a LLM like Claude 3 to label all tweets.",
      "body_html": "<div class=\"md\"><p>Use a LLM like Claude 3 to label all tweets.</p>\n</div>",
      "created_utc": 1726198185.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/LanguageTechnology/comments/1ff8kqm/manually_labeling_text_dataset/lmvj3nm/",
      "parent_id": "t3_1ff8kqm",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2024-09-12T20:29:45"
    },
    {
      "id": "ln4fvgj",
      "author": "chschroeder",
      "body": "It was already mentioned, but this sounds like a standard active learning task. It is not completely manual, but still a human-in-the-loop approach, where the model suggests samples to be label next, while the labeling is still done by a human annotator. \nActive learning requires a starting model (unless cold start approaches are employed) for which a starting model based on keyword-filtered samples, reviewed and corrected by a human annotator, is a plausible approach. \n\nI have written [small-text](https://github.com/webis-de/small-text), an active learning library exactly for text and transformer-based models. If you combine it with [argilla](https://docs.v1.argilla.io/en/latest/tutorials/notebooks/training-textclassification-smalltext-activelearning.html) you will even have a nice GUI for labelling. (Care, you need the v1.x version of argilla.)",
      "body_html": "<div class=\"md\"><p>It was already mentioned, but this sounds like a standard active learning task. It is not completely manual, but still a human-in-the-loop approach, where the model suggests samples to be label next, while the labeling is still done by a human annotator. \nActive learning requires a starting model (unless cold start approaches are employed) for which a starting model based on keyword-filtered samples, reviewed and corrected by a human annotator, is a plausible approach. </p>\n\n<p>I have written <a href=\"https://github.com/webis-de/small-text\">small-text</a>, an active learning library exactly for text and transformer-based models. If you combine it with <a href=\"https://docs.v1.argilla.io/en/latest/tutorials/notebooks/training-textclassification-smalltext-activelearning.html\">argilla</a> you will even have a nice GUI for labelling. (Care, you need the v1.x version of argilla.)</p>\n</div>",
      "created_utc": 1726338779.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/LanguageTechnology/comments/1ff8kqm/manually_labeling_text_dataset/ln4fvgj/",
      "parent_id": "t3_1ff8kqm",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": true,
      "distinguished": null,
      "timestamp": "2024-09-14T11:32:59"
    },
    {
      "id": "lmsu5rq",
      "author": "mabl00",
      "body": "The labels are talks about STEM, doesn’t talk about STEM.",
      "body_html": "<div class=\"md\"><p>The labels are talks about STEM, doesn’t talk about STEM.</p>\n</div>",
      "created_utc": 1726163788.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/LanguageTechnology/comments/1ff8kqm/manually_labeling_text_dataset/lmsu5rq/",
      "parent_id": "t1_lmstk39",
      "depth": 1,
      "is_submitter": true,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2024-09-12T10:56:28"
    },
    {
      "id": "lmtbgv9",
      "author": null,
      "body": "[removed]",
      "body_html": "<div class=\"md\"><p>[removed]</p>\n</div>",
      "created_utc": 1726169376.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/LanguageTechnology/comments/1ff8kqm/manually_labeling_text_dataset/lmtbgv9/",
      "parent_id": "t1_lmsu5rq",
      "depth": 2,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2024-09-12T12:29:36"
    },
    {
      "id": "lmttnfm",
      "author": "Hood4d",
      "body": "Not a bad idea. Maybe label a couple hundred personally so you can compare against ChatGPT's accuracy though.",
      "body_html": "<div class=\"md\"><p>Not a bad idea. Maybe label a couple hundred personally so you can compare against ChatGPT&#39;s accuracy though.</p>\n</div>",
      "created_utc": 1726175162.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/LanguageTechnology/comments/1ff8kqm/manually_labeling_text_dataset/lmttnfm/",
      "parent_id": "t1_lmtbgv9",
      "depth": 3,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2024-09-12T14:06:02"
    }
  ],
  "total_comments": 7,
  "fetched_at": "2025-09-13T20:47:31.907254"
}