{
  "submission": {
    "id": "1g8brrn",
    "title": "Is POS tagging (like with Viterbi HMM) still useful for anything in industry in 2024?  Moreover, have you ever actually used any of the older NLP techniques in an industry context?",
    "author": "Fuehnix",
    "selftext": "I have a background in a Computer Science + Linguistics BS, and a couple years of experience in industry as an AI software engineer (mostly implementing LLMs with python for chatbots/topic modeling/insights).\n\nI'm currently doing a part time master's degree and in a class that's revisiting all the concepts that I learned in undergrad and never used in my career.\n\nYou know, Naive Bayes, Convolutional Neural Networks, HMMs/Viterbi, N-grams, Logistic Regression, etc.\n\nI get that there is value in having \"foundational knowledge\" of how things used to be done, but the majority of my class is covering concepts that I learned, and then later forgot because I never used them in my career.  And now I'm working fulltime in AI, taking an AI class to get better at my job, only to learn concepts that I already know I won't use.\n\nFrom what I've read in literature, and what I've experienced, system prompts and/or finetuned LLMs kind of beat traditional models at nearly all tasks.  And even if there were cases where they didn't, LLMs eliminate the huge hurdle in industry of finding time/resources to make a quality training data set.\n\n\n\nI won't pretend that I'm senior enough to know everything, or that I have enough experience to invalidate the relevance of PhDs with far more knowledge than me.  So please, if anybody can make a point about how any of these techniques still matter, please let me know.  It'd really help motivate me to learn them more in depth and maybe apply them to my work.\n\n",
    "selftext_html": "<!-- SC_OFF --><div class=\"md\"><p>I have a background in a Computer Science + Linguistics BS, and a couple years of experience in industry as an AI software engineer (mostly implementing LLMs with python for chatbots/topic modeling/insights).</p>\n\n<p>I&#39;m currently doing a part time master&#39;s degree and in a class that&#39;s revisiting all the concepts that I learned in undergrad and never used in my career.</p>\n\n<p>You know, Naive Bayes, Convolutional Neural Networks, HMMs/Viterbi, N-grams, Logistic Regression, etc.</p>\n\n<p>I get that there is value in having &quot;foundational knowledge&quot; of how things used to be done, but the majority of my class is covering concepts that I learned, and then later forgot because I never used them in my career.  And now I&#39;m working fulltime in AI, taking an AI class to get better at my job, only to learn concepts that I already know I won&#39;t use.</p>\n\n<p>From what I&#39;ve read in literature, and what I&#39;ve experienced, system prompts and/or finetuned LLMs kind of beat traditional models at nearly all tasks.  And even if there were cases where they didn&#39;t, LLMs eliminate the huge hurdle in industry of finding time/resources to make a quality training data set.</p>\n\n<p>I won&#39;t pretend that I&#39;m senior enough to know everything, or that I have enough experience to invalidate the relevance of PhDs with far more knowledge than me.  So please, if anybody can make a point about how any of these techniques still matter, please let me know.  It&#39;d really help motivate me to learn them more in depth and maybe apply them to my work.</p>\n</div><!-- SC_ON -->",
    "url": "https://www.reddit.com/r/LanguageTechnology/comments/1g8brrn/is_pos_tagging_like_with_viterbi_hmm_still_useful/",
    "permalink": "/r/LanguageTechnology/comments/1g8brrn/is_pos_tagging_like_with_viterbi_hmm_still_useful/",
    "subreddit": "LanguageTechnology",
    "created_utc": 1729465860.0,
    "score": 26,
    "ups": 26,
    "downs": 0,
    "upvote_ratio": 0.97,
    "num_comments": 13,
    "is_self": true,
    "over_18": false,
    "spoiler": false,
    "stickied": false,
    "locked": false,
    "archived": false,
    "distinguished": null,
    "link_flair_text": null,
    "timestamp": "2024-10-20T16:11:00"
  },
  "comments": [
    {
      "id": "lsxg3bj",
      "author": "BeginnerDragon",
      "body": "Fantastic question. LLMs have changed the game, but they haven't replaced other methodologies.\n\nThe precursor to LLMs were transformer-based models like BERT. Transformer models were so groundbreaking because they showed potential for across-the-board performance gains in most NLP tasks. We're seeing an explosion of performance gains for general tasks yet again, but it doesn't mean LLMs are the end-all-be-all solution.\n\nWhy?\n\n* **Security** - Most people are chasing after state of the art without stopping to do proper security checks for their deployment. It's great for a scrappy startup or personal project but reckless when customer data is involved. OpenAI tends to be off the table for some organizations since they can have interest in your queries and could eventually sell that data to their partners or your competitors. You always have to ask yourself why the offerings are free. To my knowledge, one of the most prevalent encoder models is Chinese developed. I've known a few devs who had to line-by-line remove functionality for actual LLM models, which sometimes have a phone-home element built in. That's a risk to your business.\n* **Costs**: LLMs are wicked expensive to create from scratch, but even their use is expensive if you aren't careful. I welcome corrections here, but I understand that an AWS server that has a decently-large LLM running at all times for a RAG application will cost an organization something to the tune of $2k USD a month. When you're thinking about an enterprise system w/ big data, you have to understand that simple LLM queries on 100m+ rows is no simple undertaking.\n* **Performance**: LLMs can work wonders, but they're not going to outdo domain knowledge and targeted applications - further, when you're doing analyses, you need a script to replicate what you've done if you have to defend your results (e.g., you said 50% of customer reviews are negative and someone wants to refute that claim, are you going to just say, \"It's what ChatGPT says\") - there have been so many improvements on diving into the black box ML models, and we lose a lot of that power when we're pushing the query outside our network. Further, there are tasks that still need improvement -  Named Entity Recognition suffers from less-than-optimal performance when done by LLMs. This will definitely change over time, but my understanding is that targeted models (even ones that leverage LLMs as 1+ steps in the overall pipeline) should always do better than raw LLM outputs.\n\n**tl;dr** LLMs are fantastic at what they do, but it would be silly to have them replace all data-related functionality because it can easily be expensive, troublesome for security, and your mileage may vary with success.\n\nFor what it's worth, I've found that they're incredibly valuable in helping you code the NLP pipeline yourself. It has improved my coding dramatically.",
      "body_html": "<div class=\"md\"><p>Fantastic question. LLMs have changed the game, but they haven&#39;t replaced other methodologies.</p>\n\n<p>The precursor to LLMs were transformer-based models like BERT. Transformer models were so groundbreaking because they showed potential for across-the-board performance gains in most NLP tasks. We&#39;re seeing an explosion of performance gains for general tasks yet again, but it doesn&#39;t mean LLMs are the end-all-be-all solution.</p>\n\n<p>Why?</p>\n\n<ul>\n<li><strong>Security</strong> - Most people are chasing after state of the art without stopping to do proper security checks for their deployment. It&#39;s great for a scrappy startup or personal project but reckless when customer data is involved. OpenAI tends to be off the table for some organizations since they can have interest in your queries and could eventually sell that data to their partners or your competitors. You always have to ask yourself why the offerings are free. To my knowledge, one of the most prevalent encoder models is Chinese developed. I&#39;ve known a few devs who had to line-by-line remove functionality for actual LLM models, which sometimes have a phone-home element built in. That&#39;s a risk to your business.</li>\n<li><strong>Costs</strong>: LLMs are wicked expensive to create from scratch, but even their use is expensive if you aren&#39;t careful. I welcome corrections here, but I understand that an AWS server that has a decently-large LLM running at all times for a RAG application will cost an organization something to the tune of $2k USD a month. When you&#39;re thinking about an enterprise system w/ big data, you have to understand that simple LLM queries on 100m+ rows is no simple undertaking.</li>\n<li><strong>Performance</strong>: LLMs can work wonders, but they&#39;re not going to outdo domain knowledge and targeted applications - further, when you&#39;re doing analyses, you need a script to replicate what you&#39;ve done if you have to defend your results (e.g., you said 50% of customer reviews are negative and someone wants to refute that claim, are you going to just say, &quot;It&#39;s what ChatGPT says&quot;) - there have been so many improvements on diving into the black box ML models, and we lose a lot of that power when we&#39;re pushing the query outside our network. Further, there are tasks that still need improvement -  Named Entity Recognition suffers from less-than-optimal performance when done by LLMs. This will definitely change over time, but my understanding is that targeted models (even ones that leverage LLMs as 1+ steps in the overall pipeline) should always do better than raw LLM outputs.</li>\n</ul>\n\n<p><strong>tl;dr</strong> LLMs are fantastic at what they do, but it would be silly to have them replace all data-related functionality because it can easily be expensive, troublesome for security, and your mileage may vary with success.</p>\n\n<p>For what it&#39;s worth, I&#39;ve found that they&#39;re incredibly valuable in helping you code the NLP pipeline yourself. It has improved my coding dramatically.</p>\n</div>",
      "created_utc": 1729469354.0,
      "score": 20,
      "ups": 20,
      "downs": 0,
      "permalink": "/r/LanguageTechnology/comments/1g8brrn/is_pos_tagging_like_with_viterbi_hmm_still_useful/lsxg3bj/",
      "parent_id": "t3_1g8brrn",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": true,
      "distinguished": null,
      "timestamp": "2024-10-20T17:09:14"
    },
    {
      "id": "lsxdx02",
      "author": "milesper",
      "body": "You can definitely do just fine without ever thinking about the older methods. That said, there’s plenty of tasks where the latest LLM is probably a bad choice- for example, on many classification tasks, finetuning a BERT is often higher- \nperformance and lower-cost than any other option. \n\nAlso, those are all concepts which are absolutely more relevant in other areas of data science (speech processing, image processing, scientific ML), so understanding them is essential if you want to seek a broader range of jobs.",
      "body_html": "<div class=\"md\"><p>You can definitely do just fine without ever thinking about the older methods. That said, there’s plenty of tasks where the latest LLM is probably a bad choice- for example, on many classification tasks, finetuning a BERT is often higher- \nperformance and lower-cost than any other option. </p>\n\n<p>Also, those are all concepts which are absolutely more relevant in other areas of data science (speech processing, image processing, scientific ML), so understanding them is essential if you want to seek a broader range of jobs.</p>\n</div>",
      "created_utc": 1729468524.0,
      "score": 11,
      "ups": 11,
      "downs": 0,
      "permalink": "/r/LanguageTechnology/comments/1g8brrn/is_pos_tagging_like_with_viterbi_hmm_still_useful/lsxdx02/",
      "parent_id": "t3_1g8brrn",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2024-10-20T16:55:24"
    },
    {
      "id": "lsxiu8c",
      "author": "benjamin-crowell",
      "body": "The niche where I've been doing my hobby work is creating aids for language learners to read texts in ancient Greek. Example: [https://lightandmatter.com/anabasis/1\\_1.html](https://lightandmatter.com/anabasis/1_1.html) For this application, finding the lemma and POS are not a side issue or a means to the end, they are the main event. The reader sees a word and doesn't understand it, so they want to be able to click on it and see the lemma, POS, and gloss.\n\n(This also happens to be a case where old-fashioned pattern-matching and table lookup [do much better](https://bitbucket.org/ben-crowell/test_lemmatizers/src/master/summary.md) than the more modern neural network type of stuff.)\n\nYou can also ask yourself how tolerant a particular application is of hallucinations, or how much electrical power you're willing to burn on training and per computation.",
      "body_html": "<div class=\"md\"><p>The niche where I&#39;ve been doing my hobby work is creating aids for language learners to read texts in ancient Greek. Example: <a href=\"https://lightandmatter.com/anabasis/1_1.html\">https://lightandmatter.com/anabasis/1_1.html</a> For this application, finding the lemma and POS are not a side issue or a means to the end, they are the main event. The reader sees a word and doesn&#39;t understand it, so they want to be able to click on it and see the lemma, POS, and gloss.</p>\n\n<p>(This also happens to be a case where old-fashioned pattern-matching and table lookup <a href=\"https://bitbucket.org/ben-crowell/test_lemmatizers/src/master/summary.md\">do much better</a> than the more modern neural network type of stuff.)</p>\n\n<p>You can also ask yourself how tolerant a particular application is of hallucinations, or how much electrical power you&#39;re willing to burn on training and per computation.</p>\n</div>",
      "created_utc": 1729470386.0,
      "score": 6,
      "ups": 6,
      "downs": 0,
      "permalink": "/r/LanguageTechnology/comments/1g8brrn/is_pos_tagging_like_with_viterbi_hmm_still_useful/lsxiu8c/",
      "parent_id": "t3_1g8brrn",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2024-10-20T17:26:26"
    },
    {
      "id": "lt138k2",
      "author": "trnka",
      "body": "I've used the Viterbi algorithm in industry, and beam search is very common too (even used in LLMs).\n\nI used it for typo correction of previous words on mobile phone keyboards around 2013. Once you typed a word or two afterwards, you can use a search to use the additional context to reprocess previous text input to improve accuracy a bit. Google keyboard on Android does this nowadays and it works a lot better than what we had in 2013.\n\nSome of the others you mentioned:\n\n* Naive Bayes: Haven't used it professionally except as a baseline\n* Convolutional neural networks: Used them extensively around 2018-2022 to build small, high quality text classifiers in the medical space. If we were starting from scratch today we'd probably use a BERT variant.\n* Ngrams: Used them for typing on mobile phones, 2011-2015. Used the ideas from bag of ngram classifiers in medical text classification 2016-2022. Used for some prototyping in the medical space too, like how each question-answer in a medical interview should update the differential diagnosis.\n* Logistic regression: Used for medical text classification 2017-2018. Used for analysis of product reviews 2011-2024 (predict good/bad then inspect the weights). Used for non-NLP tasks in 2023-2024 like a content-based recommender system.\n\nOf all those things I'd say logistic regression is the most useful still in 2024 because it's fast, cheap, and interpretable. It's also very reliable when combined with a basic hyperparameter search over the regularization parameter.",
      "body_html": "<div class=\"md\"><p>I&#39;ve used the Viterbi algorithm in industry, and beam search is very common too (even used in LLMs).</p>\n\n<p>I used it for typo correction of previous words on mobile phone keyboards around 2013. Once you typed a word or two afterwards, you can use a search to use the additional context to reprocess previous text input to improve accuracy a bit. Google keyboard on Android does this nowadays and it works a lot better than what we had in 2013.</p>\n\n<p>Some of the others you mentioned:</p>\n\n<ul>\n<li>Naive Bayes: Haven&#39;t used it professionally except as a baseline</li>\n<li>Convolutional neural networks: Used them extensively around 2018-2022 to build small, high quality text classifiers in the medical space. If we were starting from scratch today we&#39;d probably use a BERT variant.</li>\n<li>Ngrams: Used them for typing on mobile phones, 2011-2015. Used the ideas from bag of ngram classifiers in medical text classification 2016-2022. Used for some prototyping in the medical space too, like how each question-answer in a medical interview should update the differential diagnosis.</li>\n<li>Logistic regression: Used for medical text classification 2017-2018. Used for analysis of product reviews 2011-2024 (predict good/bad then inspect the weights). Used for non-NLP tasks in 2023-2024 like a content-based recommender system.</li>\n</ul>\n\n<p>Of all those things I&#39;d say logistic regression is the most useful still in 2024 because it&#39;s fast, cheap, and interpretable. It&#39;s also very reliable when combined with a basic hyperparameter search over the regularization parameter.</p>\n</div>",
      "created_utc": 1729529002.0,
      "score": 2,
      "ups": 2,
      "downs": 0,
      "permalink": "/r/LanguageTechnology/comments/1g8brrn/is_pos_tagging_like_with_viterbi_hmm_still_useful/lt138k2/",
      "parent_id": "t3_1g8brrn",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2024-10-21T09:43:22"
    },
    {
      "id": "lsymf02",
      "author": "solresol",
      "body": "Prompting beats fine tuning. Fine tuning beats traditional techniques.\n\nThe main exception is explainability. e.g. \"I want to find the kinds of phrases that are more commonly appearing in the transcript logs of X vs Y\" -> the goal isn't to create a great predictor, the goal is to provide some insights.",
      "body_html": "<div class=\"md\"><p>Prompting beats fine tuning. Fine tuning beats traditional techniques.</p>\n\n<p>The main exception is explainability. e.g. &quot;I want to find the kinds of phrases that are more commonly appearing in the transcript logs of X vs Y&quot; -&gt; the goal isn&#39;t to create a great predictor, the goal is to provide some insights.</p>\n</div>",
      "created_utc": 1729486627.0,
      "score": -4,
      "ups": -4,
      "downs": 0,
      "permalink": "/r/LanguageTechnology/comments/1g8brrn/is_pos_tagging_like_with_viterbi_hmm_still_useful/lsymf02/",
      "parent_id": "t3_1g8brrn",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2024-10-20T21:57:07"
    },
    {
      "id": "lsxpro8",
      "author": "Fuehnix",
      "body": "How much data do you need to get BERT finetuned to a point where it outperforms something like Llama 3 70b + system prompt and few shot example?\n\nI have all the foundational knowledge to implement BERT, but haven't done it, so just want to know how much time I would need to devote to making training data before I propose BERT as a solution to my manager.\n\n*Obviously a very very rough question, but I just want to know what order of magnitude we're talking about in terms of examples.\n\n10s, 100s, 1000s, 10000s, higher?",
      "body_html": "<div class=\"md\"><p>How much data do you need to get BERT finetuned to a point where it outperforms something like Llama 3 70b + system prompt and few shot example?</p>\n\n<p>I have all the foundational knowledge to implement BERT, but haven&#39;t done it, so just want to know how much time I would need to devote to making training data before I propose BERT as a solution to my manager.</p>\n\n<p>*Obviously a very very rough question, but I just want to know what order of magnitude we&#39;re talking about in terms of examples.</p>\n\n<p>10s, 100s, 1000s, 10000s, higher?</p>\n</div>",
      "created_utc": 1729472941.0,
      "score": 4,
      "ups": 4,
      "downs": 0,
      "permalink": "/r/LanguageTechnology/comments/1g8brrn/is_pos_tagging_like_with_viterbi_hmm_still_useful/lsxpro8/",
      "parent_id": "t1_lsxdx02",
      "depth": 1,
      "is_submitter": true,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2024-10-20T18:09:01"
    },
    {
      "id": "lt1z71z",
      "author": "pmp22",
      "body": "Just out of curiosity, how does that compare to say GPT-4o or Claude 3.5? They are both very good at Latin, and from my testing it seems like they have some understanding of ancient Greek too. You could enable tool use and have the LLM pull from a dictionary or other sources too, and have it use in context reasoning to possibly provide a much richer context.",
      "body_html": "<div class=\"md\"><p>Just out of curiosity, how does that compare to say GPT-4o or Claude 3.5? They are both very good at Latin, and from my testing it seems like they have some understanding of ancient Greek too. You could enable tool use and have the LLM pull from a dictionary or other sources too, and have it use in context reasoning to possibly provide a much richer context.</p>\n</div>",
      "created_utc": 1729538809.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/LanguageTechnology/comments/1g8brrn/is_pos_tagging_like_with_viterbi_hmm_still_useful/lt1z71z/",
      "parent_id": "t1_lsxiu8c",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2024-10-21T12:26:49"
    },
    {
      "id": "lsxsv4b",
      "author": null,
      "body": "Depends heavily on the task. For example, something dealing with 16th or 17th century English, a fine tuned BERT would likely vastly outperform with very little data. But for contemporary sentiment analysis for example, its possible that BERT would never beat few shot LLaMa. \n\nAlso, cost is a consideration; even fine tuning BERT now is almost free.",
      "body_html": "<div class=\"md\"><p>Depends heavily on the task. For example, something dealing with 16th or 17th century English, a fine tuned BERT would likely vastly outperform with very little data. But for contemporary sentiment analysis for example, its possible that BERT would never beat few shot LLaMa. </p>\n\n<p>Also, cost is a consideration; even fine tuning BERT now is almost free.</p>\n</div>",
      "created_utc": 1729474097.0,
      "score": 5,
      "ups": 5,
      "downs": 0,
      "permalink": "/r/LanguageTechnology/comments/1g8brrn/is_pos_tagging_like_with_viterbi_hmm_still_useful/lsxsv4b/",
      "parent_id": "t1_lsxpro8",
      "depth": 2,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2024-10-20T18:28:17"
    },
    {
      "id": "lsyslqj",
      "author": "mocny-chlapik",
      "body": "Depends on the task really, but usually it is in thousands. IMO LLMs are worth it in cases where you really need the interactivity of a chatbot or when you have a nontrivial output space. But for a regular NLP text processing tasks such as classification it is usually cheaper, more efficient and more accurate to run a smaller model.",
      "body_html": "<div class=\"md\"><p>Depends on the task really, but usually it is in thousands. IMO LLMs are worth it in cases where you really need the interactivity of a chatbot or when you have a nontrivial output space. But for a regular NLP text processing tasks such as classification it is usually cheaper, more efficient and more accurate to run a smaller model.</p>\n</div>",
      "created_utc": 1729490231.0,
      "score": 3,
      "ups": 3,
      "downs": 0,
      "permalink": "/r/LanguageTechnology/comments/1g8brrn/is_pos_tagging_like_with_viterbi_hmm_still_useful/lsyslqj/",
      "parent_id": "t1_lsxpro8",
      "depth": 2,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2024-10-20T22:57:11"
    },
    {
      "id": "lt27b9x",
      "author": "benjamin-crowell",
      "body": "Are you talking about something like sending an LLM an English-language query through an API, like \"What part of speech is ἀποθανεῖν?\" I guess you could do that, but it would take ~1000 times more computational effort per word, which would make it totally impractical. The best tools specifically designed for the purpose have a failure rate of something like 0.8% per word, and when they fail, they tell you that rather than hallucinating an answer. Hard to believe that an LLM would be at all competitive with that level of reliability.",
      "body_html": "<div class=\"md\"><p>Are you talking about something like sending an LLM an English-language query through an API, like &quot;What part of speech is ἀποθανεῖν?&quot; I guess you could do that, but it would take ~1000 times more computational effort per word, which would make it totally impractical. The best tools specifically designed for the purpose have a failure rate of something like 0.8% per word, and when they fail, they tell you that rather than hallucinating an answer. Hard to believe that an LLM would be at all competitive with that level of reliability.</p>\n</div>",
      "created_utc": 1729541280.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/LanguageTechnology/comments/1g8brrn/is_pos_tagging_like_with_viterbi_hmm_still_useful/lt27b9x/",
      "parent_id": "t1_lt1z71z",
      "depth": 2,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2024-10-21T13:08:00"
    },
    {
      "id": "lt23h5j",
      "author": "Tsahanzam",
      "body": "fine-tuned roberta does beat or match LLaMa on a lot of sentiment analysis datasets at a fraction of the cost. if you look at sentiment analysis on paperswithcode, a lot of the leaderboard is various BERT-likes.",
      "body_html": "<div class=\"md\"><p>fine-tuned roberta does beat or match LLaMa on a lot of sentiment analysis datasets at a fraction of the cost. if you look at sentiment analysis on paperswithcode, a lot of the leaderboard is various BERT-likes.</p>\n</div>",
      "created_utc": 1729540115.0,
      "score": 2,
      "ups": 2,
      "downs": 0,
      "permalink": "/r/LanguageTechnology/comments/1g8brrn/is_pos_tagging_like_with_viterbi_hmm_still_useful/lt23h5j/",
      "parent_id": "t1_lsxsv4b",
      "depth": 3,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2024-10-21T12:48:35"
    },
    {
      "id": "lsypits",
      "author": "Sokorai",
      "body": "One thing to consider: even papers like the one from Brown et Al. 2020 or from the setfit authors show that LLMs or contrastive approaches suck, when you leave simple binary sentiment tasks.",
      "body_html": "<div class=\"md\"><p>One thing to consider: even papers like the one from Brown et Al. 2020 or from the setfit authors show that LLMs or contrastive approaches suck, when you leave simple binary sentiment tasks.</p>\n</div>",
      "created_utc": 1729488388.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/LanguageTechnology/comments/1g8brrn/is_pos_tagging_like_with_viterbi_hmm_still_useful/lsypits/",
      "parent_id": "t1_lsxsv4b",
      "depth": 3,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2024-10-20T22:26:28"
    },
    {
      "id": "lt2o5yo",
      "author": "pmp22",
      "body": "I agree that the reliability and computational costs are strong points for this method, the argument I tried to make was that in the context of learning a language LLMs could enhance the learning experience in ways that old-school lookup tools can't. For a language learner, it's not just about identifying the lemma or POS—it's about understanding how the word fits into the broader context of a sentence, its nuances, idiomatic usage, or even how that word has evolved over time. LLMs like GPT-4o etc. could potentially provide explanations that go beyond a simple gloss or translation, offering insights into how a particular form is used in classical texts, or even suggesting parallel constructions in related languages like Latin. But it could do this as well as providing the part of speech! That said I'm not that familiar with ancient greek so I don't know how good (or bad) current LLMs are at that, however I know they are so good at Latin that they can be used a personal latin teacher - I do it daily and it's just amazing.",
      "body_html": "<div class=\"md\"><p>I agree that the reliability and computational costs are strong points for this method, the argument I tried to make was that in the context of learning a language LLMs could enhance the learning experience in ways that old-school lookup tools can&#39;t. For a language learner, it&#39;s not just about identifying the lemma or POS—it&#39;s about understanding how the word fits into the broader context of a sentence, its nuances, idiomatic usage, or even how that word has evolved over time. LLMs like GPT-4o etc. could potentially provide explanations that go beyond a simple gloss or translation, offering insights into how a particular form is used in classical texts, or even suggesting parallel constructions in related languages like Latin. But it could do this as well as providing the part of speech! That said I&#39;m not that familiar with ancient greek so I don&#39;t know how good (or bad) current LLMs are at that, however I know they are so good at Latin that they can be used a personal latin teacher - I do it daily and it&#39;s just amazing.</p>\n</div>",
      "created_utc": 1729546335.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/LanguageTechnology/comments/1g8brrn/is_pos_tagging_like_with_viterbi_hmm_still_useful/lt2o5yo/",
      "parent_id": "t1_lt27b9x",
      "depth": 3,
      "is_submitter": false,
      "stickied": false,
      "edited": true,
      "distinguished": null,
      "timestamp": "2024-10-21T14:32:15"
    }
  ],
  "total_comments": 13,
  "fetched_at": "2025-09-13T20:47:21.220511"
}