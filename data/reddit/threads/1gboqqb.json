{
  "submission": {
    "id": "1gboqqb",
    "title": "Opinion on automatic trainings on merges to a stage (CICD)",
    "author": "SkillLevelAsia",
    "selftext": "Hello :)\n\nI was wondering what the opinion on automatic trainings (CI Pipeline) after merging code to a branch that is related to a stage (dev, preprod, prod) is. \n\nSo in our current setup, we detect changes in the Kubeflow Pipelines in a GitHub Repository. if there are any changes, we trigger an e2e test when a PR is opened from a branch to dev, which runs the ml pipeline with reduced data.\n\nI was wondering if we should also trigger an ml pipeline from our GitHub actions, once someone merges from  dev to preprod or from preprod to prod. The Git Repos are monorepos and there are lots of web services in each repo and other non MLOps related things. Therefore I would only trigger the kubeflow pipeline automatically after a merge, if the change detection has found changes in them.\n\nThere is also multiple Pipelines in a repository, which means that it is possible that multiple Kubeflow Pipelines would be triggered automatically, based on if they have changes.\n\nI am thinking to go with the approach of running changed Pipelines on preprod and prod after a Merge, but I am also not sure if I am missing something, why that would be a bad idea.\n\nThere is a YAML file at the repo root, which can be used to turn of these automatic tests and trainings. \n\nHappy for any input on how you would handle this.\n\nOptions:\n\n1. Always run all ML Pipelines on Merge \n2. Run ML Pipelines with Changes only (If people wanna retrain they can just use the scheduling options built for them)\n3. Let People run Pipelines manually after a merge with http Client or via a UI where they can trigger them\n",
    "selftext_html": "<!-- SC_OFF --><div class=\"md\"><p>Hello :)</p>\n\n<p>I was wondering what the opinion on automatic trainings (CI Pipeline) after merging code to a branch that is related to a stage (dev, preprod, prod) is. </p>\n\n<p>So in our current setup, we detect changes in the Kubeflow Pipelines in a GitHub Repository. if there are any changes, we trigger an e2e test when a PR is opened from a branch to dev, which runs the ml pipeline with reduced data.</p>\n\n<p>I was wondering if we should also trigger an ml pipeline from our GitHub actions, once someone merges from  dev to preprod or from preprod to prod. The Git Repos are monorepos and there are lots of web services in each repo and other non MLOps related things. Therefore I would only trigger the kubeflow pipeline automatically after a merge, if the change detection has found changes in them.</p>\n\n<p>There is also multiple Pipelines in a repository, which means that it is possible that multiple Kubeflow Pipelines would be triggered automatically, based on if they have changes.</p>\n\n<p>I am thinking to go with the approach of running changed Pipelines on preprod and prod after a Merge, but I am also not sure if I am missing something, why that would be a bad idea.</p>\n\n<p>There is a YAML file at the repo root, which can be used to turn of these automatic tests and trainings. </p>\n\n<p>Happy for any input on how you would handle this.</p>\n\n<p>Options:</p>\n\n<ol>\n<li>Always run all ML Pipelines on Merge </li>\n<li>Run ML Pipelines with Changes only (If people wanna retrain they can just use the scheduling options built for them)</li>\n<li>Let People run Pipelines manually after a merge with http Client or via a UI where they can trigger them</li>\n</ol>\n</div><!-- SC_ON -->",
    "url": "https://www.reddit.com/r/mlops/comments/1gboqqb/opinion_on_automatic_trainings_on_merges_to_a/",
    "permalink": "/r/mlops/comments/1gboqqb/opinion_on_automatic_trainings_on_merges_to_a/",
    "subreddit": "mlops",
    "created_utc": 1729841571.0,
    "score": 3,
    "ups": 3,
    "downs": 0,
    "upvote_ratio": 1.0,
    "num_comments": 4,
    "is_self": true,
    "over_18": false,
    "spoiler": false,
    "stickied": false,
    "locked": false,
    "archived": false,
    "distinguished": null,
    "link_flair_text": null,
    "timestamp": "2024-10-25T00:32:51"
  },
  "comments": [
    {
      "id": "lto6m4m",
      "author": "mikhola",
      "body": "Do any the KF pipelines in the repo have any inter-dependencies?  Or if there are frequent changes by different devs on the same pipelines? If so, then ideally all dependent pipelines’ e2e tests need to be ran on the PR merge. This is essentially integration testing.  However, in my experience,  training pipelines are pretty self-contained.  The e2e test runs on PR hopefully would catch any regression issues.  There is no need to run again on PR merge.  You’ll just run the same thing twice.  2nd run doesn’t had any value.",
      "body_html": "<div class=\"md\"><p>Do any the KF pipelines in the repo have any inter-dependencies?  Or if there are frequent changes by different devs on the same pipelines? If so, then ideally all dependent pipelines’ e2e tests need to be ran on the PR merge. This is essentially integration testing.  However, in my experience,  training pipelines are pretty self-contained.  The e2e test runs on PR hopefully would catch any regression issues.  There is no need to run again on PR merge.  You’ll just run the same thing twice.  2nd run doesn’t had any value.</p>\n</div>",
      "created_utc": 1729858452.0,
      "score": 2,
      "ups": 2,
      "downs": 0,
      "permalink": "/r/mlops/comments/1gboqqb/opinion_on_automatic_trainings_on_merges_to_a/lto6m4m/",
      "parent_id": "t3_1gboqqb",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2024-10-25T05:14:12"
    },
    {
      "id": "ltpar9v",
      "author": "trnka",
      "body": "Just jotting some notes, hope this helps!\n\n* Do you sometimes need to re-train without a code change? Just calling it out - It's easy enough to have multiple triggers for training\n* I don't feel good about any possibility of having different models in dev, pre-prod, and prod. Models are sometimes sensitive to random initialization so that could lead to very weird bugs where the same hyperparameters and data lead to different models in each env (or worse, those pipelines are run at slightly different times so they have different training data). I'd feel much better having the exact same binary artifact in all stages, especially if there's any e2e testing in dev or pre-prod.\n* In general I think it's good to have automated rebuilds for models. In my old team we once had a bug with one model because the developer thought they rebuilt it, but had copy-pasted another model on top of the file to try something out and committed that (but with the evaluation reports for the correct model). Rebuilding on merge to main would've prevented any issues. Luckily we caught it in dev or staging\n* It'd be nice to have manual review of evaluation reports after training before any model has a chance to go to prod",
      "body_html": "<div class=\"md\"><p>Just jotting some notes, hope this helps!</p>\n\n<ul>\n<li>Do you sometimes need to re-train without a code change? Just calling it out - It&#39;s easy enough to have multiple triggers for training</li>\n<li>I don&#39;t feel good about any possibility of having different models in dev, pre-prod, and prod. Models are sometimes sensitive to random initialization so that could lead to very weird bugs where the same hyperparameters and data lead to different models in each env (or worse, those pipelines are run at slightly different times so they have different training data). I&#39;d feel much better having the exact same binary artifact in all stages, especially if there&#39;s any e2e testing in dev or pre-prod.</li>\n<li>In general I think it&#39;s good to have automated rebuilds for models. In my old team we once had a bug with one model because the developer thought they rebuilt it, but had copy-pasted another model on top of the file to try something out and committed that (but with the evaluation reports for the correct model). Rebuilding on merge to main would&#39;ve prevented any issues. Luckily we caught it in dev or staging</li>\n<li>It&#39;d be nice to have manual review of evaluation reports after training before any model has a chance to go to prod</li>\n</ul>\n</div>",
      "created_utc": 1729872027.0,
      "score": 2,
      "ups": 2,
      "downs": 0,
      "permalink": "/r/mlops/comments/1gboqqb/opinion_on_automatic_trainings_on_merges_to_a/ltpar9v/",
      "parent_id": "t3_1gboqqb",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2024-10-25T09:00:27"
    },
    {
      "id": "lto93dv",
      "author": "SkillLevelAsia",
      "body": "The KF Pipelines sometimes use the same images which have frequent changes, because some of the dev teams embedd their shared libraries directly into them.\n\nIt's not about having a second e2e test but triggering a full training on a merge to prod for example. I know that a second test wouldn't really do much.\n\nI have found a solution that i will try for now:  the devs can configure a YAML file to configure on which stages and on what action (PR, Merge commit) they want their KF pipelines to run. The default will be configured to trigger an e2e test on opening or commiting to a pull request from branch -> dev.",
      "body_html": "<div class=\"md\"><p>The KF Pipelines sometimes use the same images which have frequent changes, because some of the dev teams embedd their shared libraries directly into them.</p>\n\n<p>It&#39;s not about having a second e2e test but triggering a full training on a merge to prod for example. I know that a second test wouldn&#39;t really do much.</p>\n\n<p>I have found a solution that i will try for now:  the devs can configure a YAML file to configure on which stages and on what action (PR, Merge commit) they want their KF pipelines to run. The default will be configured to trigger an e2e test on opening or commiting to a pull request from branch -&gt; dev.</p>\n</div>",
      "created_utc": 1729859472.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/mlops/comments/1gboqqb/opinion_on_automatic_trainings_on_merges_to_a/lto93dv/",
      "parent_id": "t1_lto6m4m",
      "depth": 1,
      "is_submitter": true,
      "stickied": false,
      "edited": true,
      "distinguished": null,
      "timestamp": "2024-10-25T05:31:12"
    },
    {
      "id": "ltpsbry",
      "author": "mikhola",
      "body": "it's one way to deal with it, defer to decision to the devs...lol.  Danger is if the dev is clueless, they might shoot themselves in the foot.  You can somewhat mitigate this by documenting it clearly and offer some best practices, i.e, don't run same e2e test in multiple stages.",
      "body_html": "<div class=\"md\"><p>it&#39;s one way to deal with it, defer to decision to the devs...lol.  Danger is if the dev is clueless, they might shoot themselves in the foot.  You can somewhat mitigate this by documenting it clearly and offer some best practices, i.e, don&#39;t run same e2e test in multiple stages.</p>\n</div>",
      "created_utc": 1729877369.0,
      "score": 2,
      "ups": 2,
      "downs": 0,
      "permalink": "/r/mlops/comments/1gboqqb/opinion_on_automatic_trainings_on_merges_to_a/ltpsbry/",
      "parent_id": "t1_lto93dv",
      "depth": 2,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2024-10-25T10:29:29"
    }
  ],
  "total_comments": 4,
  "fetched_at": "2025-09-13T20:47:14.701392"
}