{
  "submission": {
    "id": "10xrvl1",
    "title": "[deleted by user]",
    "author": null,
    "selftext": "[removed]",
    "selftext_html": "<!-- SC_OFF --><div class=\"md\"><p>[removed]</p>\n</div><!-- SC_ON -->",
    "url": "",
    "permalink": "/r/LanguageTechnology/comments/10xrvl1/deleted_by_user/",
    "subreddit": "LanguageTechnology",
    "created_utc": 1675939908.0,
    "score": 10,
    "ups": 10,
    "downs": 0,
    "upvote_ratio": 0.92,
    "num_comments": 7,
    "is_self": true,
    "over_18": false,
    "spoiler": false,
    "stickied": false,
    "locked": false,
    "archived": false,
    "distinguished": null,
    "link_flair_text": null,
    "timestamp": "2023-02-09T02:51:48"
  },
  "comments": [
    {
      "id": "j7u1mb1",
      "author": "CKtalon",
      "body": "Transformers have long taken over the field in the past 4+ years. Check out the yearly WMT and see what methods are used.\n\nRead up on Meta’s NLLB.",
      "body_html": "<div class=\"md\"><p>Transformers have long taken over the field in the past 4+ years. Check out the yearly WMT and see what methods are used.</p>\n\n<p>Read up on Meta’s NLLB.</p>\n</div>",
      "created_utc": 1675944798.0,
      "score": 6,
      "ups": 6,
      "downs": 0,
      "permalink": "/r/LanguageTechnology/comments/10xrvl1/deleted_by_user/j7u1mb1/",
      "parent_id": "t3_10xrvl1",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-09T04:13:18"
    },
    {
      "id": "j7uaape",
      "author": "trnka",
      "body": "\\+1 for transformers.\n\nAlso, there are tutorials like [https://pytorch.org/tutorials/intermediate/seq2seq\\_translation\\_tutorial.html](https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html) to get started. 2 months should be fine so long as you don't get side-tracked by some of the hard problems like getting data for low-resource languages.",
      "body_html": "<div class=\"md\"><p>+1 for transformers.</p>\n\n<p>Also, there are tutorials like <a href=\"https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html\">https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html</a> to get started. 2 months should be fine so long as you don&#39;t get side-tracked by some of the hard problems like getting data for low-resource languages.</p>\n</div>",
      "created_utc": 1675949711.0,
      "score": 2,
      "ups": 2,
      "downs": 0,
      "permalink": "/r/LanguageTechnology/comments/10xrvl1/deleted_by_user/j7uaape/",
      "parent_id": "t3_10xrvl1",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-09T05:35:11"
    },
    {
      "id": "j7w1qv4",
      "author": "ag0",
      "body": "[fairseq](https://fairseq.readthedocs.io/) and [OpenNMT](https://opennmt.net/) are very good starting points if you want to train your NMT model from scratch.\n\n[Huggingface](https://huggingface.co/docs/transformers/v4.26.1/en/tasks/translation#train) supports the training of seq2seq models too, with the advantages that you could finetune an existing model (if you have the resources for it)",
      "body_html": "<div class=\"md\"><p><a href=\"https://fairseq.readthedocs.io/\">fairseq</a> and <a href=\"https://opennmt.net/\">OpenNMT</a> are very good starting points if you want to train your NMT model from scratch.</p>\n\n<p><a href=\"https://huggingface.co/docs/transformers/v4.26.1/en/tasks/translation#train\">Huggingface</a> supports the training of seq2seq models too, with the advantages that you could finetune an existing model (if you have the resources for it)</p>\n</div>",
      "created_utc": 1675974480.0,
      "score": 2,
      "ups": 2,
      "downs": 0,
      "permalink": "/r/LanguageTechnology/comments/10xrvl1/deleted_by_user/j7w1qv4/",
      "parent_id": "t3_10xrvl1",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-09T12:28:00"
    },
    {
      "id": "j7wwjpx",
      "author": "memberjan6",
      "body": "It costs Easily tens of millions of dollars in computer time just to train a SOTA NLP model now from scratch. For example, that first couple of billion that MSFT gave to OpenAI was mostly coupons for using Azure supercomputer to train models. Getting the data together is another insurmountable task too, bc nearly all the worlds accessible writings are being input into the best performers. Also you need to carefully weed out the lower quality unedited writing unless you specifically want that particular type of writing to be learned.\n\nGiant transformers are the best performing nowfor translation.\n\nPractically speaking, fine tuning an already trained model using huggingface or some other hosting might be the best you can do of what you're talking about.",
      "body_html": "<div class=\"md\"><p>It costs Easily tens of millions of dollars in computer time just to train a SOTA NLP model now from scratch. For example, that first couple of billion that MSFT gave to OpenAI was mostly coupons for using Azure supercomputer to train models. Getting the data together is another insurmountable task too, bc nearly all the worlds accessible writings are being input into the best performers. Also you need to carefully weed out the lower quality unedited writing unless you specifically want that particular type of writing to be learned.</p>\n\n<p>Giant transformers are the best performing nowfor translation.</p>\n\n<p>Practically speaking, fine tuning an already trained model using huggingface or some other hosting might be the best you can do of what you&#39;re talking about.</p>\n</div>",
      "created_utc": 1675986555.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/LanguageTechnology/comments/10xrvl1/deleted_by_user/j7wwjpx/",
      "parent_id": "t3_10xrvl1",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": true,
      "distinguished": null,
      "timestamp": "2023-02-09T15:49:15"
    },
    {
      "id": "j7ugygu",
      "author": null,
      "body": "Thanks for the advice! Is there any scope for research by an undergrad like me or is it taken over by the big guys like meta and Google?",
      "body_html": "<div class=\"md\"><p>Thanks for the advice! Is there any scope for research by an undergrad like me or is it taken over by the big guys like meta and Google?</p>\n</div>",
      "created_utc": 1675952841.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/LanguageTechnology/comments/10xrvl1/deleted_by_user/j7ugygu/",
      "parent_id": "t1_j7u1mb1",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-09T06:27:21"
    },
    {
      "id": "j7uh3sc",
      "author": null,
      "body": "Thanks! I'll just be working on Indian language who's dataset is provided by the university of Helsinki. That should be more than enough for my use case.",
      "body_html": "<div class=\"md\"><p>Thanks! I&#39;ll just be working on Indian language who&#39;s dataset is provided by the university of Helsinki. That should be more than enough for my use case.</p>\n</div>",
      "created_utc": 1675952906.0,
      "score": 2,
      "ups": 2,
      "downs": 0,
      "permalink": "/r/LanguageTechnology/comments/10xrvl1/deleted_by_user/j7uh3sc/",
      "parent_id": "t1_j7uaape",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-09T06:28:26"
    },
    {
      "id": "j7uhnb0",
      "author": "CKtalon",
      "body": "I don't think there's any for research, but producing a model in a very specific domain  that exceeds general models might be possible.",
      "body_html": "<div class=\"md\"><p>I don&#39;t think there&#39;s any for research, but producing a model in a very specific domain  that exceeds general models might be possible.</p>\n</div>",
      "created_utc": 1675953148.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/LanguageTechnology/comments/10xrvl1/deleted_by_user/j7uhnb0/",
      "parent_id": "t1_j7ugygu",
      "depth": 2,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-02-09T06:32:28"
    }
  ],
  "total_comments": 7,
  "fetched_at": "2025-09-13T20:47:14.249078"
}