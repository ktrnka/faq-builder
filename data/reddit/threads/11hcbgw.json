{
  "submission": {
    "id": "11hcbgw",
    "title": "Is DataBricks worth it?",
    "author": "spiritualquestions",
    "selftext": "Hello, \n\nI am working as an MLE at a small health tech start up, when I started there was not any data or ML infrastructure in place. We are very much in the experimental phase of our project. However, I am noticing as our project grows in complexity it is becoming hard to track and manage. \n\nI was looking for unbiased feelings about DataBricks for small businesses getting up and running with ML. Meaning we have a fairly simple structured classification problem, but want to be able manage our data, track our experiments, use CI/CD, deploy and monitor our models, so we don't become another statistic of companies that have failing machine learning projects. \n\nAs I looked into how to navigate the growing project complexity, it seems like DataBricks has allot of the functionality and tools that could help in this area. I was already starting to implement experiment tracking in mlflow, automated slack messages, autoML reports, auto generated SHAP plots, and allot more, but DataBricks seems to already handle these types of issues, so it seems like a big waste of time for me to and my team to try to write this things from scratch (no need to reinvent the wheel).  \n\n**Am I being swindled into thinking that DataBricks can kind of \"do it all\"? Have you used data bricks successfully in our business? Is DataBricks actually useful or meh?  What are some of the draw back with DataBricks? Is it affordable or expensive? Have you had a positive/negative experience using DataBricks?**",
    "selftext_html": "<!-- SC_OFF --><div class=\"md\"><p>Hello, </p>\n\n<p>I am working as an MLE at a small health tech start up, when I started there was not any data or ML infrastructure in place. We are very much in the experimental phase of our project. However, I am noticing as our project grows in complexity it is becoming hard to track and manage. </p>\n\n<p>I was looking for unbiased feelings about DataBricks for small businesses getting up and running with ML. Meaning we have a fairly simple structured classification problem, but want to be able manage our data, track our experiments, use CI/CD, deploy and monitor our models, so we don&#39;t become another statistic of companies that have failing machine learning projects. </p>\n\n<p>As I looked into how to navigate the growing project complexity, it seems like DataBricks has allot of the functionality and tools that could help in this area. I was already starting to implement experiment tracking in mlflow, automated slack messages, autoML reports, auto generated SHAP plots, and allot more, but DataBricks seems to already handle these types of issues, so it seems like a big waste of time for me to and my team to try to write this things from scratch (no need to reinvent the wheel).  </p>\n\n<p><strong>Am I being swindled into thinking that DataBricks can kind of &quot;do it all&quot;? Have you used data bricks successfully in our business? Is DataBricks actually useful or meh?  What are some of the draw back with DataBricks? Is it affordable or expensive? Have you had a positive/negative experience using DataBricks?</strong></p>\n</div><!-- SC_ON -->",
    "url": "https://www.reddit.com/r/mlops/comments/11hcbgw/is_databricks_worth_it/",
    "permalink": "/r/mlops/comments/11hcbgw/is_databricks_worth_it/",
    "subreddit": "mlops",
    "created_utc": 1677871627.0,
    "score": 30,
    "ups": 30,
    "downs": 0,
    "upvote_ratio": 1.0,
    "num_comments": 35,
    "is_self": true,
    "over_18": false,
    "spoiler": false,
    "stickied": false,
    "locked": false,
    "archived": false,
    "distinguished": null,
    "link_flair_text": null,
    "timestamp": "2023-03-03T11:27:07"
  },
  "comments": [
    {
      "id": "jat8m64",
      "author": "trnka",
      "body": "My team evaluated Databricks for a healthtech startup too! We did a proof of concept with them and it seemed like it would've been a good fit for notebooks, but the cost of the HIPAA compliant offering was just too high for us. I don't think we would've been able to use their model deployment because we had to keep it in a separate AWS account and cross-account access from our main services was a lot of work.\n\nWe ended up with a pretty \"manual\" stack - Jenkins for CI/CD and to trigger training jobs. Sagemaker for training. DVC for model versioning. CDK/Lambda/etc for serving. Cloudwatch Metrics for monitoring. An internal blog for \"experiment tracking\".\n\nI'm happy to share more if there's anything you'd like to hear more about.",
      "body_html": "<div class=\"md\"><p>My team evaluated Databricks for a healthtech startup too! We did a proof of concept with them and it seemed like it would&#39;ve been a good fit for notebooks, but the cost of the HIPAA compliant offering was just too high for us. I don&#39;t think we would&#39;ve been able to use their model deployment because we had to keep it in a separate AWS account and cross-account access from our main services was a lot of work.</p>\n\n<p>We ended up with a pretty &quot;manual&quot; stack - Jenkins for CI/CD and to trigger training jobs. Sagemaker for training. DVC for model versioning. CDK/Lambda/etc for serving. Cloudwatch Metrics for monitoring. An internal blog for &quot;experiment tracking&quot;.</p>\n\n<p>I&#39;m happy to share more if there&#39;s anything you&#39;d like to hear more about.</p>\n</div>",
      "created_utc": 1677881340.0,
      "score": 21,
      "ups": 21,
      "downs": 0,
      "permalink": "/r/mlops/comments/11hcbgw/is_databricks_worth_it/jat8m64/",
      "parent_id": "t3_11hcbgw",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-03T14:09:00"
    },
    {
      "id": "jauir9z",
      "author": null,
      "body": "I worked briefly (4 months) with databricks. I didn’t have a chance to “get it”. Like it works fine but I find that it’s just the perfect way to incentivize everyone to write shit code. I collaborated with an otherwise very smart Senior DS on a project where he made very quick progress creating a dozen copy-pasta notebooks that you had to know to run in the correct order to get your results. Everyone was working like that. No structure whatsoever.\n\nSo sure it gives you compute and clusters and stuff but it seems so lame after working with airflow and dbt etc.. I don’t get it at all.\n\nI would love some explanation from someone who gets it",
      "body_html": "<div class=\"md\"><p>I worked briefly (4 months) with databricks. I didn’t have a chance to “get it”. Like it works fine but I find that it’s just the perfect way to incentivize everyone to write shit code. I collaborated with an otherwise very smart Senior DS on a project where he made very quick progress creating a dozen copy-pasta notebooks that you had to know to run in the correct order to get your results. Everyone was working like that. No structure whatsoever.</p>\n\n<p>So sure it gives you compute and clusters and stuff but it seems so lame after working with airflow and dbt etc.. I don’t get it at all.</p>\n\n<p>I would love some explanation from someone who gets it</p>\n</div>",
      "created_utc": 1677903202.0,
      "score": 11,
      "ups": 11,
      "downs": 0,
      "permalink": "/r/mlops/comments/11hcbgw/is_databricks_worth_it/jauir9z/",
      "parent_id": "t3_11hcbgw",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": true,
      "distinguished": null,
      "timestamp": "2023-03-03T20:13:22"
    },
    {
      "id": "jaux4fp",
      "author": "Grouchy-Friend4235",
      "body": "We looked at databricks (DABR) vs other platforms.\nHere's what we found:\n\n* DABR is at its core Spark with a predefined deployment model, yes easy to scale - if you need it\n\n* while you can run other code, unless you need Spark's scalability (we didn't), it is just too much overhead and too complex\n\n* there is a lot of salesy promises for features you will probably not need, and if you do, it's not really up to the job, unless you go all in to their somewhat opinionated approach (like deltalake and mlflow)\n\n* their pricing is beyond sensible, essentially it doubles the compute cost. \n\nAnother concern is how easy it is to find people with experience in the tech stack you use. We found that DABR skills are rare and tend to be priced higher relative to more broadly used tech. We actually interviewed a small number of candidates (~5) with prior DABR experience and probed them for their experience with it. It struck us as odd that all of them said they would prefer not to work with DABR if the project allowed it.\n\nBeware this may be totally biased because our senior tech team, including myself, are well versed in full stack analytics and software engineering in general we may just not be in DABR's target segment.",
      "body_html": "<div class=\"md\"><p>We looked at databricks (DABR) vs other platforms.\nHere&#39;s what we found:</p>\n\n<ul>\n<li><p>DABR is at its core Spark with a predefined deployment model, yes easy to scale - if you need it</p></li>\n<li><p>while you can run other code, unless you need Spark&#39;s scalability (we didn&#39;t), it is just too much overhead and too complex</p></li>\n<li><p>there is a lot of salesy promises for features you will probably not need, and if you do, it&#39;s not really up to the job, unless you go all in to their somewhat opinionated approach (like deltalake and mlflow)</p></li>\n<li><p>their pricing is beyond sensible, essentially it doubles the compute cost. </p></li>\n</ul>\n\n<p>Another concern is how easy it is to find people with experience in the tech stack you use. We found that DABR skills are rare and tend to be priced higher relative to more broadly used tech. We actually interviewed a small number of candidates (~5) with prior DABR experience and probed them for their experience with it. It struck us as odd that all of them said they would prefer not to work with DABR if the project allowed it.</p>\n\n<p>Beware this may be totally biased because our senior tech team, including myself, are well versed in full stack analytics and software engineering in general we may just not be in DABR&#39;s target segment.</p>\n</div>",
      "created_utc": 1677912337.0,
      "score": 6,
      "ups": 6,
      "downs": 0,
      "permalink": "/r/mlops/comments/11hcbgw/is_databricks_worth_it/jaux4fp/",
      "parent_id": "t3_11hcbgw",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": true,
      "distinguished": null,
      "timestamp": "2023-03-03T22:45:37"
    },
    {
      "id": "jatutay",
      "author": null,
      "body": "It’s okay, they do some legit engineering, I wouldn’t call it awesome but it can usually get the job done",
      "body_html": "<div class=\"md\"><p>It’s okay, they do some legit engineering, I wouldn’t call it awesome but it can usually get the job done</p>\n</div>",
      "created_utc": 1677891255.0,
      "score": 5,
      "ups": 5,
      "downs": 0,
      "permalink": "/r/mlops/comments/11hcbgw/is_databricks_worth_it/jatutay/",
      "parent_id": "t3_11hcbgw",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-03T16:54:15"
    },
    {
      "id": "jawh3gg",
      "author": "Vnix7",
      "body": "It is definitely worth it. Also a MLE here. It’s simplistic and easy to implement MLOps processes. We deploy models within 1-5 days because of how easy it is. I’m in the retail space at the moment. We use Azure and pair it with ADO for ci/cd. Snowflake is usually our upstream data storage, and ADLS is what we use to store the inference before post processing. Let me know if you have any other questions",
      "body_html": "<div class=\"md\"><p>It is definitely worth it. Also a MLE here. It’s simplistic and easy to implement MLOps processes. We deploy models within 1-5 days because of how easy it is. I’m in the retail space at the moment. We use Azure and pair it with ADO for ci/cd. Snowflake is usually our upstream data storage, and ADLS is what we use to store the inference before post processing. Let me know if you have any other questions</p>\n</div>",
      "created_utc": 1677948018.0,
      "score": 3,
      "ups": 3,
      "downs": 0,
      "permalink": "/r/mlops/comments/11hcbgw/is_databricks_worth_it/jawh3gg/",
      "parent_id": "t3_11hcbgw",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-04T08:40:18"
    },
    {
      "id": "jce0y3q",
      "author": "MeowCatalog",
      "body": "This makes me thinking. Is there a place where people can review and comment on ML tools they use? Price? Service? Usability and value?like yelp ?",
      "body_html": "<div class=\"md\"><p>This makes me thinking. Is there a place where people can review and comment on ML tools they use? Price? Service? Usability and value?like yelp ?</p>\n</div>",
      "created_utc": 1678938157.0,
      "score": 3,
      "ups": 3,
      "downs": 0,
      "permalink": "/r/mlops/comments/11hcbgw/is_databricks_worth_it/jce0y3q/",
      "parent_id": "t3_11hcbgw",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-15T20:42:37"
    },
    {
      "id": "jatdi2x",
      "author": "astroFizzics",
      "body": "We use databricks. I think it's awesome. We're not a small business. We use it for all our data and cloud management. Works great. For stuff like ci/cd we still use github + jenkins. \n\nI like it.",
      "body_html": "<div class=\"md\"><p>We use databricks. I think it&#39;s awesome. We&#39;re not a small business. We use it for all our data and cloud management. Works great. For stuff like ci/cd we still use github + jenkins. </p>\n\n<p>I like it.</p>\n</div>",
      "created_utc": 1677883432.0,
      "score": 2,
      "ups": 2,
      "downs": 0,
      "permalink": "/r/mlops/comments/11hcbgw/is_databricks_worth_it/jatdi2x/",
      "parent_id": "t3_11hcbgw",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-03T14:43:52"
    },
    {
      "id": "jatqmkw",
      "author": "Nofarcastplz",
      "body": "I use dbx in both corporate and in small-companies. Az Devops for build/release and the artefact feed for model-versioning. MLFlow for experiment tracking. Still looking for a good model-monitoring integration tool, I have used custom libraries in the past. \n\nDatabricks requires some tools to complement for what it is lacking, but it works great in general for batch processing. It does not support streaming. \n\nIt is not too costly, but cost does add up if you also develop within databricks, with clusters running for a long time. I love the integration with other Azure components. An alternative cloud-solution would be Sagemaker/AzureML for AWS/Azure. These work fine as well, but im not a big fan of the dropdowns and rather have most stuff coded out. However, this is mostly personal preference.",
      "body_html": "<div class=\"md\"><p>I use dbx in both corporate and in small-companies. Az Devops for build/release and the artefact feed for model-versioning. MLFlow for experiment tracking. Still looking for a good model-monitoring integration tool, I have used custom libraries in the past. </p>\n\n<p>Databricks requires some tools to complement for what it is lacking, but it works great in general for batch processing. It does not support streaming. </p>\n\n<p>It is not too costly, but cost does add up if you also develop within databricks, with clusters running for a long time. I love the integration with other Azure components. An alternative cloud-solution would be Sagemaker/AzureML for AWS/Azure. These work fine as well, but im not a big fan of the dropdowns and rather have most stuff coded out. However, this is mostly personal preference.</p>\n</div>",
      "created_utc": 1677889280.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/mlops/comments/11hcbgw/is_databricks_worth_it/jatqmkw/",
      "parent_id": "t3_11hcbgw",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": true,
      "distinguished": null,
      "timestamp": "2023-03-03T16:21:20"
    },
    {
      "id": "jb1r3u9",
      "author": "Tumphy",
      "body": "We’ve been working with Brytlyt - GPU computing so faster and quicker to implement models than Databricks. Free use on their website too.",
      "body_html": "<div class=\"md\"><p>We’ve been working with Brytlyt - GPU computing so faster and quicker to implement models than Databricks. Free use on their website too.</p>\n</div>",
      "created_utc": 1678045498.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/mlops/comments/11hcbgw/is_databricks_worth_it/jb1r3u9/",
      "parent_id": "t3_11hcbgw",
      "depth": 0,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-05T11:44:58"
    },
    {
      "id": "jatpvqa",
      "author": "spiritualquestions",
      "body": "Thank you! This is really helpful! \n\nEspecially the part of the HIPAA complaint requirement. \n\nI am just curious, how many people do you have on your data/ML/dev ops team that made the more \"manual\" approach possible, and how long has it taken to get it up and running? Also how much data infrastructure was already built when you started to look into DataBricks and the manual stack?",
      "body_html": "<div class=\"md\"><p>Thank you! This is really helpful! </p>\n\n<p>Especially the part of the HIPAA complaint requirement. </p>\n\n<p>I am just curious, how many people do you have on your data/ML/dev ops team that made the more &quot;manual&quot; approach possible, and how long has it taken to get it up and running? Also how much data infrastructure was already built when you started to look into DataBricks and the manual stack?</p>\n</div>",
      "created_utc": 1677888937.0,
      "score": 6,
      "ups": 6,
      "downs": 0,
      "permalink": "/r/mlops/comments/11hcbgw/is_databricks_worth_it/jatpvqa/",
      "parent_id": "t1_jat8m64",
      "depth": 1,
      "is_submitter": true,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-03T16:15:37"
    },
    {
      "id": "jautrp8",
      "author": "andreea-mun",
      "body": "I would suggest you try open source MLOps. Whereas you can try & even use it for free, in case of support, pricing is decent. Take a look at Charmed Kubeflow",
      "body_html": "<div class=\"md\"><p>I would suggest you try open source MLOps. Whereas you can try &amp; even use it for free, in case of support, pricing is decent. Take a look at Charmed Kubeflow</p>\n</div>",
      "created_utc": 1677909923.0,
      "score": 3,
      "ups": 3,
      "downs": 0,
      "permalink": "/r/mlops/comments/11hcbgw/is_databricks_worth_it/jautrp8/",
      "parent_id": "t1_jat8m64",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-03T22:05:23"
    },
    {
      "id": "jatzfyc",
      "author": "m98789",
      "body": "What’s DVC?",
      "body_html": "<div class=\"md\"><p>What’s DVC?</p>\n</div>",
      "created_utc": 1677893501.0,
      "score": 2,
      "ups": 2,
      "downs": 0,
      "permalink": "/r/mlops/comments/11hcbgw/is_databricks_worth_it/jatzfyc/",
      "parent_id": "t1_jat8m64",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-03T17:31:41"
    },
    {
      "id": "jaxgcag",
      "author": "NYDreamer",
      "body": "Could you tell us a bit more about your experiment tracking solution, please? I've never heard of people using a blog before, but it actually makes a lot of sense.",
      "body_html": "<div class=\"md\"><p>Could you tell us a bit more about your experiment tracking solution, please? I&#39;ve never heard of people using a blog before, but it actually makes a lot of sense.</p>\n</div>",
      "created_utc": 1677962381.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/mlops/comments/11hcbgw/is_databricks_worth_it/jaxgcag/",
      "parent_id": "t1_jat8m64",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-04T12:39:41"
    },
    {
      "id": "k829qir",
      "author": "Awkward_Dream_7934",
      "body": "@trnka - We are in a similar boat. Can I DM you for more details? Specifically architecture and scalability related topics, I'm interested in. Kindly let me know if thats ok!",
      "body_html": "<div class=\"md\"><p>@trnka - We are in a similar boat. Can I DM you for more details? Specifically architecture and scalability related topics, I&#39;m interested in. Kindly let me know if thats ok!</p>\n</div>",
      "created_utc": 1699275194.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/mlops/comments/11hcbgw/is_databricks_worth_it/k829qir/",
      "parent_id": "t1_jat8m64",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-11-06T04:53:14"
    },
    {
      "id": "lmfb52q",
      "author": "Sufficient-Result987",
      "body": "Forgive me if it is a noob question, but don't they have Workflows to put the various notebooks together?",
      "body_html": "<div class=\"md\"><p>Forgive me if it is a noob question, but don&#39;t they have Workflows to put the various notebooks together?</p>\n</div>",
      "created_utc": 1725969523.0,
      "score": 2,
      "ups": 2,
      "downs": 0,
      "permalink": "/r/mlops/comments/11hcbgw/is_databricks_worth_it/lmfb52q/",
      "parent_id": "t1_jauir9z",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2024-09-10T04:58:43"
    },
    {
      "id": "jaw0309",
      "author": null,
      "body": "Not shocked. I feel like the only way one would really “enjoy” databricks is if they have never worked with anything else.",
      "body_html": "<div class=\"md\"><p>Not shocked. I feel like the only way one would really “enjoy” databricks is if they have never worked with anything else.</p>\n</div>",
      "created_utc": 1677940701.0,
      "score": 5,
      "ups": 5,
      "downs": 0,
      "permalink": "/r/mlops/comments/11hcbgw/is_databricks_worth_it/jaw0309/",
      "parent_id": "t1_jaux4fp",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-04T06:38:21"
    },
    {
      "id": "jatn5iq",
      "author": "zbir84",
      "body": "Why do you still use Jenkins if you can do the same with GitHub actions? Any particular reason?",
      "body_html": "<div class=\"md\"><p>Why do you still use Jenkins if you can do the same with GitHub actions? Any particular reason?</p>\n</div>",
      "created_utc": 1677887685.0,
      "score": 4,
      "ups": 4,
      "downs": 0,
      "permalink": "/r/mlops/comments/11hcbgw/is_databricks_worth_it/jatn5iq/",
      "parent_id": "t1_jatdi2x",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-03T15:54:45"
    },
    {
      "id": "jaua3ts",
      "author": "astroFizzics",
      "body": "I've done streaming with spark streaming in databricks. It's certainly not as mature as their batch offerings but you can 100% stream in it",
      "body_html": "<div class=\"md\"><p>I&#39;ve done streaming with spark streaming in databricks. It&#39;s certainly not as mature as their batch offerings but you can 100% stream in it</p>\n</div>",
      "created_utc": 1677898683.0,
      "score": 3,
      "ups": 3,
      "downs": 0,
      "permalink": "/r/mlops/comments/11hcbgw/is_databricks_worth_it/jaua3ts/",
      "parent_id": "t1_jatqmkw",
      "depth": 1,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-03T18:58:03"
    },
    {
      "id": "jaw483b",
      "author": "trnka",
      "body": "Our team ranged from about 2-10 people over the years. After we'd grown to about 6, about half were applied research scientists and about half were software engineers. On average we probably had 1-2 people with deep expertise in AWS at any time. Actually that's what got me into MLOps -- it took us a while to hire people with AWS expertise, so I learned a bit myself to at least give our engineers one more person to talk to.\n\nThe very first stack was a manual stack, and we just copied what another team had built on Aptible, did training manually, and used git-lfs for model versioning. That was maybe 6 years ago. That was largely done by one person with the help of our partner teams over the course of 1-2 months.\n\nI think we were looking into Databricks around 4 years ago... I'm pretty sure we were still manually training models every week. I think we were running notebooks locally using Google Drive file sync to share notebooks (GSuite is HIPAA compliant and we had a BAA). We were still using Aptible for serving.\n\nI'd setup an EC2 instance with GPU that we sometimes shared for experimentation, which was fine when there were only 1-2 people building models but not once the team grew. Plus sometimes people would forget to shut it down and we'd have an unexpected bill.\n\nSo when we were looking into Databricks I was mainly thinking about the challenge of doing ML experimentation on PHI in a way that we could easily share our notebooks, and I wanted the compute to scale up and down to balance speed and cost. It would've been nice to replace our serving infrastructure too but that was secondary because Aptible was working fine at the time.\n\nFast forward a few years and Aptible was getting frustrating. The rest of the company was adopting AWS microservices at the time, and there was increasing cross-org tooling for it in CDK.\n\nI prototyped the AWS stack when I had a few days off and I was snowed in, I think, and refined it on and off on weekend. I wrote [a summary here if you're interested](https://medium.com/@keith.trnka/mlops-repo-walkthrough-90c7bd275f53). Then down the line we had someone with AWS experience do a PoC of migrating our Aptible service to either ECS or Lambda. We compared both and Lambda performed better under our load testing, plus it had better cross-org support, so we went with that. I think that project took maybe 3 months from one person to PoC then productionize and do a zero-downtime, quickly-reversible migration. If you're curious, the hard part of that migration was because the service had been integrated in multiple other services and clients by that time and DNS was configured in Terraform. So they added a nice layer of indirection behind DNS so that the switch (either to the new implementation or back to old) was a very fast config change. I was very fortunate to have hired good people who knew more than me in that area.",
      "body_html": "<div class=\"md\"><p>Our team ranged from about 2-10 people over the years. After we&#39;d grown to about 6, about half were applied research scientists and about half were software engineers. On average we probably had 1-2 people with deep expertise in AWS at any time. Actually that&#39;s what got me into MLOps -- it took us a while to hire people with AWS expertise, so I learned a bit myself to at least give our engineers one more person to talk to.</p>\n\n<p>The very first stack was a manual stack, and we just copied what another team had built on Aptible, did training manually, and used git-lfs for model versioning. That was maybe 6 years ago. That was largely done by one person with the help of our partner teams over the course of 1-2 months.</p>\n\n<p>I think we were looking into Databricks around 4 years ago... I&#39;m pretty sure we were still manually training models every week. I think we were running notebooks locally using Google Drive file sync to share notebooks (GSuite is HIPAA compliant and we had a BAA). We were still using Aptible for serving.</p>\n\n<p>I&#39;d setup an EC2 instance with GPU that we sometimes shared for experimentation, which was fine when there were only 1-2 people building models but not once the team grew. Plus sometimes people would forget to shut it down and we&#39;d have an unexpected bill.</p>\n\n<p>So when we were looking into Databricks I was mainly thinking about the challenge of doing ML experimentation on PHI in a way that we could easily share our notebooks, and I wanted the compute to scale up and down to balance speed and cost. It would&#39;ve been nice to replace our serving infrastructure too but that was secondary because Aptible was working fine at the time.</p>\n\n<p>Fast forward a few years and Aptible was getting frustrating. The rest of the company was adopting AWS microservices at the time, and there was increasing cross-org tooling for it in CDK.</p>\n\n<p>I prototyped the AWS stack when I had a few days off and I was snowed in, I think, and refined it on and off on weekend. I wrote <a href=\"https://medium.com/@keith.trnka/mlops-repo-walkthrough-90c7bd275f53\">a summary here if you&#39;re interested</a>. Then down the line we had someone with AWS experience do a PoC of migrating our Aptible service to either ECS or Lambda. We compared both and Lambda performed better under our load testing, plus it had better cross-org support, so we went with that. I think that project took maybe 3 months from one person to PoC then productionize and do a zero-downtime, quickly-reversible migration. If you&#39;re curious, the hard part of that migration was because the service had been integrated in multiple other services and clients by that time and DNS was configured in Terraform. So they added a nice layer of indirection behind DNS so that the switch (either to the new implementation or back to old) was a very fast config change. I was very fortunate to have hired good people who knew more than me in that area.</p>\n</div>",
      "created_utc": 1677942617.0,
      "score": 6,
      "ups": 6,
      "downs": 0,
      "permalink": "/r/mlops/comments/11hcbgw/is_databricks_worth_it/jaw483b/",
      "parent_id": "t1_jatpvqa",
      "depth": 2,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-04T07:10:17"
    },
    {
      "id": "jaw0x6q",
      "author": "trnka",
      "body": "Yeah next time I need to build a stack I'd rather lean on existing tools, whether open source or not. \n\nThe MLOps landscape was pretty dim 4 years ago, and we had a lot of other challenges with internal governance. They required a pretty detailed security review, which could take a while and often just rejected tools. After going through that a few times I felt it was just less stressful to accept a couple months of AWS work rather than a couple months of cross-org frustration. In the end I think that employer was an outlier with security/compliance/governance, and I'm looking forward to using a well-build platform in the future.",
      "body_html": "<div class=\"md\"><p>Yeah next time I need to build a stack I&#39;d rather lean on existing tools, whether open source or not. </p>\n\n<p>The MLOps landscape was pretty dim 4 years ago, and we had a lot of other challenges with internal governance. They required a pretty detailed security review, which could take a while and often just rejected tools. After going through that a few times I felt it was just less stressful to accept a couple months of AWS work rather than a couple months of cross-org frustration. In the end I think that employer was an outlier with security/compliance/governance, and I&#39;m looking forward to using a well-build platform in the future.</p>\n</div>",
      "created_utc": 1677941098.0,
      "score": 3,
      "ups": 3,
      "downs": 0,
      "permalink": "/r/mlops/comments/11hcbgw/is_databricks_worth_it/jaw0x6q/",
      "parent_id": "t1_jautrp8",
      "depth": 2,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-04T06:44:58"
    },
    {
      "id": "jaugc4h",
      "author": "B1WR2",
      "body": "Data version control… basically like source control for datasets",
      "body_html": "<div class=\"md\"><p>Data version control… basically like source control for datasets</p>\n</div>",
      "created_utc": 1677901883.0,
      "score": 2,
      "ups": 2,
      "downs": 0,
      "permalink": "/r/mlops/comments/11hcbgw/is_databricks_worth_it/jaugc4h/",
      "parent_id": "t1_jatzfyc",
      "depth": 2,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-03T19:51:23"
    },
    {
      "id": "jb1jq4e",
      "author": "trnka",
      "body": "Sure, happy to. Whenever someone ran a series of experiments I pushed them to do a writeup on our internal blog in Confluence. We had some other tools that would help with experimentation, for instance an extended version of scikit-learn's hyperparameter tuning that would run statistical testing on each hyperparam, sort them by p-value, and then I'd graph any that were significant or close to it.\n\nWe did internal blogging instead of an experiment tracker for a few reasons:\n\n* Past experience showed me that a table of numbers was often useless without someone explaining their setup, their goals, and so on\n* A blog post is unstructured, which allows a LOT of flexibility compared to just numbers\n* I wanted results to be easy for people to read, not just for our team but also for leadership and adjacent teams. That also meant that if the CTO needed to quote an experimental result, our tracking was available an transparent\n* I wanted to build towards a public blog, even if it couldn't be everything. So I figured it'd be a good way to force the team to practice writing\n\nGenerally I'd say it worked out. We did have a lot of times in which a blog post was useful to our team and to leadership, though it was unpredictable whether that would happen right after posting, or years later. One thing that helped was when I learned to share monthly/quarterly stakeholder updates and I'd include blogs in that.\n\nFor a small team it was reasonably lightweight and I'd do it again. Confluence was somewhat frustrating as an editor though.",
      "body_html": "<div class=\"md\"><p>Sure, happy to. Whenever someone ran a series of experiments I pushed them to do a writeup on our internal blog in Confluence. We had some other tools that would help with experimentation, for instance an extended version of scikit-learn&#39;s hyperparameter tuning that would run statistical testing on each hyperparam, sort them by p-value, and then I&#39;d graph any that were significant or close to it.</p>\n\n<p>We did internal blogging instead of an experiment tracker for a few reasons:</p>\n\n<ul>\n<li>Past experience showed me that a table of numbers was often useless without someone explaining their setup, their goals, and so on</li>\n<li>A blog post is unstructured, which allows a LOT of flexibility compared to just numbers</li>\n<li>I wanted results to be easy for people to read, not just for our team but also for leadership and adjacent teams. That also meant that if the CTO needed to quote an experimental result, our tracking was available an transparent</li>\n<li>I wanted to build towards a public blog, even if it couldn&#39;t be everything. So I figured it&#39;d be a good way to force the team to practice writing</li>\n</ul>\n\n<p>Generally I&#39;d say it worked out. We did have a lot of times in which a blog post was useful to our team and to leadership, though it was unpredictable whether that would happen right after posting, or years later. One thing that helped was when I learned to share monthly/quarterly stakeholder updates and I&#39;d include blogs in that.</p>\n\n<p>For a small team it was reasonably lightweight and I&#39;d do it again. Confluence was somewhat frustrating as an editor though.</p>\n</div>",
      "created_utc": 1678042449.0,
      "score": 3,
      "ups": 3,
      "downs": 0,
      "permalink": "/r/mlops/comments/11hcbgw/is_databricks_worth_it/jb1jq4e/",
      "parent_id": "t1_jaxgcag",
      "depth": 2,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-05T10:54:09"
    },
    {
      "id": "jau9upq",
      "author": "astroFizzics",
      "body": "Tech debt. Migrating to gh actions is something I am gonna really look into this year",
      "body_html": "<div class=\"md\"><p>Tech debt. Migrating to gh actions is something I am gonna really look into this year</p>\n</div>",
      "created_utc": 1677898557.0,
      "score": 3,
      "ups": 3,
      "downs": 0,
      "permalink": "/r/mlops/comments/11hcbgw/is_databricks_worth_it/jau9upq/",
      "parent_id": "t1_jatn5iq",
      "depth": 2,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-03T18:55:57"
    },
    {
      "id": "javeu3i",
      "author": "Nofarcastplz",
      "body": "really, would love to hear more about that!",
      "body_html": "<div class=\"md\"><p>really, would love to hear more about that!</p>\n</div>",
      "created_utc": 1677927090.0,
      "score": 2,
      "ups": 2,
      "downs": 0,
      "permalink": "/r/mlops/comments/11hcbgw/is_databricks_worth_it/javeu3i/",
      "parent_id": "t1_jaua3ts",
      "depth": 2,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-04T02:51:30"
    },
    {
      "id": "jawqcxu",
      "author": "PilotLatter9497",
      "body": "Thank you. What an amazing, complete and detailed answer.",
      "body_html": "<div class=\"md\"><p>Thank you. What an amazing, complete and detailed answer.</p>\n</div>",
      "created_utc": 1677951748.0,
      "score": 2,
      "ups": 2,
      "downs": 0,
      "permalink": "/r/mlops/comments/11hcbgw/is_databricks_worth_it/jawqcxu/",
      "parent_id": "t1_jaw483b",
      "depth": 3,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-04T09:42:28"
    },
    {
      "id": "jb3n8ip",
      "author": "aptible-henry",
      "body": "Thank you for sharing this detailed answer. Aptible team member here.\n\nThough many customers are successfully running machine learning projects with Aptible, it wasn't originally designed for machine learning. We're anxious for feedback on how to improve.\n\nI have a feeling you provided feedback to Aptible back when you were considering a migration to AWS, but I'm not sure. Either way, would you be willing to share some of the reasons you found Aptible to be frustrating, other than that the rest of the org was using AWS and your tests showed better performance with Lambda?",
      "body_html": "<div class=\"md\"><p>Thank you for sharing this detailed answer. Aptible team member here.</p>\n\n<p>Though many customers are successfully running machine learning projects with Aptible, it wasn&#39;t originally designed for machine learning. We&#39;re anxious for feedback on how to improve.</p>\n\n<p>I have a feeling you provided feedback to Aptible back when you were considering a migration to AWS, but I&#39;m not sure. Either way, would you be willing to share some of the reasons you found Aptible to be frustrating, other than that the rest of the org was using AWS and your tests showed better performance with Lambda?</p>\n</div>",
      "created_utc": 1678076876.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/mlops/comments/11hcbgw/is_databricks_worth_it/jb3n8ip/",
      "parent_id": "t1_jaw483b",
      "depth": 3,
      "is_submitter": false,
      "stickied": false,
      "edited": true,
      "distinguished": null,
      "timestamp": "2023-03-05T20:27:56"
    },
    {
      "id": "jaw0cr1",
      "author": "PilotLatter9497",
      "body": "Mmm, maybe DVC is more than source control for datasets. It's a pipelines orchestrator, that can keep track of versioned data, models and code and its relationship. And also have a so good UI for VSCode.",
      "body_html": "<div class=\"md\"><p>Mmm, maybe DVC is more than source control for datasets. It&#39;s a pipelines orchestrator, that can keep track of versioned data, models and code and its relationship. And also have a so good UI for VSCode.</p>\n</div>",
      "created_utc": 1677940827.0,
      "score": 2,
      "ups": 2,
      "downs": 0,
      "permalink": "/r/mlops/comments/11hcbgw/is_databricks_worth_it/jaw0cr1/",
      "parent_id": "t1_jaugc4h",
      "depth": 3,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-04T06:40:27"
    },
    {
      "id": "jb6c94e",
      "author": "NYDreamer",
      "body": "Wonderful answer, thank you. I will consider recommending this for our team too.\n\nI feel a good tradeoff between structure (blog templates, predefined metrics / graphs, etc.) and flexibility would be best.\n\nConfluence is available for us, but indeed does not feel like the best tool for the job. I'll dig deeper.",
      "body_html": "<div class=\"md\"><p>Wonderful answer, thank you. I will consider recommending this for our team too.</p>\n\n<p>I feel a good tradeoff between structure (blog templates, predefined metrics / graphs, etc.) and flexibility would be best.</p>\n\n<p>Confluence is available for us, but indeed does not feel like the best tool for the job. I&#39;ll dig deeper.</p>\n</div>",
      "created_utc": 1678131764.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/mlops/comments/11hcbgw/is_databricks_worth_it/jb6c94e/",
      "parent_id": "t1_jb1jq4e",
      "depth": 3,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-06T11:42:44"
    },
    {
      "id": "jb1hvgt",
      "author": "trnka",
      "body": "You're welcome!\n\nI forgot to include our eventual solution for notebooks, which was Sagemaker. It came with some complications though because we were put in a separate AWS account from the actual data, so we had notebooks working quickly but it took months of a mid-level dev's time to get access to PHI there. We used EFS for a while for seamless sharing of data until we had an accidental massive storage of logs and a large bill. After that we just synced to S3 manually.\n\nI should've also said that many of my choices were swayed by my limited knowledge at the time, strict security/legal, hiring challenges, and fluctuating amounts of support from the central AWS team.",
      "body_html": "<div class=\"md\"><p>You&#39;re welcome!</p>\n\n<p>I forgot to include our eventual solution for notebooks, which was Sagemaker. It came with some complications though because we were put in a separate AWS account from the actual data, so we had notebooks working quickly but it took months of a mid-level dev&#39;s time to get access to PHI there. We used EFS for a while for seamless sharing of data until we had an accidental massive storage of logs and a large bill. After that we just synced to S3 manually.</p>\n\n<p>I should&#39;ve also said that many of my choices were swayed by my limited knowledge at the time, strict security/legal, hiring challenges, and fluctuating amounts of support from the central AWS team.</p>\n</div>",
      "created_utc": 1678041710.0,
      "score": 3,
      "ups": 3,
      "downs": 0,
      "permalink": "/r/mlops/comments/11hcbgw/is_databricks_worth_it/jb1hvgt/",
      "parent_id": "t1_jawqcxu",
      "depth": 4,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-05T10:41:50"
    },
    {
      "id": "jb529pp",
      "author": "trnka",
      "body": "Sure, happy to help though keep in mind it's been a while so I'm a little hazy on the details. Definitely I was looking to reduce the number of technologies the team needed to understand, like I mapped out all the tools we used and identified opportunities to simplify. That was because I found that the infra side of things was just so complex for the team.\n\nAs for the specific challenges we faced with Aptible and adjacent tech:\n\n* Sometimes deploying a container to Aptible would fail and the error message wasn't clear on what happened. I think usually it'd succeed if we tried again but if I remember right the CLI tool didn't have an auto-retry built in so people would monitor their Jenkins job for an hour or so and kick off a new job if it failed. If I remember right we tried working with support on that but nobody figured it out.\n* Originally the company infra had been setup by one person and they kept prod permissions separate from dev/staging. Long story short it meant that my team didn't have permissions to modify RAM on our instances through the whole pipeline. We needed to coordinate with another team at that point. With IaC in CDK we had a single definition for the config and could manage it ourselves. This isn't a failing of Aptible per se, more of our policy and how we set it up. In theory I could imagine if it were easier to refactor permissions in Aptible that might've unlocked improvements.\n* Related to the previous, the env var configs weren't very transparent. I think I didn't even have read access to those for most of my time at that company so it was a mystery to me.\n* At the time we felt that Aptible was pricey. Though after the fact, we had to do so much provisioned concurrency on Lambda that it was a wash. If the company had grown 100x like we expected, we would've saved a fair amount but we were at pretty low volume even at the end. I think our main service on Aptible had 2 instances, and in Lambda our utilized concurrency ranged from 0-10 throughout the day with provisioning around 6 if I remember right.\n* Unlike AWS, Aptible doesn't come with its own Docker registry. At the time we were using Artifactory for the Docker registry. Over the years that became less and less reliable. Even if the build succeeded, the push might fail. In the last year, we had a couple weird issues in which the push would half-fail, leaving something corrupted in the registry. I think we traced it to something broken in a cached version of a particular Docker layer from the Python base image, which explained why it broke multiple images. We worked with internal and external support on that one to no avail. Our workaround was just to copy the contents of the base Python Dockerfile into ours instead of referencing the base. That fixed it temporarily until we migrated to ECR. Probably we could've used ECR for Aptible but once we were already in CDK it was just a lot nicer to do it all there.",
      "body_html": "<div class=\"md\"><p>Sure, happy to help though keep in mind it&#39;s been a while so I&#39;m a little hazy on the details. Definitely I was looking to reduce the number of technologies the team needed to understand, like I mapped out all the tools we used and identified opportunities to simplify. That was because I found that the infra side of things was just so complex for the team.</p>\n\n<p>As for the specific challenges we faced with Aptible and adjacent tech:</p>\n\n<ul>\n<li>Sometimes deploying a container to Aptible would fail and the error message wasn&#39;t clear on what happened. I think usually it&#39;d succeed if we tried again but if I remember right the CLI tool didn&#39;t have an auto-retry built in so people would monitor their Jenkins job for an hour or so and kick off a new job if it failed. If I remember right we tried working with support on that but nobody figured it out.</li>\n<li>Originally the company infra had been setup by one person and they kept prod permissions separate from dev/staging. Long story short it meant that my team didn&#39;t have permissions to modify RAM on our instances through the whole pipeline. We needed to coordinate with another team at that point. With IaC in CDK we had a single definition for the config and could manage it ourselves. This isn&#39;t a failing of Aptible per se, more of our policy and how we set it up. In theory I could imagine if it were easier to refactor permissions in Aptible that might&#39;ve unlocked improvements.</li>\n<li>Related to the previous, the env var configs weren&#39;t very transparent. I think I didn&#39;t even have read access to those for most of my time at that company so it was a mystery to me.</li>\n<li>At the time we felt that Aptible was pricey. Though after the fact, we had to do so much provisioned concurrency on Lambda that it was a wash. If the company had grown 100x like we expected, we would&#39;ve saved a fair amount but we were at pretty low volume even at the end. I think our main service on Aptible had 2 instances, and in Lambda our utilized concurrency ranged from 0-10 throughout the day with provisioning around 6 if I remember right.</li>\n<li>Unlike AWS, Aptible doesn&#39;t come with its own Docker registry. At the time we were using Artifactory for the Docker registry. Over the years that became less and less reliable. Even if the build succeeded, the push might fail. In the last year, we had a couple weird issues in which the push would half-fail, leaving something corrupted in the registry. I think we traced it to something broken in a cached version of a particular Docker layer from the Python base image, which explained why it broke multiple images. We worked with internal and external support on that one to no avail. Our workaround was just to copy the contents of the base Python Dockerfile into ours instead of referencing the base. That fixed it temporarily until we migrated to ECR. Probably we could&#39;ve used ECR for Aptible but once we were already in CDK it was just a lot nicer to do it all there.</li>\n</ul>\n</div>",
      "created_utc": 1678112763.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/mlops/comments/11hcbgw/is_databricks_worth_it/jb529pp/",
      "parent_id": "t1_jb3n8ip",
      "depth": 4,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-06T06:26:03"
    },
    {
      "id": "jaw16i0",
      "author": "trnka",
      "body": "Yeah, though for what it's worth I mainly used it to version models and keep the model versions in sync with code versions.\n\nI've used the pipelines feature a couple times but it doesn't add much beyond a Makefile imo.",
      "body_html": "<div class=\"md\"><p>Yeah, though for what it&#39;s worth I mainly used it to version models and keep the model versions in sync with code versions.</p>\n\n<p>I&#39;ve used the pipelines feature a couple times but it doesn&#39;t add much beyond a Makefile imo.</p>\n</div>",
      "created_utc": 1677941218.0,
      "score": 3,
      "ups": 3,
      "downs": 0,
      "permalink": "/r/mlops/comments/11hcbgw/is_databricks_worth_it/jaw16i0/",
      "parent_id": "t1_jaw0cr1",
      "depth": 4,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-04T06:46:58"
    },
    {
      "id": "jb3hb91",
      "author": "spiritualquestions",
      "body": "After our conversation about Data Bricks, I am considering using a kubeflow + GCP stack. \n\nIt sounds like your team has used more of the AWS based tools; however, in terms of privacy compliance, I would assume that AWS and GCP stacks are at the same level of security. \n\nAny thoughts on this?",
      "body_html": "<div class=\"md\"><p>After our conversation about Data Bricks, I am considering using a kubeflow + GCP stack. </p>\n\n<p>It sounds like your team has used more of the AWS based tools; however, in terms of privacy compliance, I would assume that AWS and GCP stacks are at the same level of security. </p>\n\n<p>Any thoughts on this?</p>\n</div>",
      "created_utc": 1678073713.0,
      "score": 1,
      "ups": 1,
      "downs": 0,
      "permalink": "/r/mlops/comments/11hcbgw/is_databricks_worth_it/jb3hb91/",
      "parent_id": "t1_jb1hvgt",
      "depth": 5,
      "is_submitter": true,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-05T19:35:13"
    },
    {
      "id": "jaw37jd",
      "author": "PilotLatter9497",
      "body": "I agree with your point.  Maybe DVC has a pretty feature: if you define inputs and outputs for the steps in the pipeline, DVC is able to \"knows\" which steps need to be reruned if some of its precedents have changed. \nBut I also think like you: you can orchestrate with a Makefile or with bash scripting.",
      "body_html": "<div class=\"md\"><p>I agree with your point.  Maybe DVC has a pretty feature: if you define inputs and outputs for the steps in the pipeline, DVC is able to &quot;knows&quot; which steps need to be reruned if some of its precedents have changed. \nBut I also think like you: you can orchestrate with a Makefile or with bash scripting.</p>\n</div>",
      "created_utc": 1677942159.0,
      "score": 3,
      "ups": 3,
      "downs": 0,
      "permalink": "/r/mlops/comments/11hcbgw/is_databricks_worth_it/jaw37jd/",
      "parent_id": "t1_jaw16i0",
      "depth": 5,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-04T07:02:39"
    },
    {
      "id": "jb53a58",
      "author": "trnka",
      "body": "I'm confident that they can both be compliant. I've *heard* that it's easier in GCP to isolate a stack from other stacks even in the same account too.\n\nThe hardest thing by far was that we had a company policy that version 1 of a system must have least privilege permissions, and nobody in the company was efficient at building them. It was a lot of guess and check with very slow dev cycles. I've heard in AWS you can do things like stand up a system and use an audit tool to discover the used permissions then setup your roles from that. Maybe there's a better way in GCP.\n\nAnother thing that's handy is that AWS maintains a [HIPAA eligible](https://aws.amazon.com/compliance/hipaa-eligible-services-reference/) list, which are services that are compliant if they're configured correctly. If a service wasn't on there that we wanted, we could reach out to our AWS reps to see if it was on the roadmap at least. I'm sure GCP has something similar.",
      "body_html": "<div class=\"md\"><p>I&#39;m confident that they can both be compliant. I&#39;ve <em>heard</em> that it&#39;s easier in GCP to isolate a stack from other stacks even in the same account too.</p>\n\n<p>The hardest thing by far was that we had a company policy that version 1 of a system must have least privilege permissions, and nobody in the company was efficient at building them. It was a lot of guess and check with very slow dev cycles. I&#39;ve heard in AWS you can do things like stand up a system and use an audit tool to discover the used permissions then setup your roles from that. Maybe there&#39;s a better way in GCP.</p>\n\n<p>Another thing that&#39;s handy is that AWS maintains a <a href=\"https://aws.amazon.com/compliance/hipaa-eligible-services-reference/\">HIPAA eligible</a> list, which are services that are compliant if they&#39;re configured correctly. If a service wasn&#39;t on there that we wanted, we could reach out to our AWS reps to see if it was on the roadmap at least. I&#39;m sure GCP has something similar.</p>\n</div>",
      "created_utc": 1678113229.0,
      "score": 2,
      "ups": 2,
      "downs": 0,
      "permalink": "/r/mlops/comments/11hcbgw/is_databricks_worth_it/jb53a58/",
      "parent_id": "t1_jb3hb91",
      "depth": 6,
      "is_submitter": false,
      "stickied": false,
      "edited": false,
      "distinguished": null,
      "timestamp": "2023-03-06T06:33:49"
    }
  ],
  "total_comments": 34,
  "fetched_at": "2025-09-13T20:47:07.189443"
}