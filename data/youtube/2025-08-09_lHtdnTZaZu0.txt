YouTube Video Transcript
Video ID: lHtdnTZaZu0
Publish Date: 2025-08-09
Language: English (auto-generated) (en)
Generated: Yes
Total segments: 1337
Total duration: 64:31
============================================================

[00:05] Okay.
[00:06] >> And let's see, you know, if anyone has
[00:08] any topics or questions they wanted to
[00:10] to jump into, feel free.
[00:18] Yeah, I have a question.
[00:20] like nowadays I see the LLM uh you can
[00:25] use it with the rags and other context
[00:28] and prepare some websites and I al saw
[00:32] that people are using LLM with MCP
[00:36] server.
[00:36] >> Mhm.
[00:38] >> And it is pretty easy to just build an
[00:42] MCP server and this uh uh is utilizing
[00:46] the LLM.
[00:48] uh can you tell me about the total
[00:50] conceptual uh uh difference between
[00:54] these two concept?
[00:57] >> Oh sure. Um so uh you know for for
[01:00] others just to kind of get us all on the
[01:02] same page. So rag is retrieved augmented
[01:05] generation. That's the deal where uh
[01:07] maybe you send a question into a large
[01:09] language model and it does a search over
[01:12] some database or the internet and then
[01:14] gets some documents and injects those
[01:17] into the context along with your prompt.
[01:19] Um so that will help it get more recent
[01:21] information or if you have some special
[01:23] instructions that you want it to follow.
[01:26] And then MCP is model context protocol
[01:29] and that's that's uh it's much newer. Um
[01:33] but the I will say MCP is an evolution
[01:37] of tool calling. So for a long time we
[01:40] had tool calling and you would have to
[01:41] implement all these different tools. Um
[01:44] and then you could give your LLM access
[01:48] to call those tools.
[01:50] um and say okay well you have these five
[01:53] tools and you can respond you know the
[01:56] output of the thing can be something
[01:58] like uh uh generate text or it can be
[02:02] call this tool with this parameter that
[02:04] kind of thing and then MCP is the
[02:07] evolution of that is a more it's sort of
[02:09] standardizing that and saying oh well
[02:10] okay the tools aren't going to be um a
[02:13] function in Python that the the return
[02:17] will be sent into a Python function and
[02:19] then back out to the LL LLM. Um the the
[02:22] sort of quote unquote tool call is going
[02:25] to uh like call one of the MCP servers.
[02:29] So you're sort of registering a bunch of
[02:32] MCP servers
[02:34] uh to you know essentially in I think
[02:38] through the prompt. I'm not I haven't
[02:39] actually done much MCP stuff. Um and uh
[02:45] sorry I'm a little bit distracted. Um,
[02:49] so you're exposing that LLM can choose
[02:52] to call those or not to call those. Uh,
[02:57] implementing an MCP server is relatively
[02:59] easy. Just to give you some like highle
[03:02] context where where it starts to get
[03:04] hard is that um, MCP is really designed
[03:07] as an evolution of tool calling where
[03:10] they're kind of thinking about it in
[03:11] like a very like local sense of like
[03:14] running on your machine. Um, and so a
[03:18] lot of the early steps in MCP um,
[03:21] weren't really designed for like
[03:23] multi-user support and authentication
[03:25] and security. And so there can be some
[03:27] issues with that or some challenges with
[03:29] that. But uh, yeah, I mean that's that's
[03:32] kind of the gist. So like you could for
[03:34] instance implement a web search as an
[03:38] MCP server and inject it into a large
[03:40] language model that way or you could
[03:43] implement um your rag service as MCP and
[03:47] have it injected that way or you can do
[03:49] it kind of the traditional way. Um, I
[03:52] would say probably if you have a lot of
[03:55] different types of actions you wanted to
[03:57] take where some are like a structured
[03:59] database lookup, some are looking over
[04:02] document stores, that's probably when
[04:04] you would want to go to MCP versus like
[04:06] a like, you know, just rag. Um, but uh I
[04:10] actually haven't played around with MCP
[04:12] much. So, I'm sort of, you know, just
[04:13] sharing the knowledge that I have, but
[04:15] it's not firsthand knowledge.
[04:17] >> Okay, got you. Uh so uh my point is uh
[04:21] basically if I follow the rag so I am
[04:25] getting the better result or if I built
[04:28] a MCP server to link up with different
[04:31] LLM I'll get the better result. So that
[04:35] is my uh dilemma you can say.
[04:38] >> I see. I see. So um it's rag versus MCP
[04:43] isn't about a difference in quality.
[04:46] It's about a difference in capabilities.
[04:47] So if you expose rag through MCP versus
[04:51] doing Rag the same way, you'll get the
[04:54] same quality result. Um it's it's not
[04:57] about quality, it's about capabilities.
[05:01] >> Okay. So MCP is doing the same rag in in
[05:04] their codebase or
[05:06] >> No, I would say rag
[05:08] >> following the different Yeah.
[05:10] >> Uh rag could be you could implement rag
[05:13] as an MCP server. Um a different kind of
[05:17] MPCP server, you know, one I was talking
[05:19] about with a friend would be um so for
[05:23] for my startup, we use linear for
[05:25] tickets,
[05:27] >> you know, for like bugs and and work to
[05:28] do.
[05:30] >> So what we can do is we can implement an
[05:31] MCP server that will allow uh co-pilot
[05:36] to call to the MCP server and look up
[05:38] search in linear for tickets and
[05:40] retrieve stuff from linear for tickets.
[05:43] So that would be sort of like
[05:44] implementing giving it the capability to
[05:46] do a custom rag.
[05:48] >> Um
[05:49] >> in this case, one thing that it does
[05:51] since I can hook up um like I could hook
[05:55] up you can add additional MCP to copilot
[05:59] is that like I'm the one implementing
[06:01] the MCP server and it's getting injected
[06:03] into
[06:04] >> someone else's LLM implementation.
[06:07] >> Whereas with rag, it's it's a part of
[06:10] that implementation or it isn't. So MCP
[06:13] is like a way to inject customization
[06:16] into an existing um LLM solution and so
[06:21] it's giving you more flexibility, more
[06:22] capability
[06:24] um
[06:25] >> but uh it's not fundamentally changing
[06:29] you know like copilot could have
[06:32] implemented a linear rag in their system
[06:34] if they wanted to and it's not you know
[06:37] whether they implement it or I
[06:39] implemented it doesn't really doesn't
[06:41] fundamentally change the the quality
[06:43] potential. Uh but it does change like
[06:46] who's doing the work and you know
[06:47] whether it has to be implemented by the
[06:49] author or third party. So it's sort of
[06:52] it's more of a capabilities change.
[06:56] There's there's other kinds of you can
[06:57] do other things in MCP too. So some
[06:59] people will do MCP
[07:01] >> for like code checking. So you can have
[07:06] an MCP server
[07:08] >> that runs code through like security
[07:10] testers
[07:12] uh that runs code through llinters.
[07:15] Uh you could have MCP servers
[07:18] um that uh you know to do math and that
[07:22] kind of thing if you're doing a lot of
[07:23] like math heavy tasks.
[07:25] >> So it's really a generalization of tool
[07:27] calling.
[07:28] >> Oh.
[07:30] >> So you can you can kind of do anything
[07:31] in there really. Like you could say um
[07:35] actually to uh to Glenn's example of of
[07:40] uh you know frontend work, you could
[07:42] have an MCP server that um deploys the
[07:45] code
[07:46] >> and then renders it in a Chrome window
[07:48] and takes a screenshot and sends the
[07:50] screenshot back into the LLM.
[07:53] And then if you do that, you're giving
[07:56] the LM the the possibility of finding
[07:58] out what it actually looks like, not
[08:00] just looking at the file.
[08:02] So you're kind of exposing comput.
[08:05] >> Yeah, I was thinking say we have
[08:08] different project in our tech joy like
[08:10] support local. So if I uh make an MCP
[08:14] server to uh find out the bugs from this
[08:20] support local. Can I have that?
[08:23] >> Yeah. So I I'm not too familiar with
[08:25] support local. I I forget what it does.
[08:28] >> Maybe any project. You forget about
[08:30] support local. any project. So the MCP
[08:33] server will help me do all those actions
[08:35] or
[08:37] uh
[08:37] >> if you implement the MCP server.
[08:40] >> Yeah.
[08:40] >> Yeah.
[08:41] >> I'm talking about this implementation.
[08:42] If I implement a MCP server, what kind
[08:44] of uh advantage or the things I can get
[08:48] it from there.
[08:50] So,
[08:52] so say if it's like a group project or
[08:55] something and there's
[08:57] >> maybe there's um
[09:00] >> and you're working with say something
[09:02] like co-pilot
[09:04] um
[09:05] for most things on the project like
[09:07] documentation it's best to just put them
[09:09] in put that in files and then let
[09:11] co-pilot access those files and then you
[09:14] don't have to implement MCP to access
[09:16] those. But for something like uh like
[09:19] tickets or you know if you want it to
[09:23] access like say if you're chatting in
[09:25] discord in a certain channel about
[09:26] something if you want to access those
[09:28] discord logs
[09:29] >> what you could do is you could implement
[09:30] an MCP server to allow discord search
[09:34] within a particular channel to so that
[09:36] the
[09:37] >> so that copilot can go look up the
[09:39] recent discussions about the project or
[09:41] so that copilot can go look up recent
[09:44] >> but but my project is uh made on rags.
[09:48] So now if I implement MCP server, will
[09:50] it work there or they may conflict?
[09:54] >> Oh, so you want you want to use the MC
[09:57] you want to be the one.
[10:00] >> So you want MCP capability
[10:04] not for
[10:04] >> I'm giving you the context. Okay, like
[10:06] in our tech joy. Mhm.
[10:08] >> We have a discord board. So from the
[10:10] discord board we get a help and this
[10:12] help is supported by our coding tutor.
[10:16] >> Mhm. Yep. Now if I want to use a MCP
[10:20] server in this code base and try to
[10:23] extract all those conversation and from
[10:25] that conversation
[10:26] >> before you go on when you say you want
[10:28] to use MCP you as the user of code tutor
[10:31] or you as the developer of code tutor
[10:34] >> developer of the code tutor
[10:36] >> and you want it to be in the
[10:38] implementation of code tutor or to
[10:39] assist you in coding code tutor.
[10:42] uh kind of both maybe assist some
[10:46] >> those are actually two different
[10:47] implementations.
[10:48] >> Yeah, I I understand maybe okay just uh
[10:52] assisting the code uh uh evaluation or
[10:55] code correction or code helps can be uh
[10:59] G can it be given through MCP server? Uh
[11:03] so if you're if you're talking about in
[11:05] the implementation of code tutor
[11:07] >> yes
[11:08] >> in in how code tutor responds um mcp
[11:11] server would not offer any benefit over
[11:14] the existing rag solution it does not
[11:17] increase the capabilities at all uh it
[11:20] adds extra work um but it doesn't
[11:23] increase capabilities
[11:26] uh if you're talking about
[11:27] >> but our coding tutor only uh verify the
[11:31] help request and say Okay, you'll be
[11:33] given the help 24 or 48 hours. But if I
[11:37] make a MCP server that will read that
[11:41] code and what is the problem of that
[11:43] code? Uh can it be uh can it be given in
[11:48] uh to the to the user or can any
[11:52] guidance can be given to the user from
[11:53] the LLM? Okay. So he is writing say uh
[11:58] def add of a and b and you is missing
[12:02] some variable or something like that. So
[12:05] can I make mcp server to add it and then
[12:09] he directly responds to that uh problem
[12:13] or the tickets or anything or query.
[12:18] Um
[12:19] so in the case where so a student
[12:21] submits a help request to code tutor and
[12:24] they have code in their help request and
[12:27] >> you want to process that code in some
[12:29] way.
[12:30] >> Yes. Yes.
[12:31] >> Um
[12:32] >> so in that case and if it's in code
[12:34] tutor specifically it would probably be
[12:38] easier and safer to implement it as tool
[12:40] calling rather than MCP.
[12:43] >> Okay. Because with MCP, typically what
[12:46] you're doing is you're opening a port on
[12:48] a computer.
[12:49] >> Yeah.
[12:50] >> And and then it's, you know, sending
[12:52] stuff over to that port.
[12:53] >> Um,
[12:55] >> do you do
[12:55] >> you know the server is running on the
[12:58] internet and then now you have an extra
[13:00] open port and you have to secure that or
[13:03] it's a port that's being blocked by AWS
[13:05] and then your MCP server doesn't work.
[13:08] >> We'll go through AWS so that it doesn't
[13:11] create any conflict. uh depending on the
[13:15] configuration of the project, it may
[13:17] just block all ports by default.
[13:20] >> You might have to config,
[13:22] >> you know, it's it's possible. I'm not
[13:24] saying it's not possible. I'm just
[13:26] saying that in that situation, if it
[13:28] were me implementing it, I would
[13:30] implement any kind of code processing as
[13:32] function calling rather than MCP.
[13:35] >> So, we'll just write a function there
[13:37] and do something. Got you.
[13:39] >> Yeah. Yeah. So the traditional thing was
[13:41] function calling where the output of the
[13:43] element
[13:43] >> I was I was thinking that if I if I can
[13:45] implement the MCP server then it can
[13:49] extract from some LLM about that code
[13:52] and can give you the right guidance to
[13:55] that uh individual or the user uh that
[13:59] what he's missing or what he's supposed
[14:01] to implement so that instantly he get
[14:04] the reply
[14:06] >> I mean
[14:07] >> because in coding tutor we don't have
[14:09] any database uh of all the coding but
[14:14] when I add a MCP server MCP server can
[14:17] host any of the LLM and can give that
[14:21] guidance that is my idea I do not know
[14:23] my idea is good or not because I just
[14:25] learning and you are the
[14:26] >> so
[14:28] what I would actually recommend doing is
[14:30] to kind of like go through like a
[14:33] tutorial example of function calling and
[14:35] then a tutorial example of MCP and sort
[14:37] of compare Um um it's MCP server isn't
[14:42] giving you anything for free.
[14:44] >> Yeah, I know.
[14:45] >> You know like
[14:46] >> but I I was thinking about the price.
[14:49] Yeah, I was just thinking about that
[14:51] actually any student can get a feedback
[14:54] within a second or within a minute
[14:57] >> uh what to do rather waiting for 24 to
[15:00] 48 hours to somebody from our peer
[15:03] review to reply them. That was my
[15:05] concept.
[15:05] >> Oh yeah. Yeah. Well, that's what the
[15:07] code tutor project's trying to do.
[15:09] >> Um,
[15:10] >> MCP isn't the problems that they're
[15:13] having aren't solved by MCP.
[15:16] Um,
[15:17] >> that's not that's not why the project
[15:19] has taken a while. Um,
[15:23] >> so what what are the possible solution
[15:26] to regarding this issue?
[15:28] >> Which issue? uh this issue that a
[15:31] student gets uh prompt reply about his
[15:34] code and a kind of kind of assessment
[15:38] about his code what is missing or
[15:41] something is missing what rather waiting
[15:42] for 24 to 48 hours for a peer review
[15:46] >> oh I mean if look you can do a decent
[15:48] solution on that by just doing prompt
[15:49] engineering you don't need MCP you don't
[15:52] need rag all you have to do is do some
[15:55] prompt engineering
[15:57] just you know you send the students code
[15:59] with some prompt about how to advise a
[16:02] student, how to interact with a student,
[16:03] run it through, get the output, send it
[16:05] back. All the hard work is really in
[16:08] hooking it up to Discord live and having
[16:10] it be secure and running 247.
[16:13] >> So, you don't need Rag, you don't need
[16:15] MCP for that. if you want it to be um
[16:19] the reason why they're doing rag in the
[16:21] code tutor project instead of just a
[16:23] straight prompt
[16:24] >> is because some of the questions that
[16:27] student ha students have aren't just
[16:28] about programming but they're about
[16:30] specific lessons
[16:31] >> and so if they ask about lesson two
[16:35] uh open AI's large language models don't
[16:38] know what lesson two means
[16:39] >> no I don't have
[16:40] >> right but that's why they have rag so
[16:42] that's why they're using rag to do some
[16:45] things like that but But if it was just
[16:46] for coding help, they don't actually
[16:48] need rag at all. Like the large language
[16:50] models are already good at programming.
[16:52] >> So they just need some prompting to help
[16:54] figure out like how do we
[16:57] >> how do we do a response that's helpful
[16:59] to a student? What tone do we want?
[17:01] >> Um and that sort of thing. You don't
[17:03] >> you don't need RAG or MCP for um you
[17:06] know general programming help.
[17:10] >> Okay. Thank you so much, sir.
[17:12] >> Yeah, you're welcome. I so I would
[17:14] recommend if you want to um explore that
[17:16] idea um I would recommend
[17:20] >> um trying to take an example student
[17:22] question
[17:23] >> and just like copy paste it into chat
[17:26] GPT or whatever online
[17:28] >> I did it already. Yeah. And they're
[17:30] giving uh kind of assessment.
[17:32] >> I tested that.
[17:34] >> Well, there you go.
[17:34] >> Within myself. So I was trying to think
[17:36] that how to implement then I came across
[17:39] of this MCP server. people are trying to
[17:41] talk that it can easily be extracted
[17:45] from some of the LLM easily and can be
[17:47] delivered anywhere. So I was thinking on
[17:49] that line.
[17:50] >> Oh yeah. So so really like the the first
[17:54] basic thing is really you just need an
[17:55] API call like you just make an API call
[17:58] to open AAI. Um that just uses like a
[18:00] regular API
[18:01] >> we have already in in our coding tutotor
[18:03] open API.
[18:05] >> So that can be used. We don't have to do
[18:07] anything new there. Yep. That was my
[18:10] idea.
[18:10] >> Yep. Yep.
[18:11] >> Am I right?
[18:12] >> Yeah. Yeah. You don't need anything
[18:14] special to do like coding assistance. Um
[18:16] >> Yes.
[18:17] >> Uh
[18:18] >> yeah.
[18:19] >> Yeah. Yeah. Not for not for any of this
[18:21] kind of stuff. There's like some niche
[18:23] situations in like if you're using um AI
[18:26] to get coding assistance and you're
[18:29] using like a new programming language or
[18:31] new programming libraries, that's when
[18:33] you start to need rag because uh for
[18:36] instance like OpenAI's models were
[18:38] trained on data that goes up to last
[18:40] year. So they don't know about anything
[18:42] that's happened in 2025.
[18:44] >> Yeah, you actually like need something
[18:46] like a rag system for that. Basically we
[18:49] are talking about the basic coding not
[18:51] advanced project something like the
[18:53] students are in the basic level and it
[18:55] covered by all the llm I saw
[18:56] >> yes yeah
[18:57] >> I tried with chat GPT I tried with cloud
[19:00] and they are giving us very responsive
[19:02] answer so that's why I was trying to
[19:04] think that if I can add it with MCP so
[19:08] then it will be uh eventually giving
[19:11] them some kind of response
[19:14] rather than waiting for 24 to 48 hours
[19:16] that's my thinking
[19:18] Yeah. Yeah. Yeah. But the MCP it just it
[19:21] gets hooked into the large language
[19:22] model part of it, not Discord. The hard
[19:25] part is looking into Discord. That's why
[19:27] project's taking so long.
[19:29] >> Yeah. But that part is already hooked
[19:32] with our rags. So can they not exchange
[19:36] their prompt each other?
[19:39] >> I mean you can you can uh I would say
[19:41] talk to them if you want to. If their
[19:43] prompt isn't working well, then you can
[19:45] talk to them. But a part of the reason
[19:47] why it wasn't hooked in was because it's
[19:52] difficult to make sure that everything's
[19:54] secure
[19:55] >> um and cheap. So,
[19:57] >> you know, to to have this Discord thing
[20:00] working
[20:01] >> uh the way it was set up is that it has
[20:03] to run a server 24/7 like every single
[20:05] day, every single minute, and has to be
[20:07] kind of
[20:08] >> 365. Yeah.
[20:09] >> Right. And so they had to, you know,
[20:11] they were worried about cost with that.
[20:12] And so, you know, they're trying to work
[20:14] that out.
[20:15] And then there's a problem with there's
[20:17] a lot of problems with security with um
[20:20] making sure that the Discord token used
[20:23] to reply is secure because if it's not
[20:26] secure then anyone on the internet could
[20:28] get access to Yeah.
[20:29] >> to doing some of these things. And so
[20:31] some of the security parts were pretty
[20:32] tricky of it.
[20:33] >> Um the the actual like large language
[20:35] model part is pretty straightforward as
[20:37] you saw.
[20:38] >> Yeah. Um, and so I don't I I think I saw
[20:43] Adam, was it not Adam? Uh, I think Nick
[20:47] posted
[20:49] um just the other day.
[20:52] Let's see here. Um, just yesterday that
[20:55] some parts of it, you guess the ETL
[20:58] dockerized, but that's not the not
[21:02] running in the cloud yet. So, I think
[21:04] that was the step to to update the data
[21:06] from Discord. Um but that's anyway so
[21:09] there's a lot of steps to that project.
[21:11] Um
[21:14] unfortunately the the part the part that
[21:16] you're interested in the part of like
[21:18] giving uh the helpful response to the
[21:20] student that part um generating the
[21:23] response is the easy part um and it's
[21:26] all the things around it that make it
[21:28] hard um and time consuming.
[21:36] Thank you so much.
[21:45] >> Anyone else have topics or questions? If
[21:47] not, I'll I'll, you know, do some some
[21:49] coding and we can chat through that.
[22:06] I'm a fly on the wall. I'm interested in
[22:08] whatever you do, Keith.
[22:10] >> Right on.
[22:23] Well, let me just let me get set up for
[22:25] some coding and then if someone you know
[22:28] you know you remember some question or
[22:30] topic you wanted to bring up just kind
[22:31] of blur it out. Um
[22:34] and I guess since this is a project that
[22:37] I've already been working on a bit, I
[22:40] got to start with a little bit of a
[22:41] demo. So, let me get set up for that
[22:44] real quick here.
[22:47] All right.
[22:49] Um,
[22:57] that's interesting. All right. Uh, let's
[22:59] see here. Screen share.
[23:03] Uh,
[23:04] probably
[23:09] probably doing a whole desktop is the
[23:11] way to go.
[23:13] Um,
[23:17] all right.
[23:20] Can you see I'm looking at a GitHub
[23:21] window.
[23:33] Okay, cool.
[23:35] Yeah, somehow for whatever reason when I
[23:37] um start sharing it like autohides the
[23:40] the chat window and then also it takes
[23:43] away the chat window button so it's like
[23:46] hidden under a thing. Anyway, long story
[23:48] short, all right, so this is kind of um
[23:53] let me dive into the problem that I'm
[23:55] facing here to give you a little bit of
[23:57] motivation.
[23:59] Uh maybe let's start with this. close
[24:04] this. Um, so I do volunteering with this
[24:07] this Green Seattle partnership
[24:09] organization and we like help restore
[24:11] parks around the city and that sort of
[24:12] thing and you know native woodlands. Um,
[24:16] but what I found is that they have a
[24:20] good number of events but not
[24:22] everything. So this has, you know, you
[24:24] can see a decent amount here. You can
[24:26] see there's some stuff on the calendar
[24:27] there. This like map version, this
[24:30] calendar version here.
[24:33] Um, that's pretty cool.
[24:35] And then some of the events are actually
[24:38] on a different website entirely.
[24:41] Let me see if I can find one in my list.
[24:47] That's not a good one.
[24:50] Oh, almost all these are. All right.
[24:52] Here's
[24:55] All right. So, the Seattle Public
[24:58] Utilities site has this thing about uh
[25:01] cleanup events. So, stuff where, you
[25:03] know, we just go around, pick up trash
[25:05] and stuff and, you know, back it up and
[25:07] and that sort of thing. So, um let's see
[25:10] here. So, tomorrow
[25:12] there's one um in the Oello neighborhood
[25:16] at Oello Park from 10 to 12.
[25:19] And so it turns out that there's like I
[25:23] don't know 10 different places where you
[25:26] can look for this stuff. The one that
[25:28] and so what I started to do was to build
[25:30] this aggregator. Um so you know this
[25:34] Magnuson reforestation event that um was
[25:38] this morning from from 9 to noon at
[25:41] Magnuson Park. Um, you know, I got this
[25:45] from
[25:47] scraping some data on Green Seattle
[25:48] Partnerships. It's also on Seattle Parks
[25:51] Foundation. It's also on
[25:54] Seattle.gov/parks.
[25:56] So, it's in three different places and I
[25:57] was able to kind of merge this all into
[25:59] like one line item. Um, there are some
[26:02] where um I don't do a perfect job. So,
[26:07] probably some of these ones down here,
[26:09] like this one right here,
[26:12] three of my sources call it join
[26:14] EarthCore on Lake Washington Boulevard,
[26:16] and then Earth Core calls it something
[26:18] else entirely. And then my merge code
[26:20] didn't merge though, so that's that's a
[26:21] bit of a problem.
[26:23] Um, and then to add Google button, like
[26:26] partly I did this so that I can like
[26:28] just easily like aggregate all the
[26:30] sources, see what volunteering is coming
[26:31] up. like if I know that I'm free a day,
[26:34] then I can just like add something to
[26:35] Google and then um add it to my calendar
[26:38] and then you know I know know where to
[26:40] show up and whatnot. Um but I saw this.
[26:44] So Fremont is a neighborhood I live in
[26:49] Wallingford. Fremont's one of the
[26:50] neighborhoods right next to me and they
[26:53] have this local Fremont neighbor blog
[26:58] and they posted okay they've got a
[27:00] cleanup in AB Ernst Park on Sunday. So
[27:05] uh Sunday August 10th and then Saturday
[27:07] August 16th from 9 to noon. And they're
[27:10] looking for a bunch of volunteers for
[27:12] this one particular park.
[27:15] And this event, this is the only place I
[27:17] could find it is in a blog. It's not on
[27:20] a calendar. It's not in the official
[27:22] Seattle, you know, list of volunteer
[27:25] events. So, um, probably they're not
[27:29] going to get as many people as they
[27:31] might want because 15 is actually kind
[27:32] of a lot of people. You know, they're
[27:34] only going to get people that read this
[27:36] blog that happen to be available at that
[27:37] time. So, I'd really love to be able to,
[27:41] you know, just have a So, this one's the
[27:43] was it the 10th? Yeah. So, I'd really
[27:45] love to be able to just have a line item
[27:47] on here um to say, "Okay, well, we got
[27:51] this thing." The problem though is that
[27:54] if we go to
[27:58] if we just click here.
[28:01] So, there's this volunteering one,
[28:05] but then there's other stuff, too. This
[28:07] is like more of a social night out.
[28:11] Uh this is like businesses closing and
[28:13] opening.
[28:15] This is about you know like voting. Um
[28:20] and so maybe actually this there's this
[28:24] volunteering category. Okay. So that has
[28:26] this one. That's cool. It has this one.
[28:29] That's cool.
[28:32] But then it also has this survey. That's
[28:34] not a volunteering event.
[28:37] Um,
[28:39] it has, oh, some people upgraded
[28:41] chessboard. That's cool. That's like a
[28:43] result of a volunteering event, not an
[28:44] actual like, hey, come out for this
[28:46] event. Um, solstice parade. Yeah. Okay.
[28:50] That's like asking for volunteers.
[28:53] Uh,
[28:55] oh, something was vandalized. Okay. So,
[28:57] anyway, so it's a mixture of stuff
[28:58] that's like actual volunteer events and
[29:00] not volunteer events.
[29:03] And so for me to integrate this kind of
[29:05] thing I'm thinking okay well how do I do
[29:08] it uh really I need one to get the data
[29:12] and then two
[29:14] uh to to try to like classify uh you
[29:18] know each of these posts to say is there
[29:21] a volunteering event here and if so we
[29:24] need to know okay what day is it on uh
[29:28] what time is it at like what what's the
[29:31] location.
[29:33] Um what kind of stuff are they doing? So
[29:35] some people um as you imagine like
[29:38] picking up later if you have like one of
[29:39] those like grabbers
[29:41] then you don't have to bend over as
[29:43] much. Um and so some people can do that
[29:46] but then um there are other events where
[29:49] it's like you're really down on your
[29:50] hands on knees. You're like weeding.
[29:51] It's really hard tiring work. And so
[29:53] some events um you know anyone can do
[29:56] and some events you know maybe only
[29:58] certain people could do or if you don't
[30:00] want to get your clothes dirty like that
[30:02] might affect it too. So we kind of want
[30:04] to try to integrate all that stuff. So
[30:09] so we'll start on I don't know if we'll
[30:11] be able to get it done in 20 minutes
[30:13] because that's kind of a compl you know
[30:15] in the old days this would be like a you
[30:16] know a solid day of work or something
[30:18] but we'll see. We'll see. So first
[30:22] things first is to try to figure out if
[30:23] there is a data source. So for this I
[30:28] want to try to find an RSS.
[30:32] Um so let me bring up
[30:35] let's see here see if we can find an RSS
[30:38] feed on here somewhere.
[30:41] RSS. No.
[30:44] And let's see. Sometimes in the archive.
[30:51] No.
[30:53] Let's try clicking on category.
[30:57] Subscribe socials. Nope. Nope. Nope.
[30:59] Nope. Nope. So, I do have it in my
[31:01] Feedley,
[31:03] but let's look a couple other places
[31:06] real quick.
[31:08] Look in the source here. RSS.
[31:11] RSS. Here we go. Okay,
[31:17] open a new tab. All right, so we do have
[31:20] an RSS feed. Great.
[31:24] Great.
[31:28] All right.
[31:32] So, I'll copy that URL and then I will
[31:35] go over to my VS Code window
[31:39] and I'll say
[31:42] I have some context here.
[31:46] So, my only chance of getting through
[31:48] some of this is to try to hope that that
[31:52] uh yeah, assisted coding will get this
[31:55] to happen fast enough.
[31:57] Let's work on integrating
[32:01] the Fremont
[32:04] neighbor neighbor
[32:08] blog.
[32:11] For context, this blog has a mixture of
[32:17] of uh posts on it. Some of them are
[32:23] events, some are not. The blog does have
[32:28] a volunteering
[32:30] category,
[32:33] but some of those posts are not events.
[32:39] So I anticipate
[32:42] that what will
[32:45] build is to download the RSS feed
[32:53] and process each
[32:57] um
[32:58] should I call it an article?
[33:02] Sure. each article with GitHub LLM,
[33:06] GitHub models.
[33:10] There's already an
[33:14] uh a research prototype of this in the
[33:19] repo.
[33:24] I'm anticipating
[33:26] that the LLM call will need to be
[33:31] cached. So in the database so that we
[33:36] don't reprocess
[33:42] the same page over and over every day.
[33:50] Um let's see what else do I need to say.
[33:55] And we'll want to create a data
[34:00] structure for the extracted
[34:04] event or events.
[34:08] Let's start by running a curl command
[34:14] to download
[34:17] the RSS data into the repo. Oh. Uh
[34:23] oh. Edit. There we go.
[34:25] into the repo.
[34:29] And then we can build out a
[34:35] uh what do I want to call it?
[34:38] An ETL module or this blog
[34:44] with a roughly similar structure to the
[34:49] others.
[34:54] Once we have something basic working, we
[34:59] can switch to testdriven
[35:04] development.
[35:05] Um, yeah.
[35:08] Uh,
[35:11] okay. Let's start by downloading the
[35:16] RSS. Here is the URL.
[35:20] Um,
[35:22] all right. So, long story short, when
[35:25] I'm implementing features um using uh
[35:28] large language models and actually let
[35:30] me try to make this a little bigger for
[35:31] you. Um,
[35:34] especially with an advanced model where
[35:36] it's capable of implementing a lot of
[35:38] the feature, I provide a lot of detail
[35:40] about what we're building.
[35:43] Um and so downloaded the RSS we should
[35:47] say into
[35:49] into where is it? It's test data
[35:54] tests
[35:57] data.
[36:00] All right.
[36:02] Oh darn. I ran it with ask not agent. Uh
[36:11] so in agent mode it will like suggest to
[36:12] actually run it. Oops. I meant to run in
[36:17] agent mode. Try again.
[36:25] And so in agent mode in VS code it can
[36:28] suggest commands um to run. Um, so
[36:32] that's this is the curl command to
[36:34] download this URL with an HTTP get
[36:37] request to this particular file.
[36:40] If I hit continue, it'll go actually run
[36:42] that command.
[36:48] Typical. Oh, it's WordPress. Okay,
[36:50] great.
[36:52] Yep.
[36:59] So SPR there is Seattle parks and wreck.
[37:01] Base is my base class for um for
[37:04] extractors.
[37:06] This is the RSS feed.
[37:09] LM canonicalization. Oh, I already had
[37:11] started to do some stuff. So that was
[37:14] some um experiments. So you can kind of
[37:16] see what uh had written this you know
[37:21] this big prompt to try to do some stuff.
[37:25] But that experiment kind of failed.
[37:30] So let's take a look at what that RSS
[37:31] feed looks like.
[37:37] Oh, it says generated by R WordPress
[37:40] right there. Of course, and it does have
[37:42] this like Okay, here's this cleanup on
[37:44] Sunday. Great.
[37:48] I need to fix typers.
[37:52] This is the part where like, you know,
[37:56] sometimes I'll like watch it and then
[37:58] I'll like stop it if it goes off the
[37:59] rails and then um if if it has uh
[38:06] tests
[38:09] um then usually it'll suggest to run the
[38:11] test and then it'll sort of keep it on
[38:12] the rails and that's great. Um sometimes
[38:16] when it's doing this initial development
[38:17] it's like wow I could do it this way. do
[38:19] it this you know it's kind of like it
[38:21] wants to keep doing things without
[38:23] input. Um, so we'll see.
[38:27] Let's let's take a look at what Okay, so
[38:29] it started to create this thing. Fix
[38:32] type editors. Check that. Correct field
[38:34] names. So it is looking at time zone
[38:36] stuff. That's actually one of these like
[38:39] I will say in programming getting times
[38:42] right is very hard. In this codebase,
[38:45] it's uh particularly challenging because
[38:47] a lot of the data is unstructured. So,
[38:50] um, if you have this like, you know, in
[38:52] this post, um, we can go back over to
[38:54] Chrome and see, um,
[38:59] you know, in this post, it just says,
[39:02] uh, 9:00 a.m. to noon. It doesn't say
[39:04] what time zone it is because it's
[39:06] assumed that all of the readers are here
[39:07] in Seattle. But when we're programming
[39:10] it, we need the time zone. And so I have
[39:13] this, you know, uh, you know, if we
[39:16] don't know the time zone, default to the
[39:18] the time zone in Seattle. All right,
[39:21] let's see what it's doing here. Uh, fix
[39:23] null checking, great. Fix type handling,
[39:27] type assertions, great.
[39:29] Uh, LLM response handling, time zone
[39:32] handling, those are all important
[39:33] things. Fix
[39:36] import HTTP URL. Um, so paidantic. Uh,
[39:42] you can store a URL in a string.
[39:44] Videantic has a special class for HTTP
[39:46] URLs that'll throw an error if it's not
[39:48] a valid one. Um, so I kind of like to
[39:50] use that. Um, it has gotten to the point
[39:53] where it wrote a bunch of stuff and it
[39:56] has some tests. I'm going to take a look
[39:58] at the code because it's actually like
[39:59] paused itself right now. So, I have
[40:02] actually like a moment to look at the
[40:04] code. Um, I kind of like to start by
[40:07] looking at test code.
[40:09] So we can sort of start there. I'll make
[40:12] this a little bit bigger. Uh let's see
[40:15] test with real RSS data. Okay. So this
[40:18] this part here um it's sort of copying
[40:20] the patterns that we have elsewhere in
[40:22] the repo which is to load the data using
[40:25] a path that's relative to this file
[40:27] that's being executed. Um because if you
[40:30] run your unit test from a different
[40:31] directory, I still want to run without
[40:33] crashing.
[40:34] So okay, it goes loads that it sends it
[40:37] into the Fremont neighborhood extractor.
[40:39] Great. Uh runs extractor.extract.
[40:43] So the pattern that I have well we'll
[40:45] come back to this pattern I guess but
[40:47] says okay um we expect it to be a list.
[40:50] Great.
[40:53] And it's saying okay for any events in
[40:56] here
[40:58] you know it's saying Fre is the sort of
[41:00] like source ID. Um all events should
[41:03] have a title. All events should have a
[41:05] venue. That's one I don't know. Um,
[41:09] start and end should be a datetime. I
[41:11] mean, that's it's a pyantic model, so
[41:14] that's actually not a very good test.
[41:16] Like pyantic,
[41:19] I think we'll just crash if we don't do
[41:21] that. Anyway, um, saying the URL should
[41:25] be null. I can show you what the event
[41:26] model looks like. So, um, here's the an
[41:30] event. you know, we have some kind of
[41:31] source name, some kind of unique ID,
[41:35] uh the title, we have a start and end.
[41:38] Some of these things are optional. So,
[41:40] like the venue is usually like a park
[41:42] name. Um the address is usually like a
[41:44] specific address. Those are optional.
[41:46] Sometimes it doesn't specify exactly.
[41:50] Um the URL is not optional. You'll
[41:53] notice. So if we go back over here, it's
[41:56] saying assert that the URL,
[41:59] you know, is not null or empty. Uh there
[42:03] that's like such a that's not likely to
[42:05] happen. So this test is actually not a
[42:07] very good test. Um
[42:10] but uh in the interest of time, let me
[42:13] keep scrolling down. I don't want to
[42:16] just, you know, nitpick on the the LLM's
[42:19] tests here. All right. So this one was
[42:22] test it with real data. Sure. I mean
[42:25] both of them are doing the same data.
[42:28] And this one is testing sort of the
[42:30] first item is this AB Ernst Park
[42:32] cleanup. This is actually much better um
[42:35] because it's sort of testing the first
[42:36] item here. Um and then
[42:45] it it put it put this in here. But since
[42:48] I'm doing everything in piest, I don't
[42:50] need these.
[42:52] Um, and so it's sort of like generating
[42:55] something that I can run directly. But
[42:57] um, since I use piest um that I would
[43:00] rather just run it through piest. So
[43:02] what I'm going to do is I'm going to
[43:04] make some modifications
[43:06] um kind of trim it down to its bare
[43:09] essentials and then um and then I'll
[43:12] have this run through pi test. But
[43:14] before we go too deep into that, I want
[43:16] to take a look at the the ETL code that
[43:18] I wrote. All right. So, we have a
[43:21] Fremont article.
[43:23] Got title, link, publication date,
[43:25] categories, description, content, and a
[43:28] gooid globally unique ID. Um, okay. So,
[43:31] that's cool. That's cool. So, that's um
[43:33] coming directly from this RSS XML. Um,
[43:37] and so it's a very like shallow
[43:40] interpretation of that. It's not like
[43:42] extracting the um the event data. It's
[43:46] just you know a structure for
[43:49] uh let's see here item.
[43:52] So it's a very simplistic representation
[43:55] of this XML right here. This item XML.
[44:02] Sorry, I just saw something that's like
[44:04] uh all right. Um since we're looking at
[44:08] it, it's a learning moment. we have to
[44:11] talk about it. Uh, I'll just
[44:17] So, what I'm looking at here is this
[44:20] content encoded tag
[44:25] in XML.
[44:28] And the contents of it are this, you
[44:30] know, C data thing. So, character data.
[44:33] And then you'll notice that inside here
[44:36] is HTML.
[44:39] Um, but it's not in the h the XML
[44:42] structure. it's raw character do. So,
[44:43] it's kind of like being wrapped into
[44:44] there. Um I
[44:48] that is
[44:51] probably necessary.
[44:53] Um there's a certain part of me that's
[44:55] like h we're like escaping all this
[44:57] stuff in this other thing which like but
[45:04] HTML is not actually a subset um is a
[45:08] subset of XML. Um there is a standard
[45:11] called XHTML that is but uh HTML itself
[45:15] is not. Anyway, I'm getting distracted.
[45:19] Um
[45:21] so anyway, so uh if I go over to Fremont
[45:24] neighbor, which is our ETL. So this is
[45:26] sort of the shallow representation of
[45:28] that that item, which is great. I like
[45:30] that a lot. And then it has this
[45:33] extracted event here. So sort of like
[45:36] okay, we got a shallow representation of
[45:37] an article. Oh, is my
[45:45] is my audio doing weird stuff? I can't
[45:47] though.
[45:50] Can you guys hear me?
[46:14] Let's see.
[46:17] Well, I'll just keep going and we'll
[46:18] sort of see. Um hopefully my mic's still
[46:22] working.
[46:23] Wait.
[46:36] It's still connected there. I don't
[46:37] know.
[46:44] Um,
[46:45] anyhow. Oh, yeah. Sorry. It's someone
[46:49] actually outside my window kind of
[46:51] talking. Let me close my window here.
[46:58] sounded like a like an echo, but it's
[47:02] I don't know.
[47:04] Uh, someone is like hanging out over the
[47:06] roof, and I'm trying not to think about
[47:08] that. I don't know. I think they're like
[47:10] looking for
[47:12] a drone that they got lost or some such.
[47:15] Anyhow, um, so, so this is for an
[47:19] article. An article can be an event or
[47:22] it can have multiple events. Um and this
[47:25] is this is for an event that's extracted
[47:27] from it. Um in the other ones what I do
[47:31] is I have like a uh sight specific
[47:35] representation of event that has the
[47:36] data that it tends to have and I have
[47:39] that generic representation of event and
[47:40] a conversion process between them. So
[47:42] that that looks good.
[47:45] Um I do like in general what I do is I
[47:49] have like I separate the downloading
[47:51] part
[47:53] um which is this fetch method and then
[47:55] the extraction part. So that looks
[47:58] correct to me.
[48:01] Uh let's see here.
[48:06] So this is looking for all the items.
[48:08] Parse the item. If there is an item,
[48:10] send it to the LLM. and extract it with
[48:14] um extend with any events that it
[48:16] extracts. Okay, great.
[48:18] Let me look into here. So, this, you
[48:21] know, I just trust that this is fine.
[48:23] I'm not too worried about that. Extract
[48:25] events with LM. All right. Volunteer
[48:27] categories,
[48:29] volunteering, parks, community. Okay,
[48:31] great.
[48:33] Yeah. Yeah. If it has a volunteering
[48:35] category, sure. Um in general I don't
[48:39] like doing in against a list because
[48:42] it's a linear search. It's generally
[48:43] better to use a set which will be O of
[48:45] one.
[48:48] Uh same deal with this keywords. Uh you
[48:51] should use a set for this. The
[48:54] performance for these small lists versus
[48:56] sets is kind of negligible. So I'm not
[48:58] too worried about it.
[49:00] Um okay.
[49:03] I don't love that it's checking if any
[49:06] of these are in the title or
[49:07] description. So, I'll probably delete
[49:09] that.
[49:11] Content for analysis. Preparing content
[49:13] for All right. So, it's doing that. Full
[49:16] extraction prompt.
[49:18] 40 mini is absolutely not what we should
[49:21] use. Part of the reason why it's saying
[49:23] 40 mini is because we're generating code
[49:25] over here with clawson sonnet 4 and uh
[49:29] we should be using like 41 mini or you
[49:32] know uh I don't think five is available
[49:35] via API yet but um we should be using a
[49:39] newer one but probably cloud sonnet 4
[49:42] was trained on data that uh you know
[49:45] doesn't know about 4.1 so it's
[49:46] generating slightly older stuff. Uh we
[49:49] have aluminum on max tokens. That's
[49:50] okay. Temperature 0.1 that's okay.
[49:55] Parse as and we're parsing as an
[49:59] extracted event or none.
[50:02] So that is okay.
[50:07] If we go into here
[50:10] LLM response it's doing
[50:15] uh oh jeez there's so much wrong with
[50:17] this. Um,
[50:23] so, so it's doing doing coding style
[50:26] with LLMs that's that's outdated. Um, as
[50:29] a general rule,
[50:32] um, I'll show you what in gerally you
[50:34] should do in a sec. Um, let's see if we
[50:37] can go over to LM canonicalization.
[50:40] So, as a general rule, like say you have
[50:43] this, you know, big old list of
[50:44] instructions.
[50:46] uh you have your sort of standard here's
[50:49] your directions you know how you should
[50:52] behave as an agent and then here's the
[50:55] input that I want you to process and
[50:57] then you run it through uh you know in
[51:02] this case open AI client chat
[51:04] completions parse uh this one is using
[51:07] gpt 4.1
[51:10] and we're doing a response format so
[51:12] we're actually giving it a pideantic
[51:13] model we're having it generate
[51:15] structured data that's what we wanted to
[51:16] do um instead and this is something that
[51:20] you can do with most of the LLM
[51:22] providers
[51:24] instead the code that uh was generated
[51:27] here
[51:29] uh this parse LLM response or sorry I
[51:33] should say all right so we're doing this
[51:36] here right client chat completions
[51:39] create we have all this stuff here we
[51:42] don't have a response format it's just
[51:44] giving us text back and we're probably
[51:48] doing something like please please send
[51:50] us JSON pretty please and then here in
[51:54] parsl response we're saying go search
[51:57] reax and search for any JSON this is
[51:59] like the old way to do it that was like
[52:04] uh common like a year and a half ago um
[52:06] even maybe a year ago it's super dubious
[52:10] um half the time it's going to crash
[52:14] um And then your recourse is to just try
[52:18] again or rerun it. So
[52:22] yeah. Uh
[52:27] can't believe it generated that. That's
[52:29] really disappointing. Let's look at the
[52:31] what prompt did it give us here?
[52:38] You're an expert at this. So I do like
[52:40] that you know in in this case we're
[52:42] saying we're explaining our data
[52:44] structure. That's that's good. That's
[52:45] something you should generally do.
[52:47] Return your response as a JSON object.
[52:49] Yeah, I mean that's good to do, too. But
[52:51] we got to do, you know, specify the
[52:53] output format. Uh focus only on
[52:55] volunteer events with specific dates.
[52:58] So, one thing that I do want to bring up
[53:01] is that like we give us this this
[53:04] instruction right here, right? uh
[53:10] says extract any outdoor volunteer
[53:12] events
[53:17] event information. The thing I'm looking
[53:18] for is to try to figure out if it
[53:20] designed it to extract multiple events
[53:22] from a singular single blog post or
[53:24] single events from, you know, zero or
[53:26] one or is it, you know, up to n because
[53:29] that post actually mentioned two
[53:32] volunteer events, not just one.
[53:36] And so here you can see optional event
[53:40] which means it can return zero or one.
[53:44] Uh but in this case, the blog post
[53:46] mentions two.
[53:48] Uh and so the LM is probably going to
[53:50] have a hard time
[53:52] because we're telling it, oh, give us
[53:55] one event, but the post actually has
[53:57] two.
[53:58] Um so that's going to be problematic.
[54:01] Oh, hang on one sec.
[54:46] Yeah.
[55:58] Thank you.
[56:23] Well, uh, found out why people were
[56:26] hanging off the roof is because, uh,
[56:28] they lost their key and they're trying
[56:30] to track their Air Tag and they thought
[56:33] maybe it was in my place but it wasn't.
[56:37] Um
[56:38] I guess maybe I'll just I'll I'll go on
[56:41] for like a couple more minutes. Um
[56:46] so uh so quick check of where things are
[56:50] at. So part of the reason why I'm
[56:52] looking through the LLM results in
[56:55] detail, there's two reasons for it. One
[56:56] is because we're in an educational
[56:58] setting, right? And so I want to make
[56:59] sure that that we can all learn from it.
[57:01] Um if I were
[57:04] um you know just on my own, maybe I
[57:05] would just run stuff and see um in this
[57:08] case you know that it wants to run a
[57:10] dedicated script in the test folder not
[57:12] through pi test. I would be h I don't
[57:14] know. Um
[57:17] so that's one thing. The other reason
[57:19] why um
[57:22] uh I I didn't um didn't want to just go
[57:26] try and run the tests because when I was
[57:29] over here
[57:32] uh was it when I was over here
[57:39] testing the parse item that's fine
[57:45] event maybe it wasn't over there but
[57:47] somewhere in here I noticed that it was
[57:49] doing this thing of like optional
[57:51] events.
[57:53] So, it's assuming that it's only going
[57:54] to get one. Um, and I know that that
[57:58] particular event has two. Um, and so
[58:02] what we'll have to do to make this work,
[58:05] and I'll do this um probably over the
[58:08] weekend, is
[58:13] uh let's see where to put it.
[58:19] It's not in parse lm response. It's the
[58:21] thing that calls it.
[58:24] So here
[58:27] where we're doing this call, uh what I'm
[58:30] going to do is to um set a return type.
[58:33] So sort of like I do here where I set
[58:36] response format.
[58:39] I mean also I'm going to change the
[58:41] model to be a better one too, but I'll
[58:43] set a response format uh to one that can
[58:47] have you know an arbitrary number of
[58:48] events. So that's one of the things we
[58:50] need to do is to you know extract a list
[58:54] of events. And so probably
[58:58] we could say it looks like
[59:03] s extract
[59:06] extracted event list
[59:11] base model and then it's just going to
[59:12] look like that events.
[59:16] So then down here, what we're going to
[59:19] do is we're going to say
[59:26] response format equals extracted event.
[59:29] Uh why are you mad?
[59:35] I think it's parse if I remember.
[59:40] Parse. Let's see.
[59:45] Chat completions. parse. Yeah,
[59:49] just copy paste this so I make sure that
[59:51] I get the thing exactly right. So parse
[59:54] reports response format. Great.
[59:57] And then note there's a couple
[59:59] differences here in the way that model
[60:01] actually let me split this so that we
[60:03] can I can show it more clearly.
[60:09] Okay. So there's two or three different
[60:12] there. Well, there's two there's a
[60:14] couple different things going on here.
[60:16] One is that here we're using GPT 4.1.
[60:20] This is GPT40 mini. Um, so we want to
[60:23] use the newer model and uh while we're
[60:25] in development, I'll probably use, you
[60:27] know, 4.1. Um, not the mini. Um, it
[60:31] costs more, but I'm using the GitHub
[60:33] one, so it's it's free. Um, it just
[60:35] means that I'm going to run out of, you
[60:37] know, ability to process at a certain
[60:38] point.
[60:40] uh this open AI slash thing here is
[60:44] actually a special case situation
[60:46] because we're using GitHub models. So I
[60:49] will show you the client call there.
[60:52] So luckily this is calling the same git
[60:54] client. Um but we are loading a GitHub
[60:58] token from the environment
[61:00] and then the endpoint which is the
[61:03] server we're connecting to is actually
[61:05] models.github.aiinference.
[61:08] It's not actually an OpenAI server. It's
[61:10] a model. It's a server that GitHub owns,
[61:13] but they've made their servers
[61:15] compatible with the OpenAI LLM library
[61:20] if you pass in this base URL thing and
[61:24] the GitHub token.
[61:26] Um,
[61:29] all right. Sorry. Maybe I'll I'll kind
[61:31] of sort of stop there in the the coding
[61:35] part and just sort of see like are there
[61:37] things that people were wondering about
[61:38] or you know questions people had or um
[61:41] you know anything you're curious about
[62:16] All right. Well, uh, since there are no
[62:18] questions, uh, what I'll actually do is,
[62:20] you know, get get started working on
[62:22] dinner here and, uh,
[62:25] and, yeah, then I can try to come back
[62:27] to this and, uh, clean up some of this
[62:30] this AI generated stuff here. Um, it
[62:33] probably won't be too bad. I'm saying,
[62:34] you know, I'm forcing a type to that.
[62:37] Um, probably just have to offer a little
[62:40] bit of um, uh, let's see here. Um,
[62:46] little bit of
[62:50] probably in here
[62:52] um, guidelines here about like how to
[62:55] process um, multiple events. Um, and
[62:59] then the other thing that I noticed that
[63:01] we don't have in here is we don't have
[63:03] caching.
[63:04] And so, um, what that means is that
[63:07] every time I run the test, it's going to
[63:09] go and do, I don't know, 10 20 LM calls.
[63:12] Um, well, if it keeps doing that, I'm
[63:14] just going to run out of, um, you know,
[63:16] LM uh,
[63:21] however GitHub handles their like rate
[63:24] limiting and quotas. And so, you know, I
[63:26] have to figure out a little bit of a
[63:28] better way of handling that. Um,
[63:32] so I might need to do something a little
[63:34] bit differently for the sake of testing
[63:36] because I don't want the unit test
[63:38] themselves to drain all of my GitHub
[63:41] models LLM usage. Um, and then, you
[63:44] know, prevent me from using it for
[63:45] anything else.
[63:51] All right. Well, yeah, it was it was,
[63:54] you know, a good time. talked through
[63:55] some good stuff and uh you know made
[63:58] some made some progress on something
[64:00] that's been on my list for a little
[64:01] while. So uh have a bit of llm clean up
[64:04] to do still
[64:06] and uh yeah I hope you guys have a good
[64:08] rest of your weekend.
[64:14] >> Same to you. Thank you.
[64:21] All right, just shutting down the screen
[64:22] share
[64:26] or trying to
[64:28] stop share.
